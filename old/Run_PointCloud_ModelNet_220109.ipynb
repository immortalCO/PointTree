{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Run_PointCloud_ModelNet.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xJm_DG6kzGYG",
        "4lmXaxD5ynlo",
        "rqM9d9ravexM",
        "zaVtwp4wsIME",
        "rEgeHANNsM7r",
        "4U4NvVgYupdf"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJm_DG6kzGYG"
      },
      "source": [
        "# **One-time Init**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hIfBidT2tE0",
        "outputId": "3e87a5bb-1817-4528-dc44-710a6164636d"
      },
      "source": [
        "from os import chdir, environ\n",
        "environ['TZ'] = 'US/Central'\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jan  1 22:07:48 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 496.49       Driver Version: 496.49       CUDA Version: 11.5     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ... WDDM  | 00000000:02:00.0  On |                  N/A |\n",
            "|  0%   51C    P5    16W / 170W |   4091MiB / 12288MiB |     34%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      2204    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
            "|    0   N/A  N/A      7244    C+G   ...b3d8bbwe\\ScreenSketch.exe    N/A      |\n",
            "|    0   N/A  N/A      8912    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
            "|    0   N/A  N/A     12380    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
            "|    0   N/A  N/A     14480    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     14532    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
            "|    0   N/A  N/A     15676    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
            "|    0   N/A  N/A     21200    C+G   ...wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
            "|    0   N/A  N/A     22456    C+G   ...oot\\Office16\\POWERPNT.EXE    N/A      |\n",
            "|    0   N/A  N/A     24396    C+G   ...ons\\Grammarly.Desktop.exe    N/A      |\n",
            "|    0   N/A  N/A     26812    C+G   ...8bbwe\\WindowsTerminal.exe    N/A      |\n",
            "|    0   N/A  N/A     29928    C+G   ...4.0.2.0\\GoogleDriveFS.exe    N/A      |\n",
            "|    0   N/A  N/A     31212    C+G   ...Roaming\\Zoom\\bin\\Zoom.exe    N/A      |\n",
            "|    0   N/A  N/A     32192    C+G   ...bbwe\\HxCalendarAppImm.exe    N/A      |\n",
            "|    0   N/A  N/A     37284    C+G   ...IA GeForce Experience.exe    N/A      |\n",
            "|    0   N/A  N/A     43904    C+G   ...8wekyb3d8bbwe\\GameBar.exe    N/A      |\n",
            "|    0   N/A  N/A     48308    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
            "|    0   N/A  N/A     48892    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
            "|    0   N/A  N/A     50060    C+G   Insufficient Permissions        N/A      |\n",
            "|    0   N/A  N/A     53404    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "_EmauZ9Vp3_r",
        "outputId": "751630d8-3ade-49cf-9dcf-008ab09251f4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/google_drive', force_remount=True)\n",
        "!unlink /content/drive\n",
        "!ln -s /content/google_drive/MyDrive/ /content/drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-2-85854138f314>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush_and_unmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/google_drive'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unlink /content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ln -s /content/google_drive/MyDrive/ /content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWNGK_g-i5Eo"
      },
      "source": [
        "# For debug\n",
        "from os import environ\n",
        "# environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lmXaxD5ynlo"
      },
      "source": [
        "# **Starting Work**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7mHJSTOLfAk"
      },
      "source": [
        "from os import chdir, environ\n",
        "environ['TZ'] = 'US/Central'\n",
        "chdir('PointCloud/')\n",
        "# chdir('/content/drive/PointCloud/')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global logging_init_flag\n",
        "logging_init_flag = False\n",
        "\n",
        "def init_logging(OUTPUT):\n",
        "    global logging_init_flag\n",
        "    if logging_init_flag:\n",
        "        return\n",
        "    logging_init_flag = True\n",
        "\n",
        "    logger = logging.getLogger()\n",
        "    logger.setLevel(logging.DEBUG)\n",
        "    formatter = logging.Formatter(\n",
        "        '%(asctime)s - %(levelname)s:\\t%(message)s',\n",
        "        datefmt='%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    fh = logging.FileHandler(f\"{OUTPUT}/training.log\")\n",
        "    fh.setLevel(logging.INFO)\n",
        "    fh.setFormatter(formatter)\n",
        "\n",
        "    ch = logging.StreamHandler()\n",
        "    ch.setLevel(logging.DEBUG)\n",
        "    ch.setFormatter(formatter)\n",
        "\n",
        "    logger.addHandler(ch)\n",
        "    logger.addHandler(fh)\n",
        "\n"
      ],
      "metadata": {
        "id": "E1_pFKn6s08r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHDHoF-Lsmle",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99b39a34-0d89-4405-90ae-4e5f15f9fe9a"
      },
      "source": [
        "!ls -lt --time-style='+%y-%m-%d %H:%M:%S'\n",
        "!dir"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'ls' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Volume in drive C is OS\n",
            " Volume Serial Number is 3A4D-1115\n",
            "\n",
            " Directory of C:\\Users\\immor\\Colab\\PointCloud\n",
            "\n",
            "01/09/2022  13:30    <DIR>          .\n",
            "01/08/2022  11:58    <DIR>          ..\n",
            "10/27/2021  09:09            53,575 build_tree\n",
            "11/01/2021  22:50             3,795 build_tree.cpp\n",
            "01/07/2022  15:32            20,639 build_tree.py\n",
            "11/01/2021  22:50             2,769 build_tree_basic.cpp\n",
            "11/01/2021  22:50             5,065 build_tree_extra.cpp\n",
            "10/24/2021  09:45             1,969 build_tree_toy.py\n",
            "01/07/2022  02:46             8,160 dataset.py\n",
            "12/03/2021  11:10    <DIR>          datasets\n",
            "09/23/2021  13:13               208 def.sh\n",
            "09/24/2021  10:16           579,198 dev.ans\n",
            "10/27/2021  09:09           350,568 dev.out\n",
            "01/09/2022  13:30            13,096 encoder.py\n",
            "10/31/2021  11:26             9,195 model.py\n",
            "10/17/2021  15:20            12,386 model_arrange.py\n",
            "11/02/2021  20:28            14,641 model_attention.py\n",
            "10/23/2021  06:33            14,284 model_carry.py\n",
            "09/30/2021  21:57             7,892 model_channel.py\n",
            "12/02/2021  10:55            12,660 model_cross.py\n",
            "10/24/2021  08:06            12,574 model_dense.py\n",
            "11/08/2021  12:18            14,781 model_dropout.py\n",
            "11/01/2021  22:23            13,983 model_extra.py\n",
            "12/02/2021  21:03            12,223 model_res.py\n",
            "10/30/2021  14:49             6,953 model_transformer.py\n",
            "10/31/2021  11:18    <DIR>          old\n",
            "10/24/2021  09:46            93,631 plot_directions.nb\n",
            "01/08/2022  13:55             1,058 res_encoder.py\n",
            "10/31/2021  11:18    <DIR>          scratch\n",
            "01/08/2022  11:39    <DIR>          scratch_extra\n",
            "01/06/2022  20:53    <DIR>          scratch_shapenetpart\n",
            "01/08/2022  12:35             7,169 segment.py\n",
            "11/02/2021  18:29    <DIR>          tmp\n",
            "10/24/2021  00:18            29,679 train_split.pth\n",
            "01/09/2022  13:30    <DIR>          __pycache__\n",
            "              26 File(s)      1,302,151 bytes\n",
            "               9 Dir(s)  421,196,640,256 bytes free\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLvduaqgSRuq"
      },
      "source": [
        "# **Experiment Init**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XInyKWaTSYXY",
        "outputId": "416adcc8-c314-477b-eaef-5be6c8df5914"
      },
      "source": [
        "import json\n",
        "import h5py\n",
        "import torch\n",
        "import os\n",
        "from encoder import Encoder, EncoderKdtAlign, MLP\n",
        "# from encoder import MLP\n",
        "from res_encoder import ResEncoder\n",
        "from build_tree import get_directions, init_directions\n",
        "import logging\n",
        "from dataset import *\n",
        "\n",
        "# 1\n",
        "# prefix = \"_orig_pca_symloss_x2\"\n",
        "# no_prealign = True \n",
        "# rotate_only = False\n",
        "# augment = 2\n",
        "# transform = no_transform \n",
        "# use_symmetry_loss = True\n",
        "# dim = 2048 # 2048\n",
        "# lowrk = 128\n",
        "# dim_layer0 = 16 # 16\n",
        "# dim_repeat_cut = 5\n",
        "# train_augment = False\n",
        "# permute_augment = False #False\n",
        "# model_size = 2 ** 11\n",
        "# num_res_layer = 0\n",
        "# carry_dim = 64\n",
        "# upload_remove_equal = True\n",
        "\n",
        "# 2\n",
        "prefix = \"_affine_pca_nosample_x16\"\n",
        "no_prealign = False \n",
        "rotate_only = False\n",
        "augment = 16\n",
        "transform = affine_transform \n",
        "use_symmetry_loss = False\n",
        "dim = 2048 # 2048\n",
        "lowrk = 999999999\n",
        "dim_layer0 = 16 # 16\n",
        "dim_repeat_cut = 5 # 5\n",
        "train_augment = False\n",
        "permute_augment = True\n",
        "model_size = 2 ** 11\n",
        "num_res_layer = 2\n",
        "carry_dim = 64\n",
        "upload_remove_equal = False\n",
        "\n",
        "OUTPUT = 'scratch_extra'\n",
        "\n",
        "sample_layers = 50 # 2\n",
        "channel = 1\n",
        "\n",
        "\n",
        "sample_child_first = False # True in l7s1\n",
        "num_classes = 40\n",
        "DATASET = './datasets/ModelNet40'\n",
        "chaos_limit = 0\n",
        "\n",
        "init_logging(OUTPUT)\n",
        "logging.info(f\"prefix = {prefix}\")\n",
        "_ = init_directions(chaos_limit, calc_dmap=False)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-09 14:18:29 - INFO:\tprefix = _affine_pca_nosample_x16\n",
            "2022-01-09 14:18:29 - INFO:\tinit_directions: # = 3\n",
            "2022-01-09 14:18:29 - DEBUG:\t0: 0.000000 1.000000 0.000000 otho = {1, 2}\n",
            "2022-01-09 14:18:29 - DEBUG:\t1: 1.000000 0.000000 0.000000 otho = {0, 2}\n",
            "2022-01-09 14:18:29 - DEBUG:\t2: 0.000000 0.000000 1.000000 otho = {0, 1}\n",
            "2022-01-09 14:18:29 - INFO:\tbasic # = 3\n",
            "2022-01-09 14:18:29 - INFO:\ttransforms # = 48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ve1aug-tytB",
        "outputId": "9a20ab22-8b48-4b42-ce50-a086ecf4cda1"
      },
      "source": [
        "torch.manual_seed(674433238)\n",
        "# model = Encoder(model_size, sample_layers, dim, OUTPUT, channel=channel, sample_child_first=sample_child_first, dim_layer0=dim_layer0, dim_repeat_cut=dim_repeat_cut, use_symmetry_loss=use_symmetry_loss).cuda()\n",
        "# model = ResEncoder(num_res_layer, carry_dim, model_size, sample_layers, dim, OUTPUT, channel=channel, sample_child_first=sample_child_first, dim_layer0=dim_layer0, dim_repeat_cut=dim_repeat_cut, use_symmetry_loss=use_symmetry_loss).cuda()\n",
        "model = EncoderKdtAlign(model_size, sample_layers, dim, OUTPUT, channel=channel, sample_child_first=sample_child_first, dim_layer0=dim_layer0, dim_repeat_cut=dim_repeat_cut, use_symmetry_loss=use_symmetry_loss).cuda()\n",
        "model.dim"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-09 14:18:29 - INFO:\tself.N = 2048\n",
            "2022-01-09 14:18:29 - INFO:\tself.num_layers = 12\n",
            "2022-01-09 14:18:29 - INFO:\tself.sample_layers = 50\n",
            "2022-01-09 14:18:29 - INFO:\tlayer 0 (leaf) # = 2048 odim = 16\n",
            "2022-01-09 14:18:30 - INFO:\tlayer 1 (unsampled) # = 1024 odim = 32\n",
            "2022-01-09 14:18:30 - INFO:\tlayer 2 (unsampled) # = 512 odim = 64\n",
            "2022-01-09 14:18:30 - INFO:\tlayer 3 (unsampled) # = 256 odim = 128\n",
            "2022-01-09 14:18:30 - INFO:\tlayer 4 (unsampled) # = 128 odim = 256\n",
            "2022-01-09 14:18:30 - INFO:\tlayer 5 (unsampled) # = 64 odim = 256\n",
            "2022-01-09 14:18:30 - INFO:\tlayer 6 (unsampled) # = 32 odim = 512\n",
            "2022-01-09 14:18:30 - INFO:\tlayer 7 (unsampled) # = 16 odim = 512\n",
            "2022-01-09 14:18:30 - INFO:\tlayer 8 (unsampled) # = 8 odim = 1024\n",
            "2022-01-09 14:18:30 - INFO:\tlayer 9 (unsampled) # = 4 odim = 1024\n",
            "2022-01-09 14:18:30 - INFO:\tlayer 10 (unsampled) # = 2 odim = 2048\n",
            "2022-01-09 14:18:30 - INFO:\tlayer 11 (unsampled) # = 1 odim = 2048\n",
            "2022-01-09 14:18:30 - INFO:\tself.N = 2048\n",
            "2022-01-09 14:18:30 - INFO:\tself.num_layers = 12\n",
            "2022-01-09 14:18:30 - INFO:\tself.sample_layers = 50\n",
            "2022-01-09 14:18:30 - INFO:\tlayer 0 (leaf) # = 2048 odim = 16\n",
            "2022-01-09 14:18:30 - INFO:\tlayer 1 (unsampled) # = 1024 odim = 32\n",
            "2022-01-09 14:18:30 - INFO:\tlayer 2 (unsampled) # = 512 odim = 64\n",
            "2022-01-09 14:18:30 - INFO:\tlayer 3 (unsampled) # = 256 odim = 128\n",
            "2022-01-09 14:18:30 - INFO:\tlayer 4 (unsampled) # = 128 odim = 256\n",
            "2022-01-09 14:18:30 - INFO:\tlayer 5 (unsampled) # = 64 odim = 256\n",
            "2022-01-09 14:18:30 - INFO:\tlayer 6 (unsampled) # = 32 odim = 512\n",
            "2022-01-09 14:18:30 - INFO:\tlayer 7 (unsampled) # = 16 odim = 512\n",
            "2022-01-09 14:18:30 - INFO:\tlayer 8 (unsampled) # = 8 odim = 1024\n",
            "2022-01-09 14:18:30 - INFO:\tlayer 9 (unsampled) # = 4 odim = 1024\n",
            "2022-01-09 14:18:30 - INFO:\tlayer 10 (unsampled) # = 2 odim = 2048\n",
            "2022-01-09 14:18:30 - INFO:\tlayer 11 (unsampled) # = 1 odim = 2048\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2048"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hack(model):\n",
        "    if upload_remove_equal:\n",
        "        for i, layer in enumerate(model.layers):\n",
        "            if layer.idim == layer.odim:\n",
        "                layer.upload = torch.nn.Identity().cuda()\n",
        "                print(f\"#{i}: Set upload to identity.\")\n",
        "    if lowrk < dim:\n",
        "        from encoder import convert_lowrk\n",
        "        # pts_align = model.layers[0].pts_align\n",
        "        # for i in range(6):\n",
        "        #     pts_align.fc[i] = convert_lowrk(pts_align.fc[i], lowrk).cuda()\n",
        "        # for l in model.layers[0].mlp.layers:\n",
        "        #     l.linear = convert_lowrk(l.linear, lowrk).cuda()\n",
        "        for i, layer in enumerate(model.layers):\n",
        "            if layer.layer_type != 'leaf' and isinstance(layer.upload, MLP):\n",
        "                for l in layer.upload.layers:\n",
        "                    l.linear = convert_lowrk(l.linear, lowrk).cuda()\n",
        "                print(f\"#{i}: Converted to lowrk.\")\n",
        "    if 'orig' in prefix:\n",
        "        l = model.layers[0]\n",
        "        l.mlp = MLP([l.idim, l.odim * 4, l.odim], init=0.25).cuda()\n",
        "        print(f\"Reset middle layer of pts2feature\")\n",
        "\n",
        "# hack(model)\n",
        "hack(model.align_encoder)\n",
        "hack(model.encoder)"
      ],
      "metadata": {
        "id": "7z32SzUQT1JW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS58zLcFNjT9",
        "outputId": "d445bbb7-344b-43a9-e2a2-29179d9b2f6c"
      },
      "source": [
        "model"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EncoderKdtAlign(\n",
              "  (align_encoder): Encoder(\n",
              "    (layers): ModuleList(\n",
              "      (0): EncoderLayer(\n",
              "        (pts_align): Alignment(\n",
              "          (conv1): Conv1d(3, 128, kernel_size=(1,), stride=(1,))\n",
              "          (conv2): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
              "          (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
              "          (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (fc3): Linear(in_features=256, out_features=9, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (mlp): MLP(\n",
              "          (layers): ModuleList(\n",
              "            (0): FC(\n",
              "              (linear): Linear(in_features=3, out_features=1024, bias=True)\n",
              "              (relu): PReLU(num_parameters=1)\n",
              "              (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (1): FC(\n",
              "              (linear): Linear(in_features=1024, out_features=16, bias=True)\n",
              "              (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): EncoderLayer(\n",
              "        (upload): MLP(\n",
              "          (layers): ModuleList(\n",
              "            (0): FC(\n",
              "              (linear): Linear(in_features=16, out_features=32, bias=True)\n",
              "              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): EncoderLayer(\n",
              "        (upload): MLP(\n",
              "          (layers): ModuleList(\n",
              "            (0): FC(\n",
              "              (linear): Linear(in_features=32, out_features=64, bias=True)\n",
              "              (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): EncoderLayer(\n",
              "        (upload): MLP(\n",
              "          (layers): ModuleList(\n",
              "            (0): FC(\n",
              "              (linear): Linear(in_features=64, out_features=128, bias=True)\n",
              "              (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): EncoderLayer(\n",
              "        (upload): MLP(\n",
              "          (layers): ModuleList(\n",
              "            (0): FC(\n",
              "              (linear): Linear(in_features=128, out_features=256, bias=True)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): EncoderLayer(\n",
              "        (upload): MLP(\n",
              "          (layers): ModuleList(\n",
              "            (0): FC(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (6): EncoderLayer(\n",
              "        (upload): MLP(\n",
              "          (layers): ModuleList(\n",
              "            (0): FC(\n",
              "              (linear): Linear(in_features=256, out_features=512, bias=True)\n",
              "              (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): EncoderLayer(\n",
              "        (upload): MLP(\n",
              "          (layers): ModuleList(\n",
              "            (0): FC(\n",
              "              (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (8): EncoderLayer(\n",
              "        (upload): MLP(\n",
              "          (layers): ModuleList(\n",
              "            (0): FC(\n",
              "              (linear): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (9): EncoderLayer(\n",
              "        (upload): MLP(\n",
              "          (layers): ModuleList(\n",
              "            (0): FC(\n",
              "              (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (10): EncoderLayer(\n",
              "        (upload): MLP(\n",
              "          (layers): ModuleList(\n",
              "            (0): FC(\n",
              "              (linear): Linear(in_features=1024, out_features=2048, bias=True)\n",
              "              (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (11): EncoderLayer(\n",
              "        (upload): MLP(\n",
              "          (layers): ModuleList(\n",
              "            (0): FC(\n",
              "              (linear): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "              (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (align_mlp): MLP(\n",
              "    (layers): ModuleList(\n",
              "      (0): FC(\n",
              "        (linear): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "        (relu): PReLU(num_parameters=1)\n",
              "        (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): FC(\n",
              "        (linear): Linear(in_features=1024, out_features=512, bias=True)\n",
              "        (relu): PReLU(num_parameters=1)\n",
              "        (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): FC(\n",
              "        (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (encoder): Encoder(\n",
              "    (layers): ModuleList(\n",
              "      (0): EncoderLayer(\n",
              "        (pts_align): Identity()\n",
              "        (mlp): MLP(\n",
              "          (layers): ModuleList(\n",
              "            (0): FC(\n",
              "              (linear): Linear(in_features=3, out_features=1024, bias=True)\n",
              "              (relu): PReLU(num_parameters=1)\n",
              "              (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (1): FC(\n",
              "              (linear): Linear(in_features=1024, out_features=16, bias=True)\n",
              "              (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): EncoderLayer(\n",
              "        (upload): MLP(\n",
              "          (layers): ModuleList(\n",
              "            (0): FC(\n",
              "              (linear): Linear(in_features=16, out_features=32, bias=True)\n",
              "              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): EncoderLayer(\n",
              "        (upload): MLP(\n",
              "          (layers): ModuleList(\n",
              "            (0): FC(\n",
              "              (linear): Linear(in_features=32, out_features=64, bias=True)\n",
              "              (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): EncoderLayer(\n",
              "        (upload): MLP(\n",
              "          (layers): ModuleList(\n",
              "            (0): FC(\n",
              "              (linear): Linear(in_features=64, out_features=128, bias=True)\n",
              "              (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): EncoderLayer(\n",
              "        (upload): MLP(\n",
              "          (layers): ModuleList(\n",
              "            (0): FC(\n",
              "              (linear): Linear(in_features=128, out_features=256, bias=True)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): EncoderLayer(\n",
              "        (upload): MLP(\n",
              "          (layers): ModuleList(\n",
              "            (0): FC(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (6): EncoderLayer(\n",
              "        (upload): MLP(\n",
              "          (layers): ModuleList(\n",
              "            (0): FC(\n",
              "              (linear): Linear(in_features=256, out_features=512, bias=True)\n",
              "              (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): EncoderLayer(\n",
              "        (upload): MLP(\n",
              "          (layers): ModuleList(\n",
              "            (0): FC(\n",
              "              (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (8): EncoderLayer(\n",
              "        (upload): MLP(\n",
              "          (layers): ModuleList(\n",
              "            (0): FC(\n",
              "              (linear): Linear(in_features=512, out_features=1024, bias=True)\n",
              "              (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (9): EncoderLayer(\n",
              "        (upload): MLP(\n",
              "          (layers): ModuleList(\n",
              "            (0): FC(\n",
              "              (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (10): EncoderLayer(\n",
              "        (upload): MLP(\n",
              "          (layers): ModuleList(\n",
              "            (0): FC(\n",
              "              (linear): Linear(in_features=1024, out_features=2048, bias=True)\n",
              "              (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (11): EncoderLayer(\n",
              "        (upload): MLP(\n",
              "          (layers): ModuleList(\n",
              "            (0): FC(\n",
              "              (linear): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "              (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LzQmMFZmz60"
      },
      "source": [
        "# **Debug**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyuWtrElslel"
      },
      "source": [
        "assert False, \"debug part cannot be run through\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU1ibEuOnAei",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c0510ae-be12-4a74-bb4d-8570acb47599"
      },
      "source": [
        "pts = h5py.File(f'{DATASET}/train0.h5')['data'][0]\n",
        "pts = torch.tensor(pts)\n",
        "output = None"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-17a3ae9dea0c>:1: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  pts = h5py.File(f'{DATASET}/train0.h5')['data'][0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZON2cTGeAKW"
      },
      "source": [
        "pts = transform(pts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoy81cu7nxdj"
      },
      "source": [
        "tree = model.tree\n",
        "pts, output, extra = model.tree.arrange(pts, rotate=not no_prealign, extra=False, pca=True,\n",
        "                                          rotate_only=rotate_only, debug=False)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t36sKk4VIkr"
      },
      "source": [
        "%matplotlib inline\n",
        "def plot(points, color_layers=2, output=None):\n",
        "    import matplotlib.pyplot as plt\n",
        "    from mpl_toolkits.mplot3d import Axes3D\n",
        "    import matplotlib.gridspec as gridspec\n",
        "    import numpy as np\n",
        "\n",
        "    points = points.cpu().numpy()\n",
        "    x, y, z = points[:,0], points[:,1], points[:,2]\n",
        "    x -= x.mean()\n",
        "    y -= y.mean()\n",
        "    z -= z.mean()\n",
        "\n",
        "    color = np.array([0 for _ in range(x.shape[0])])\n",
        "    \n",
        "    def mark_color(z, last_ind=None):\n",
        "        n = z.shape[0]\n",
        "        ind = torch.tensor(z).sort()[1].numpy()\n",
        "        indl, indr = ind[: n >> 1], ind[n >> 1 : ]\n",
        "        if last_ind is not None:\n",
        "            indl, indr = last_ind[indl], last_ind[indr]\n",
        "        color[indr] += 1\n",
        "        return indl, indr\n",
        "\n",
        "    if output is not None:\n",
        "\n",
        "        color = torch.tensor([0]).cuda()\n",
        "        # print(tree.layer_size)\n",
        "        for i, (layer, next_layer_size) in enumerate(zip(reversed(model.layers[1:]), tree.layer_size[1:])):\n",
        "            next_color = torch.zeros(next_layer_size).long().cuda()\n",
        "            if i < color_layers:\n",
        "                color = color << 1\n",
        "                right_add = 1\n",
        "            else:\n",
        "                right_add = 0\n",
        "            assert layer.child_l.max() < next_layer_size\n",
        "            assert layer.child_r.max() < next_layer_size\n",
        "            next_color[layer.child_l] = color\n",
        "            next_color[layer.child_r] = color + right_add\n",
        "            color = next_color\n",
        "\n",
        "        arrange = output[0]\n",
        "        n = points.shape[0]\n",
        "        color = np.array([color[arrange == i].max().item() for i in range(n)])\n",
        "\n",
        "    elif color_layers >= 1:\n",
        "        l, r = mark_color(z)\n",
        "        if color_layers >= 2:\n",
        "            color *= 2\n",
        "            ll, lr = mark_color(y[l], l)\n",
        "            rl, rr = mark_color(y[r], r)\n",
        "            if color_layers >= 3:\n",
        "                color *= 2\n",
        "                for p in [ll, lr, rl, rr]:\n",
        "                    mark_color(x[p], p)\n",
        "\n",
        "    colormap = np.array(['red', 'blue', 'green', 'yellow', 'grey', 'orange', 'purple', 'cyan'])\n",
        "\n",
        "    fig = plt.figure(dpi=80)\n",
        "    gs = gridspec.GridSpec(nrows=2, ncols=4, left=0.1, right=2.5, wspace=0.05, hspace=0.05, bottom=0.1, top=1.3)\n",
        "    for i in range(8):\n",
        "        ax = fig.add_subplot(gs[i // 4, i % 4], projection='3d')\n",
        "\n",
        "        x, y, z = points[:,0], points[:,1], points[:,2]\n",
        "        labx, laby, labz = 'x', 'y', 'z'\n",
        "        if (i & 4) != 0:    x = -x; labx = '-x'\n",
        "        if (i & 2) != 0:    y = -y; laby = '-y'\n",
        "        if (i & 1) != 0:    z = -z; labz = '-z'\n",
        "\n",
        "        lmin = min(x.min(), y.min(), z.min())\n",
        "        lmax = max(x.max(), y.max(), z.max())\n",
        "        ax.scatter(x, y, z, c=colormap[color], marker='.')\n",
        "\n",
        "        ax.set_xlim(lmin, lmax)\n",
        "        ax.set_ylim(lmin, lmax)\n",
        "        ax.set_zlim(lmin, lmax)\n",
        "\n",
        "        ax.set_xlabel(labx)\n",
        "        ax.set_ylabel(laby)\n",
        "        ax.set_zlabel(labz) \n",
        "    plt.show()\n",
        "\n",
        "    fig = plt.figure(dpi=80)\n",
        "    ncolor = color.max() + 1\n",
        "    nrows = max(1, ncolor // 4)\n",
        "    ncols = min(ncolor, 4)\n",
        "    gs = gridspec.GridSpec(nrows=nrows, ncols=ncols, left=0.1, right=0.1 + 0.6 * ncols, wspace=0.05, hspace=0.05, bottom=0.1, top=0.1 + 0.6 * nrows)\n",
        "    for i in range(ncolor):\n",
        "        ax = fig.add_subplot(gs[i // 4, i % 4], projection='3d')\n",
        "\n",
        "        p = points[color == i]\n",
        "        x, y, z = p[:,0], p[:,1], p[:,2]\n",
        "\n",
        "        lmin = min(x.min(), y.min(), z.min())\n",
        "        lmax = max(x.max(), y.max(), z.max())\n",
        "        ax.scatter(x, y, z, c=colormap[i], marker='.')\n",
        "\n",
        "        ax.set_xlim(lmin, lmax)\n",
        "        ax.set_ylim(lmin, lmax)\n",
        "        ax.set_zlim(lmin, lmax)\n",
        "\n",
        "        ax.set_xlabel('x')\n",
        "        ax.set_ylabel('y')\n",
        "        ax.set_zlabel('z') \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEEZykGAVjLk"
      },
      "source": [
        "plot(pts, 3, output=output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86L-VbTUqyGo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "148b4a41-7e2a-4c24-d328-350f2439b2a1"
      },
      "source": [
        "batch_size = 64\n",
        "model.train()\n",
        "for _ in range(8):\n",
        "    _pts = pts.unsqueeze(0).expand(batch_size, *pts.shape)\n",
        "    _output = list(map(lambda x : x.unsqueeze(0).expand(batch_size, *x.shape), output))\n",
        "    _extra = extra.unsqueeze(0).expand(batch_size, *extra.shape)\n",
        "    feature = model(_pts, _output, _extra, perm=0)\n",
        "    print(feature.shape)\n",
        "    (feature.sum()).backward()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 2048])\n",
            "torch.Size([64, 2048])\n",
            "torch.Size([64, 2048])\n",
            "torch.Size([64, 2048])\n",
            "torch.Size([64, 2048])\n",
            "torch.Size([64, 2048])\n",
            "torch.Size([64, 2048])\n",
            "torch.Size([64, 2048])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_tri(pts, tri_ind)"
      ],
      "metadata": {
        "id": "rk52R7MBIve9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_tri(points, tri):\n",
        "    points = points.numpy()\n",
        "    tri = tri.numpy()\n",
        "\n",
        "    fig = plt.figure(dpi=200)\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "    \n",
        "    edges = collect_edges(tri)\n",
        "    x = np.array([])\n",
        "    y = np.array([])\n",
        "    z = np.array([])\n",
        "    for (i,j) in edges:\n",
        "        x = np.append(x, [points[i, 0], points[j, 0], np.nan])      \n",
        "        y = np.append(y, [points[i, 1], points[j, 1], np.nan])      \n",
        "        z = np.append(z, [points[i, 2], points[j, 2], np.nan])\n",
        "    ax.plot3D(x, y, z, color='g', lw='0.1')\n",
        "\n",
        "    ax.scatter(points[:,0], points[:,1], points[:,2], color='b', s=1)\n",
        "\n",
        "\n",
        "def collect_edges(tri):\n",
        "    edges = set()\n",
        "\n",
        "    def sorted_tuple(a,b):\n",
        "        return (a,b) if a < b else (b,a)\n",
        "    # Add edges of tetrahedron (sorted so we don't add an edge twice, even if it comes in reverse order).\n",
        "    for (i0, i1, i2, i3) in tri:\n",
        "        edges.add(sorted_tuple(i0,i1))\n",
        "        edges.add(sorted_tuple(i0,i2))\n",
        "        edges.add(sorted_tuple(i0,i3))\n",
        "        edges.add(sorted_tuple(i1,i2))\n",
        "        edges.add(sorted_tuple(i1,i3))\n",
        "        edges.add(sorted_tuple(i2,i3))\n",
        "    return edges"
      ],
      "metadata": {
        "id": "tUpzwbFoIWqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp7w45moXheA"
      },
      "source": [
        "pts = train_data[7][0]\n",
        "output = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwnsH3fVEy8E"
      },
      "source": [
        "for i in range(50):\n",
        "    output, arrange = tree.arrange(pts, basic=basic, debug=False, device='cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfF1uQMf6E4V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J5eeH4A_KYE"
      },
      "source": [
        "feature.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Emzothiutr1R"
      },
      "source": [
        "for i in range(10):\n",
        "    loss = model(pts.unsqueeze(0), list(map(lambda x : x.unsqueeze(0), output))).view(-1).sum()\n",
        "    loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjWu4jsiezyq"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4IW-IhaXNI7"
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(name, param.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3m193YMMKJX"
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if 'activate' in name:\n",
        "        print(name, \"\\t\", param.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edrzFkxkfSnH"
      },
      "source": [
        "!cp /tmp/cppinput.txt scratch/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTdWpWCrfHto"
      },
      "source": [
        "!tail -n 5 /tmp/cppoutput.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqM9d9ravexM"
      },
      "source": [
        "# **Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWRjuhs4tl1v"
      },
      "source": [
        "from dataset import *\n",
        "import numpy as np"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3Tua4uPKA8G"
      },
      "source": [
        "if False:\n",
        "    from random import shuffle, seed\n",
        "    raw_data = torch.load(f'{OUTPUT}/train_data{prefix}.pth')\n",
        "    n = len(raw_data) // data_augments\n",
        "    perm = list(range(n))\n",
        "    seed(674433238)\n",
        "    shuffle(perm)\n",
        "    train_perm = perm[: -n//8]\n",
        "    valid_perm = perm[-n//8: ]\n",
        "    torch.save([train_perm, valid_perm], f'{OUTPUT}/train_split{prefix}.pth')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqqwreNL5L6g"
      },
      "source": [
        "make = make_data_default\n",
        "if rotate_only:\n",
        "    make = make_data_rotate_only\n",
        "if no_prealign:\n",
        "    make = make_data_no_prealign"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG7rbo4ekcjE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2c5e256-cddd-4c07-919d-d8a51ded0019"
      },
      "source": [
        "n_train = 5\n",
        "clouds = []\n",
        "labels = []\n",
        "for i in range(n_train):\n",
        "    data_file = h5py.File(f'{DATASET}/train{i}.h5')\n",
        "    clouds.append(torch.tensor(np.array(data_file['data'])))\n",
        "    labels.append(torch.tensor(np.array(data_file['label'])))\n",
        "\n",
        "clouds = torch.cat(clouds, dim=0)\n",
        "labels = torch.cat(labels, dim=0)\n",
        "\n",
        "try:\n",
        "    train_perm, valid_perm = torch.load(f'{OUTPUT}/train_split{prefix}.pth')\n",
        "except:\n",
        "    train_perm, valid_perm = torch.load(f'{OUTPUT}/train_split.pth')\n",
        "\n",
        "from math import ceil\n",
        "train_dataset = PointCloudDataset(clouds, labels, model.tree.arrange, augment=augment, transform=transform, make=make, subset=train_perm)\n",
        "valid_dataset = PointCloudDataset(clouds, labels, model.tree.arrange, augment=max(1, (1 + int(ceil(augment/4) + 0.5) if augment <= 4 else augment // 4)), transform=transform, make=make, subset=valid_perm)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-d66ef4e5e104>:5: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  data_file = h5py.File(f'{DATASET}/train{i}.h5')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3j6QUPo11OV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61c76627-d153-44c5-e4c6-b949a5cb383d"
      },
      "source": [
        "n_test = 2\n",
        "clouds = []\n",
        "labels = []\n",
        "for i in range(n_test):\n",
        "    data_file = h5py.File(f'{DATASET}/test{i}.h5')\n",
        "    clouds.append(torch.tensor(np.array(data_file['data'])))\n",
        "    labels.append(torch.tensor(np.array(data_file['label'])))\n",
        "\n",
        "clouds = torch.cat(clouds, dim=0)\n",
        "labels = torch.cat(labels, dim=0)\n",
        "\n",
        "test_dataset = PointCloudDataset(clouds, labels, model.tree.arrange, augment=1, make=make, transform=transform)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-936995772004>:5: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  data_file = h5py.File(f'{DATASET}/test{i}.h5')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bX9UCfSsTweO",
        "outputId": "bba7546f-bd5d-481d-acd5-5b3917688fc7"
      },
      "source": [
        "len(train_dataset), len(valid_dataset), len(test_dataset)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(137792, 4924, 2468)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfWwHySFzgbz"
      },
      "source": [
        "target = [] # ['train', 'valid', 'test']\n",
        "\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "for name, dataset in zip(['train', 'valid', 'test'], [train_dataset, valid_dataset, test_dataset]):\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    if name not in target:\n",
        "        continue\n",
        "\n",
        "    num_workers = 16\n",
        "    batch_size = 8\n",
        "\n",
        "    data_init = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=placeholder, pin_memory=False, drop_last=False)\n",
        "    logging.info(f\"Init {name}\")\n",
        "\n",
        "    mem = []\n",
        "\n",
        "    def save():\n",
        "        torch.save(mem, f'{OUTPUT}/{name}_data{prefix}.pth')\n",
        "        # logging.info(\"Saved\")\n",
        "\n",
        "    for i, data in enumerate(tqdm(data_init)):\n",
        "        mem += data\n",
        "        # logging.debug(f\"Init {name}: {i+1}/{len(data_init)}\")\n",
        "\n",
        "        if (i + 1) % (400 * max(1, augment//4)) == 0:\n",
        "            save()\n",
        "    \n",
        "    save()\n",
        "    logging.info(\"Done\")\n",
        "\n",
        "    del mem\n",
        "    gc.collect()\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaVtwp4wsIME"
      },
      "source": [
        "# **Pretrain**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Md0GTeQGUFH"
      },
      "source": [
        "assert False, \"not implemented\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeTUdpkBrXN3"
      },
      "source": [
        "class FeatureMap(torch.nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super(FeatureMap, self).__init__()\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "        self.linear1 = torch.nn.Linear(dim, dim // 2)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(dim // 2)\n",
        "\n",
        "        self.linear2 = torch.nn.Linear(dim // 2, dim // 4)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(dim // 4)\n",
        "\n",
        "        self.linear3 = torch.nn.Linear(dim // 4, dim // 8)\n",
        "        self.bn3 = torch.nn.BatchNorm1d(dim // 8)\n",
        "        self.dropout = torch.nn.Dropout(0.7)\n",
        "\n",
        "    def forward(self, ans):\n",
        "        ans = self.linear1(ans)\n",
        "        ans = self.bn1(ans)\n",
        "        ans = self.relu(ans)\n",
        "\n",
        "        ans = self.linear2(ans)\n",
        "        ans = self.dropout(ans)\n",
        "        ans = self.bn2(ans)\n",
        "        ans = self.relu(ans)\n",
        "        \n",
        "        ans = self.linear3(ans)\n",
        "        ans = self.bn3(ans)\n",
        "        return ans\n",
        "\n",
        "torch.manual_seed(674433238)\n",
        "feature_map = FeatureMap(dim).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBI9yhBalwYE"
      },
      "source": [
        "try:\n",
        "    raw_data\n",
        "except:\n",
        "    raw_data = torch.load(f'{OUTPUT}/train_data{prefix}.pth')\n",
        "try:\n",
        "    test_data\n",
        "except:\n",
        "    test_data = torch.load(f'{OUTPUT}/test_data{prefix}.pth')\n",
        "try:\n",
        "    train_perm, valid_perm = torch.load(f'{OUTPUT}/train_split{prefix}.pth')\n",
        "except:\n",
        "    train_perm, valid_perm = torch.load(f'{OUTPUT}/train_split.pth')\n",
        "\n",
        "n = len(raw_data)\n",
        "\n",
        "train_data = [raw_data[i * data_augments + j] for i in train_perm for j in range(data_augments)]\n",
        "valid_data = [raw_data[i * data_augments + j] for i in valid_perm for j in range(data_augments)]\n",
        "\n",
        "classes = [[] for i in range(num_classes)]\n",
        "for (pts, output, extra, label) in train_data:\n",
        "    classes[label.item()].append((pts, output, extra, label))\n",
        "\n",
        "valid_classes = [[] for i in range(num_classes)]\n",
        "for (pts, output, extra, label) in valid_data:\n",
        "    valid_classes[label.item()].append((pts, output, extra, label))\n",
        "\n",
        "from random import shuffle, seed\n",
        "seed(674433238)\n",
        "shuffle(train_data)\n",
        "shuffle(valid_data)\n",
        "shuffle(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0tNaAoqyne9"
      },
      "source": [
        "def make_batch(batches, eval=False):\n",
        "    from random import randint\n",
        "    layers = 0\n",
        "    points = []\n",
        "    inputs = None\n",
        "    labels = []\n",
        "    extras = []\n",
        "    for pts, output, extra, label in batches:\n",
        "        # Simple data augment\n",
        "        # sgn = torch.tensor(-1).pow(torch.randint(low=0, high=2, size=[extra.shape[-1]])).cuda()\n",
        "        sgn = (-1) ** randint(0, 1)\n",
        "        \n",
        "        points.append(pts.cuda())\n",
        "        labels.append(label.cuda())\n",
        "        extras.append(extra.cuda() * (1 if eval else sgn))\n",
        "        if inputs is None:\n",
        "            layers = len(output)\n",
        "            inputs = [[] for _ in output]\n",
        "\n",
        "        for line, out in zip(inputs, output):\n",
        "            line.append(out.cuda())\n",
        "\n",
        "    points = torch.stack(points, dim=0).float().cuda()\n",
        "    extras = torch.stack(extras, dim=0).float().cuda()\n",
        "    for i, line in enumerate(inputs):\n",
        "        inputs[i] = torch.stack(line, dim=0).long().cuda()\n",
        "    labels = torch.stack(labels, dim=0).long().cuda()\n",
        "    \n",
        "    return (points, inputs, extras), labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DYbl6PPLvSf"
      },
      "source": [
        "from random import choice\n",
        "num_samples = 2\n",
        "temperature = 0.07\n",
        "\n",
        "class_size = torch.tensor([len(c) for c in classes]).float().cuda()\n",
        "contrast_crit = torch.nn.CrossEntropyLoss(reduce=None)\n",
        "\n",
        "def contrast_batch(used_classes=classes):\n",
        "    batches = []\n",
        "    for _ in range(num_samples):\n",
        "        for c in used_classes:\n",
        "            batches.append(choice(c))\n",
        "    return make_batch(batches)\n",
        "\n",
        "def contrast_loss(features, labels):\n",
        "    num_data = num_classes * num_samples\n",
        "\n",
        "    ratio = class_size[labels]\n",
        "    ratio /= ratio.sum()\n",
        "    labels = (labels.unsqueeze(0) == labels.unsqueeze(1))\n",
        "\n",
        "    features = torch.nn.functional.normalize(features, dim=1)\n",
        "\n",
        "    sim = features.matmul(features.T)\n",
        "\n",
        "    mask = torch.eye(num_data).bool().cuda()\n",
        "    labels = labels[~mask].view(num_data, -1)\n",
        "    sim = sim[~mask].view(num_data, -1)\n",
        "\n",
        "    pos = sim[labels].view(num_data, -1)\n",
        "    neg = sim[~labels].view(num_data, -1)\n",
        "\n",
        "    logits = torch.cat([pos, neg], dim=1) / temperature\n",
        "\n",
        "    correct = ((logits.argmax(dim=-1) == 0) * ratio).sum().item() * num_data\n",
        "\n",
        "    loss = (contrast_crit(logits, torch.zeros(num_data).long().cuda()) * ratio).sum()\n",
        "\n",
        "    return loss, correct\n",
        "\n",
        "def valid_eval(classes=valid_classes):\n",
        "    model.eval()\n",
        "    feature_map.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        cum_loss = 0\n",
        "        cum_correct = 0\n",
        "        cum_1 = 0\n",
        "\n",
        "        for _ in range(8):\n",
        "            input, labels = contrast_batch(classes)\n",
        "            features = feature_map(model(*input))\n",
        "            l, c = contrast_loss(features, labels)\n",
        "\n",
        "            cum_loss += l.item()\n",
        "            cum_correct += c / (num_classes * num_samples)\n",
        "            cum_1 += 1\n",
        "\n",
        "        valid_str = \"valid = %.4lf (%.6lf)\" % (cum_loss / cum_1, cum_correct / cum_1)\n",
        "\n",
        "    model.train()\n",
        "    feature_map.train()\n",
        "\n",
        "    return valid_str\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCaHoUxITroY"
      },
      "source": [
        "from random import choice, randint, seed\n",
        "import build_tree\n",
        "import torch\n",
        "from math import sin, acos\n",
        "\n",
        "logging.info(f\"train_data # = {len(train_data)}\")\n",
        "\n",
        "\n",
        "model.train()\n",
        "feature_map.train()\n",
        "activate = lambda x : x\n",
        "\n",
        "pi = acos(-1)\n",
        "cum_loss = 0\n",
        "\n",
        "batch_scale = 1 # 1 if basic else 1\n",
        "epoch_scale = 4 # 4 if basic else 2\n",
        "num_trans = 1\n",
        "\n",
        "print_epoch = 50\n",
        "valid_epoch = 1\n",
        "epoch_since = 0\n",
        "save_epoch = 500\n",
        "cut_epoch = 10000000000\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "debug_print = 5\n",
        "\n",
        "def erate_value(epoch):\n",
        "    N = 20000\n",
        "    return torch.tensor(sin(min(1, epoch / N) * pi / 2)).cuda()\n",
        "\n",
        "threshold = -1.0\n",
        "\n",
        "num_epoch = 100000\n",
        "\n",
        "crit = torch.nn.CrossEntropyLoss()\n",
        "opt = torch.optim.Adam(list(model.parameters()) + list(feature_map.parameters()), lr=1e-4)\n",
        "# sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=num_epoch / 5, eta_min=1e-5)\n",
        "sch = torch.optim.lr_scheduler.ExponentialLR(opt, 0.9999)\n",
        "\n",
        "def get_trans(n=3):\n",
        "    if n == 0:  return [None]\n",
        "    return [randint(0, len(build_tree.transforms) - 1) for _ in range(n)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqP9X6SVmFqU"
      },
      "source": [
        "seed(674433238)\n",
        "torch.manual_seed(674433238)\n",
        "\n",
        "best_vres = -1.0\n",
        "\n",
        "for epoch in range(1, num_epoch + 1):\n",
        "    for _ in range(epoch_scale):\n",
        "        loss = 0.\n",
        "        for _ in range(batch_scale):\n",
        "            input, labels = contrast_batch()\n",
        "            for iperm in get_trans(num_trans):\n",
        "\n",
        "                features = feature_map(model(*input, perm=iperm))\n",
        "                l, c = contrast_loss(features, labels)\n",
        "                loss += l\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    correct += c\n",
        "                    total += labels.shape[0]\n",
        "                    epoch_since += 1\n",
        "        \n",
        "        # assert loss.isnan().sum() == 0\n",
        "        cum_loss += loss.item()\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        \n",
        "    sch.step()\n",
        "        \n",
        "    if epoch <= debug_print or epoch % print_epoch == 0:\n",
        "        valid_str = \"\"\n",
        "        func = logging.debug\n",
        "        func(f\"train #{epoch} lr = {'%.2e' % sch.get_last_lr()[0]} train = {'%.4lf (%.6lf)' % (cum_loss / epoch_since, correct / total)} {valid_eval()}\")\n",
        "        epoch_since = cum_loss = correct = total = 0\n",
        "\n",
        "    if epoch % save_epoch == 0 or epoch == debug_print:\n",
        "        torch.save({\n",
        "            'encoder': model.state_dict(),\n",
        "            'feature_map': feature_map.state_dict(),\n",
        "        }, f\"{OUTPUT}/pretrained_{epoch}.pth\")\n",
        "        logging.info(f\"Saved\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiILxo2qlfBf"
      },
      "source": [
        "# **Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw0-l-jDmbMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c165c1b-c743-4b57-d9a9-94de20fd67b4"
      },
      "source": [
        "from dataset import make_batch_train, make_batch_eval\n",
        "\n",
        "global batch_size\n",
        "num_workers = 0\n",
        "batch_size = 64 #64\n",
        "\n",
        "for name, dataset in zip(['train', 'valid', 'test'], [train_dataset, valid_dataset, test_dataset]):\n",
        "    print(f\"Loading {name}\")\n",
        "    dataset.mem = torch.load(f'{OUTPUT}/{name}_data{prefix}.pth')\n",
        "    assert len(dataset.mem) == len(dataset)\n",
        "\n",
        "mbtrain = make_batch_generator(dropout=0.5, augment=train_augment) if 'orig' in prefix else make_batch_train\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, collate_fn=mbtrain, pin_memory=True, drop_last=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, collate_fn=make_batch_eval, pin_memory=True, drop_last=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, collate_fn=make_batch_eval, pin_memory=True, drop_last=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading train\n",
            "Loading valid\n",
            "Loading test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIcxQV-Jl-Mf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc647062-b55a-4b6c-bd78-2b0ae9249f27"
      },
      "source": [
        "torch.manual_seed(674433238)\n",
        "\n",
        "if 'orig' in prefix:\n",
        "    from encoder import make_lowrk\n",
        "    class Classifier(torch.nn.Module):\n",
        "        def __init__(self, idim, odim):\n",
        "            super(Classifier, self).__init__()\n",
        "            self.relu = torch.nn.ReLU()\n",
        "\n",
        "            self.linear1 = make_lowrk(idim, idim // 2, lowrk)\n",
        "            self.bn1 = torch.nn.BatchNorm1d(idim // 2)\n",
        "\n",
        "            self.linear2 = make_lowrk(idim // 2, idim // 4, lowrk)\n",
        "            self.bn2 = torch.nn.BatchNorm1d(idim // 4)\n",
        "            self.dropout = torch.nn.Dropout(1 - 1/8)\n",
        "\n",
        "            self.linear3 = make_lowrk(idim // 4, odim, lowrk)\n",
        "\n",
        "        def forward(self, ans):\n",
        "            ans = self.linear1(ans)\n",
        "            ans = self.bn1(ans)\n",
        "            ans = self.relu(ans)\n",
        "\n",
        "            ans = self.linear2(ans)\n",
        "            ans = self.bn2(ans)\n",
        "            ans = self.dropout(ans)\n",
        "            ans = self.relu(ans)\n",
        "            \n",
        "            ans = self.linear3(ans)\n",
        "            return ans\n",
        "    linear = Classifier(model.dim, num_classes).cuda()\n",
        "else:\n",
        "    linear = MLP([model.dim, model.dim // 2, model.dim // 4, num_classes], last_bn=False).cuda()\n",
        "\n",
        "linear"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (layers): ModuleList(\n",
              "    (0): FC(\n",
              "      (linear): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "      (relu): PReLU(num_parameters=1)\n",
              "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): FC(\n",
              "      (linear): Linear(in_features=1024, out_features=512, bias=True)\n",
              "      (relu): PReLU(num_parameters=1)\n",
              "      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): FC(\n",
              "      (linear): Linear(in_features=512, out_features=40, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Dj6kfNZmdeq"
      },
      "source": [
        "def evaluate(model, linear, loader, noprint=False, perms=[None]):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    if not noprint:\n",
        "        logging.info(f\"loader # = {len(loader)}\")\n",
        "\n",
        "    print_epoch = 1\n",
        "\n",
        "    model.eval()\n",
        "    linear.eval()\n",
        "    activate = lambda x : x\n",
        "\n",
        "    for epoch, (input, label) in enumerate(loader):\n",
        "        with torch.no_grad():\n",
        "            label = label.squeeze(-1).cuda()\n",
        "            for perm in perms:\n",
        "                result = activate(linear(model(*input, perm=perm).contiguous().view(label.size(0), -1)))\n",
        "\n",
        "                correct += (result.argmax(dim=-1) == label.cuda()).sum().item()\n",
        "                total += label.size()[0]\n",
        "\n",
        "        if not noprint:\n",
        "            if (epoch // batch_size + 1) % print_epoch == 0:\n",
        "                logging.debug(f\"test #{epoch} correct = {'%.6lf' % (correct / total)}\")\n",
        "\n",
        "    if not noprint:\n",
        "        logging.info(f\"Done: score = {'%.8lf' % (correct / total)}\")\n",
        "\n",
        "    model.train()\n",
        "    linear.train()  \n",
        "    \n",
        "    return correct / total"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0zAZto5v9DT"
      },
      "source": [
        "from random import choice, randint\n",
        "import build_tree\n",
        "import torch\n",
        "\n",
        "def get_trans(n=3):\n",
        "    if n == 0:  return [None]\n",
        "    return [randint(0, len(build_tree.transforms) - 1) for _ in range(n)]\n",
        "\n",
        "def save(epoch):\n",
        "    torch.save({\n",
        "        'encoder': model.state_dict(),\n",
        "        'linear': linear.state_dict(),\n",
        "        # 'opt': opt.state_dict(),\n",
        "        # 'sch': sch.state_dict(),\n",
        "        # 'best_vres': best_vres,\n",
        "    }, f\"{OUTPUT}/trained_{epoch}.pth\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En3eHY5Av_tF"
      },
      "source": [
        "# if 'orig' in prefix:\n",
        "#     ckpt = torch.load(f\"{OUTPUT}/pretrained_affine_pca_nosample_x16_20211207.pth\")\n",
        "#     model.load_state_dict(ckpt['encoder'])\n",
        "#     linear.load_state_dict(ckpt['linear'])\n",
        "#     print(\"Pretrain loaded\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBpg22qOl2Hu"
      },
      "source": [
        "global current_epoch\n",
        "global best_vres\n",
        "current_epoch = 0\n",
        "best_vres = -1.0\n",
        "\n",
        "def train(more_epoch=100000, valid_result_threshold=1.0):\n",
        "    global current_epoch\n",
        "    global best_vres\n",
        "    global batch_size\n",
        "\n",
        "    logging.info(f\"train epoch = {current_epoch + 1} ~ {more_epoch} threshold = {valid_result_threshold}\")\n",
        "\n",
        "    model.train()\n",
        "    linear.train()\n",
        "    activate = lambda x : x\n",
        "\n",
        "    cum_loss = 0\n",
        "\n",
        "    batch_scale = 1 # 1\n",
        "    epoch_scale = 8 # 8\n",
        "    num_trans = 1 if permute_augment else 0\n",
        "\n",
        "\n",
        "    print_epoch = 10\n",
        "    valid_epoch = 10\n",
        "    epoch_since = 0\n",
        "    save_epoch = 100\n",
        "    cut_epoch = 10000000000\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    temperature = 1\n",
        "    threshold = -1.0\n",
        "\n",
        "    crit = torch.nn.CrossEntropyLoss()\n",
        "    opt = torch.optim.Adam(list(model.parameters()) + list(linear.parameters()), lr=1e-4)\n",
        "    sch = torch.optim.lr_scheduler.ExponentialLR(opt, 0.9999)\n",
        "    save(current_epoch)\n",
        "\n",
        "    for epoch in range(current_epoch + 1, current_epoch + more_epoch + 1):\n",
        "\n",
        "        current_epoch = epoch\n",
        "\n",
        "        for _ in range(epoch_scale):\n",
        "            loss = 0.\n",
        "            for _ in range(batch_scale):\n",
        "                input, label = next(iter(train_loader))\n",
        "                label = label.squeeze(-1).cuda()\n",
        "                for iperm in get_trans(num_trans):\n",
        "                    \n",
        "                    logits = linear(model(*input, perm=iperm).contiguous().view(batch_size, -1))\n",
        "                    loss += crit(logits / temperature, label.cuda())\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        correct += (logits.argmax(dim=-1) == label.cuda()).sum().item()\n",
        "                        total += label.size()[0]\n",
        "                        epoch_since += 1\n",
        "            \n",
        "            # assert loss.isnan().sum() == 0\n",
        "            cum_loss += loss.item()\n",
        "            opt.zero_grad()\n",
        "            # loss.backward()\n",
        "            ((loss / loss.clamp(min=1e-6).item()) if 'orig' in prefix else loss).backward()\n",
        "            opt.step()\n",
        "            \n",
        "        sch.step()\n",
        "\n",
        "        if cum_loss / epoch_since < threshold:\n",
        "            epoch_scale, batch_scale = batch_scale, epoch_scale\n",
        "            \n",
        "            logging.info(\"Threshold Reached\")\n",
        "            threshold = -1e10\n",
        "            \n",
        "        if epoch <= 5 or epoch % print_epoch == 0:\n",
        "            valid_str = \"\"\n",
        "            func = logging.debug\n",
        "\n",
        "            stop_training = False\n",
        "            if epoch % valid_epoch == 0:\n",
        "                vres = evaluate(model, linear, valid_loader, noprint=True)\n",
        "                valid_str = f\"valid = {'%.6lf' % vres}\"\n",
        "                stop_training = (vres >= valid_result_threshold)\n",
        "                if vres > best_vres:\n",
        "                    best_vres = vres\n",
        "                    torch.save({\n",
        "                        'encoder': model.state_dict(),\n",
        "                        'linear': linear.state_dict()\n",
        "                    }, f\"{OUTPUT}/trained_best{prefix}.pth\")\n",
        "                    valid_str += \" updated\"\n",
        "\n",
        "                func = logging.info\n",
        "            func(f\"train #{epoch} lr = {'%.2e' % sch.get_last_lr()[0]} loss = {'%.6lf' % (cum_loss / epoch_since)} train = {'%.6lf' % (correct / total)} {valid_str}\")\n",
        "            epoch_since = cum_loss = correct = total = 0\n",
        "\n",
        "            if stop_training:\n",
        "                break\n",
        "\n",
        "\n",
        "        if epoch % save_epoch == 0:\n",
        "            save(epoch)\n",
        "            tres = evaluate(model, linear, test_loader, noprint=True)\n",
        "            logging.info(f\"Saved test = {'%.6lf' % tres}\")\n",
        "\n",
        "        if epoch % cut_epoch == 0:\n",
        "            if batch_size > 8:\n",
        "                batch_size //= 2\n",
        "                epoch_scale *= 2\n",
        "\n",
        "            logging.info(f\"Cut batch_size = {batch_size} epoch_scale = {epoch_scale}\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pzKDajQK5_4o",
        "outputId": "c490ddbf-e23e-4b66-e051-f31fb3ed4385"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-09 14:19:23 - INFO:\ttrain epoch = 1 ~ 100000 threshold = 1.0\n",
            "2022-01-09 14:19:28 - DEBUG:\ttrain #1 lr = 1.00e-04 loss = 3.669731 train = 0.064453 \n",
            "2022-01-09 14:19:30 - DEBUG:\ttrain #2 lr = 1.00e-04 loss = 3.527757 train = 0.113281 \n",
            "2022-01-09 14:19:33 - DEBUG:\ttrain #3 lr = 1.00e-04 loss = 3.419238 train = 0.144531 \n",
            "2022-01-09 14:19:35 - DEBUG:\ttrain #4 lr = 1.00e-04 loss = 3.300736 train = 0.187500 \n",
            "2022-01-09 14:19:37 - DEBUG:\ttrain #5 lr = 1.00e-04 loss = 3.180820 train = 0.191406 \n",
            "2022-01-09 14:19:54 - INFO:\ttrain #10 lr = 9.99e-05 loss = 3.013043 train = 0.228125 valid = 0.219740 updated\n",
            "2022-01-09 14:20:22 - INFO:\ttrain #20 lr = 9.98e-05 loss = 2.670121 train = 0.281250 valid = 0.285337 updated\n",
            "2022-01-09 14:20:51 - INFO:\ttrain #30 lr = 9.97e-05 loss = 2.483932 train = 0.328516 valid = 0.312957 updated\n",
            "2022-01-09 14:21:19 - INFO:\ttrain #40 lr = 9.96e-05 loss = 2.323066 train = 0.367969 valid = 0.356621 updated\n",
            "2022-01-09 14:21:47 - INFO:\ttrain #50 lr = 9.95e-05 loss = 2.162837 train = 0.404883 valid = 0.397847 updated\n",
            "2022-01-09 14:22:15 - INFO:\ttrain #60 lr = 9.94e-05 loss = 2.015958 train = 0.451367 valid = 0.419984 updated\n",
            "2022-01-09 14:22:43 - INFO:\ttrain #70 lr = 9.93e-05 loss = 1.866020 train = 0.482031 valid = 0.450447 updated\n",
            "2022-01-09 14:23:11 - INFO:\ttrain #80 lr = 9.92e-05 loss = 1.765557 train = 0.509180 valid = 0.493095 updated\n",
            "2022-01-09 14:23:39 - INFO:\ttrain #90 lr = 9.91e-05 loss = 1.656143 train = 0.537109 valid = 0.378960\n",
            "2022-01-09 14:24:07 - INFO:\ttrain #100 lr = 9.90e-05 loss = 1.542084 train = 0.561719 valid = 0.497157 updated\n",
            "2022-01-09 14:24:11 - INFO:\tSaved test = 0.470016\n",
            "2022-01-09 14:24:39 - INFO:\ttrain #110 lr = 9.89e-05 loss = 1.503682 train = 0.572070 valid = 0.548944 updated\n",
            "2022-01-09 14:25:07 - INFO:\ttrain #120 lr = 9.88e-05 loss = 1.452333 train = 0.590234 valid = 0.566613 updated\n",
            "2022-01-09 14:25:35 - INFO:\ttrain #130 lr = 9.87e-05 loss = 1.380631 train = 0.608398 valid = 0.566409\n",
            "2022-01-09 14:26:04 - INFO:\ttrain #140 lr = 9.86e-05 loss = 1.358428 train = 0.608789 valid = 0.590171 updated\n",
            "2022-01-09 14:26:32 - INFO:\ttrain #150 lr = 9.85e-05 loss = 1.289471 train = 0.630273 valid = 0.537571\n",
            "2022-01-09 14:27:00 - INFO:\ttrain #160 lr = 9.84e-05 loss = 1.248902 train = 0.645703 valid = 0.592201 updated\n",
            "2022-01-09 14:27:28 - INFO:\ttrain #170 lr = 9.83e-05 loss = 1.213135 train = 0.647461 valid = 0.616166 updated\n",
            "2022-01-09 14:27:56 - INFO:\ttrain #180 lr = 9.82e-05 loss = 1.163508 train = 0.664453 valid = 0.593623\n",
            "2022-01-09 14:28:24 - INFO:\ttrain #190 lr = 9.81e-05 loss = 1.145178 train = 0.660547 valid = 0.601340\n",
            "2022-01-09 14:28:53 - INFO:\ttrain #200 lr = 9.80e-05 loss = 1.139432 train = 0.670117 valid = 0.643989 updated\n",
            "2022-01-09 14:28:56 - INFO:\tSaved test = 0.624797\n",
            "2022-01-09 14:29:24 - INFO:\ttrain #210 lr = 9.79e-05 loss = 1.099084 train = 0.673047 valid = 0.617790\n",
            "2022-01-09 14:29:52 - INFO:\ttrain #220 lr = 9.78e-05 loss = 1.083370 train = 0.685156 valid = 0.538180\n",
            "2022-01-09 14:30:20 - INFO:\ttrain #230 lr = 9.77e-05 loss = 1.074031 train = 0.681445 valid = 0.580219\n",
            "2022-01-09 14:30:48 - INFO:\ttrain #240 lr = 9.76e-05 loss = 1.045891 train = 0.676562 valid = 0.635256\n",
            "2022-01-09 14:31:16 - INFO:\ttrain #250 lr = 9.75e-05 loss = 1.052227 train = 0.685937 valid = 0.639724\n",
            "2022-01-09 14:31:44 - INFO:\ttrain #260 lr = 9.74e-05 loss = 1.020720 train = 0.703320 valid = 0.638099\n",
            "2022-01-09 14:32:13 - INFO:\ttrain #270 lr = 9.73e-05 loss = 0.992314 train = 0.701562 valid = 0.666328 updated\n",
            "2022-01-09 14:32:41 - INFO:\ttrain #280 lr = 9.72e-05 loss = 0.967081 train = 0.710352 valid = 0.666734 updated\n",
            "2022-01-09 14:33:09 - INFO:\ttrain #290 lr = 9.71e-05 loss = 0.912114 train = 0.724414 valid = 0.662266\n",
            "2022-01-09 14:33:37 - INFO:\ttrain #300 lr = 9.70e-05 loss = 0.944878 train = 0.715625 valid = 0.658205\n",
            "2022-01-09 14:33:41 - INFO:\tSaved test = 0.653160\n",
            "2022-01-09 14:34:09 - INFO:\ttrain #310 lr = 9.69e-05 loss = 0.940132 train = 0.725195 valid = 0.683184 updated\n",
            "2022-01-09 14:34:37 - INFO:\ttrain #320 lr = 9.69e-05 loss = 0.883779 train = 0.729102 valid = 0.581235\n",
            "2022-01-09 14:35:05 - INFO:\ttrain #330 lr = 9.68e-05 loss = 0.905509 train = 0.722852 valid = 0.664703\n",
            "2022-01-09 14:35:33 - INFO:\ttrain #340 lr = 9.67e-05 loss = 0.898886 train = 0.735938 valid = 0.641755\n",
            "2022-01-09 14:36:02 - INFO:\ttrain #350 lr = 9.66e-05 loss = 0.846473 train = 0.742383 valid = 0.687449 updated\n",
            "2022-01-09 14:36:30 - INFO:\ttrain #360 lr = 9.65e-05 loss = 0.818064 train = 0.747656 valid = 0.647035\n",
            "2022-01-09 14:36:58 - INFO:\ttrain #370 lr = 9.64e-05 loss = 0.842228 train = 0.742188 valid = 0.696994 updated\n",
            "2022-01-09 14:37:26 - INFO:\ttrain #380 lr = 9.63e-05 loss = 0.816222 train = 0.750977 valid = 0.693542\n",
            "2022-01-09 14:37:54 - INFO:\ttrain #390 lr = 9.62e-05 loss = 0.767439 train = 0.760156 valid = 0.695573\n",
            "2022-01-09 14:38:22 - INFO:\ttrain #400 lr = 9.61e-05 loss = 0.794067 train = 0.755469 valid = 0.704712 updated\n",
            "2022-01-09 14:38:25 - INFO:\tSaved test = 0.705024\n",
            "2022-01-09 14:38:53 - INFO:\ttrain #410 lr = 9.60e-05 loss = 0.795709 train = 0.755078 valid = 0.686434\n",
            "2022-01-09 14:39:22 - INFO:\ttrain #420 lr = 9.59e-05 loss = 0.779193 train = 0.762695 valid = 0.726645 updated\n",
            "2022-01-09 14:39:50 - INFO:\ttrain #430 lr = 9.58e-05 loss = 0.719662 train = 0.781445 valid = 0.690699\n",
            "2022-01-09 14:40:18 - INFO:\ttrain #440 lr = 9.57e-05 loss = 0.729361 train = 0.776172 valid = 0.709586\n",
            "2022-01-09 14:40:46 - INFO:\ttrain #450 lr = 9.56e-05 loss = 0.745506 train = 0.769727 valid = 0.700447\n",
            "2022-01-09 14:41:14 - INFO:\ttrain #460 lr = 9.55e-05 loss = 0.732236 train = 0.775586 valid = 0.705727\n",
            "2022-01-09 14:41:42 - INFO:\ttrain #470 lr = 9.54e-05 loss = 0.724525 train = 0.771289 valid = 0.706946\n",
            "2022-01-09 14:42:10 - INFO:\ttrain #480 lr = 9.53e-05 loss = 0.728596 train = 0.776172 valid = 0.711007\n",
            "2022-01-09 14:42:38 - INFO:\ttrain #490 lr = 9.52e-05 loss = 0.703316 train = 0.785937 valid = 0.713038\n",
            "2022-01-09 14:43:06 - INFO:\ttrain #500 lr = 9.51e-05 loss = 0.686683 train = 0.780469 valid = 0.690902\n",
            "2022-01-09 14:43:10 - INFO:\tSaved test = 0.659238\n",
            "2022-01-09 14:43:38 - INFO:\ttrain #510 lr = 9.50e-05 loss = 0.667635 train = 0.788867 valid = 0.709586\n",
            "2022-01-09 14:44:06 - INFO:\ttrain #520 lr = 9.49e-05 loss = 0.681819 train = 0.785156 valid = 0.727864 updated\n",
            "2022-01-09 14:44:34 - INFO:\ttrain #530 lr = 9.48e-05 loss = 0.703009 train = 0.786914 valid = 0.726036\n",
            "2022-01-09 14:45:02 - INFO:\ttrain #540 lr = 9.47e-05 loss = 0.663144 train = 0.795117 valid = 0.709586\n",
            "2022-01-09 14:45:30 - INFO:\ttrain #550 lr = 9.46e-05 loss = 0.673774 train = 0.788477 valid = 0.696994\n",
            "2022-01-09 14:45:59 - INFO:\ttrain #560 lr = 9.46e-05 loss = 0.681531 train = 0.782227 valid = 0.737815 updated\n",
            "2022-01-09 14:46:27 - INFO:\ttrain #570 lr = 9.45e-05 loss = 0.635952 train = 0.806836 valid = 0.724411\n",
            "2022-01-09 14:46:55 - INFO:\ttrain #580 lr = 9.44e-05 loss = 0.608554 train = 0.807422 valid = 0.731722\n",
            "2022-01-09 14:47:23 - INFO:\ttrain #590 lr = 9.43e-05 loss = 0.611517 train = 0.810352 valid = 0.707149\n",
            "2022-01-09 14:47:51 - INFO:\ttrain #600 lr = 9.42e-05 loss = 0.606378 train = 0.809961 valid = 0.711413\n",
            "2022-01-09 14:47:54 - INFO:\tSaved test = 0.706240\n",
            "2022-01-09 14:48:22 - INFO:\ttrain #610 lr = 9.41e-05 loss = 0.635349 train = 0.796875 valid = 0.721771\n",
            "2022-01-09 14:48:50 - INFO:\ttrain #620 lr = 9.40e-05 loss = 0.611883 train = 0.802734 valid = 0.733753\n",
            "2022-01-09 14:49:18 - INFO:\ttrain #630 lr = 9.39e-05 loss = 0.575719 train = 0.818945 valid = 0.750812 updated\n",
            "2022-01-09 14:49:47 - INFO:\ttrain #640 lr = 9.38e-05 loss = 0.612202 train = 0.803711 valid = 0.719334\n",
            "2022-01-09 14:50:17 - INFO:\ttrain #650 lr = 9.37e-05 loss = 0.595103 train = 0.814648 valid = 0.722583\n",
            "2022-01-09 14:50:48 - INFO:\ttrain #660 lr = 9.36e-05 loss = 0.607982 train = 0.807227 valid = 0.716288\n",
            "2022-01-09 14:51:18 - INFO:\ttrain #670 lr = 9.35e-05 loss = 0.590492 train = 0.814648 valid = 0.708367\n",
            "2022-01-09 14:51:49 - INFO:\ttrain #680 lr = 9.34e-05 loss = 0.589066 train = 0.808984 valid = 0.746751\n",
            "2022-01-09 14:52:19 - INFO:\ttrain #690 lr = 9.33e-05 loss = 0.563731 train = 0.817969 valid = 0.733753\n",
            "2022-01-09 14:52:50 - INFO:\ttrain #700 lr = 9.32e-05 loss = 0.559870 train = 0.815234 valid = 0.732535\n",
            "2022-01-09 14:52:54 - INFO:\tSaved test = 0.727715\n",
            "2022-01-09 14:53:25 - INFO:\ttrain #710 lr = 9.31e-05 loss = 0.527368 train = 0.834961 valid = 0.742689\n",
            "2022-01-09 14:53:56 - INFO:\ttrain #720 lr = 9.31e-05 loss = 0.546515 train = 0.826562 valid = 0.738627\n",
            "2022-01-09 14:54:26 - INFO:\ttrain #730 lr = 9.30e-05 loss = 0.536079 train = 0.830664 valid = 0.722989\n",
            "2022-01-09 14:54:56 - INFO:\ttrain #740 lr = 9.29e-05 loss = 0.559891 train = 0.826953 valid = 0.735784\n",
            "2022-01-09 14:55:26 - INFO:\ttrain #750 lr = 9.28e-05 loss = 0.567221 train = 0.824414 valid = 0.741470\n",
            "2022-01-09 14:55:57 - INFO:\ttrain #760 lr = 9.27e-05 loss = 0.540612 train = 0.827734 valid = 0.729488\n",
            "2022-01-09 14:56:27 - INFO:\ttrain #770 lr = 9.26e-05 loss = 0.520401 train = 0.838477 valid = 0.744314\n",
            "2022-01-09 14:56:57 - INFO:\ttrain #780 lr = 9.25e-05 loss = 0.515968 train = 0.832422 valid = 0.739643\n",
            "2022-01-09 14:57:27 - INFO:\ttrain #790 lr = 9.24e-05 loss = 0.521727 train = 0.833008 valid = 0.736596\n",
            "2022-01-09 14:57:57 - INFO:\ttrain #800 lr = 9.23e-05 loss = 0.474679 train = 0.847656 valid = 0.742080\n",
            "2022-01-09 14:58:01 - INFO:\tSaved test = 0.737034\n",
            "2022-01-09 14:58:31 - INFO:\ttrain #810 lr = 9.22e-05 loss = 0.499257 train = 0.841602 valid = 0.724005\n",
            "2022-01-09 14:59:01 - INFO:\ttrain #820 lr = 9.21e-05 loss = 0.531987 train = 0.825000 valid = 0.728270\n",
            "2022-01-09 14:59:31 - INFO:\ttrain #830 lr = 9.20e-05 loss = 0.512946 train = 0.836914 valid = 0.719537\n",
            "2022-01-09 15:00:02 - INFO:\ttrain #840 lr = 9.19e-05 loss = 0.483325 train = 0.844727 valid = 0.733347\n",
            "2022-01-09 15:00:32 - INFO:\ttrain #850 lr = 9.19e-05 loss = 0.510092 train = 0.839648 valid = 0.746548\n",
            "2022-01-09 15:01:03 - INFO:\ttrain #860 lr = 9.18e-05 loss = 0.475559 train = 0.839648 valid = 0.719131\n",
            "2022-01-09 15:01:33 - INFO:\ttrain #870 lr = 9.17e-05 loss = 0.475848 train = 0.844727 valid = 0.734972\n",
            "2022-01-09 15:02:03 - INFO:\ttrain #880 lr = 9.16e-05 loss = 0.458963 train = 0.850000 valid = 0.749594\n",
            "2022-01-09 15:02:33 - INFO:\ttrain #890 lr = 9.15e-05 loss = 0.462888 train = 0.848242 valid = 0.763607 updated\n",
            "2022-01-09 15:03:04 - INFO:\ttrain #900 lr = 9.14e-05 loss = 0.456872 train = 0.850781 valid = 0.730504\n",
            "2022-01-09 15:03:07 - INFO:\tSaved test = 0.728525\n",
            "2022-01-09 15:03:38 - INFO:\ttrain #910 lr = 9.13e-05 loss = 0.462046 train = 0.851953 valid = 0.759342\n",
            "2022-01-09 15:04:08 - INFO:\ttrain #920 lr = 9.12e-05 loss = 0.437914 train = 0.859961 valid = 0.743704\n",
            "2022-01-09 15:04:38 - INFO:\ttrain #930 lr = 9.11e-05 loss = 0.444639 train = 0.855078 valid = 0.739439\n",
            "2022-01-09 15:05:08 - INFO:\ttrain #940 lr = 9.10e-05 loss = 0.427451 train = 0.859375 valid = 0.744314\n",
            "2022-01-09 15:05:36 - INFO:\ttrain #950 lr = 9.09e-05 loss = 0.440617 train = 0.853711 valid = 0.758123\n",
            "2022-01-09 15:06:04 - INFO:\ttrain #960 lr = 9.08e-05 loss = 0.446114 train = 0.856836 valid = 0.762388\n",
            "2022-01-09 15:06:32 - INFO:\ttrain #970 lr = 9.08e-05 loss = 0.440415 train = 0.859375 valid = 0.747766\n",
            "2022-01-09 15:07:01 - INFO:\ttrain #980 lr = 9.07e-05 loss = 0.480041 train = 0.847461 valid = 0.746141\n",
            "2022-01-09 15:07:29 - INFO:\ttrain #990 lr = 9.06e-05 loss = 0.442627 train = 0.857422 valid = 0.761982\n",
            "2022-01-09 15:07:57 - INFO:\ttrain #1000 lr = 9.05e-05 loss = 0.415841 train = 0.873633 valid = 0.748985\n",
            "2022-01-09 15:08:01 - INFO:\tSaved test = 0.753647\n",
            "2022-01-09 15:08:29 - INFO:\ttrain #1010 lr = 9.04e-05 loss = 0.422307 train = 0.859766 valid = 0.703493\n",
            "2022-01-09 15:08:57 - INFO:\ttrain #1020 lr = 9.03e-05 loss = 0.442464 train = 0.856445 valid = 0.752437\n",
            "2022-01-09 15:09:25 - INFO:\ttrain #1030 lr = 9.02e-05 loss = 0.414810 train = 0.865430 valid = 0.767059 updated\n",
            "2022-01-09 15:09:54 - INFO:\ttrain #1040 lr = 9.01e-05 loss = 0.419581 train = 0.863281 valid = 0.751828\n",
            "2022-01-09 15:10:22 - INFO:\ttrain #1050 lr = 9.00e-05 loss = 0.475842 train = 0.844727 valid = 0.759139\n",
            "2022-01-09 15:10:50 - INFO:\ttrain #1060 lr = 8.99e-05 loss = 0.401981 train = 0.867578 valid = 0.739439\n",
            "2022-01-09 15:11:18 - INFO:\ttrain #1070 lr = 8.99e-05 loss = 0.428578 train = 0.862305 valid = 0.756296\n",
            "2022-01-09 15:11:46 - INFO:\ttrain #1080 lr = 8.98e-05 loss = 0.415741 train = 0.865430 valid = 0.753249\n",
            "2022-01-09 15:12:14 - INFO:\ttrain #1090 lr = 8.97e-05 loss = 0.398918 train = 0.872266 valid = 0.752437\n",
            "2022-01-09 15:12:43 - INFO:\ttrain #1100 lr = 8.96e-05 loss = 0.402598 train = 0.864062 valid = 0.762998\n",
            "2022-01-09 15:12:46 - INFO:\tSaved test = 0.749595\n",
            "2022-01-09 15:13:14 - INFO:\ttrain #1110 lr = 8.95e-05 loss = 0.404568 train = 0.866797 valid = 0.763201\n",
            "2022-01-09 15:13:42 - INFO:\ttrain #1120 lr = 8.94e-05 loss = 0.367119 train = 0.879687 valid = 0.750000\n",
            "2022-01-09 15:14:10 - INFO:\ttrain #1130 lr = 8.93e-05 loss = 0.381530 train = 0.869922 valid = 0.767872 updated\n",
            "2022-01-09 15:14:38 - INFO:\ttrain #1140 lr = 8.92e-05 loss = 0.398506 train = 0.865625 valid = 0.768278 updated\n",
            "2022-01-09 15:15:06 - INFO:\ttrain #1150 lr = 8.91e-05 loss = 0.376932 train = 0.876758 valid = 0.762591\n",
            "2022-01-09 15:15:35 - INFO:\ttrain #1160 lr = 8.90e-05 loss = 0.351962 train = 0.881250 valid = 0.743298\n",
            "2022-01-09 15:16:03 - INFO:\ttrain #1170 lr = 8.90e-05 loss = 0.356626 train = 0.885547 valid = 0.758530\n",
            "2022-01-09 15:16:31 - INFO:\ttrain #1180 lr = 8.89e-05 loss = 0.368097 train = 0.878711 valid = 0.768887 updated\n",
            "2022-01-09 15:16:59 - INFO:\ttrain #1190 lr = 8.88e-05 loss = 0.394350 train = 0.870117 valid = 0.755890\n",
            "2022-01-09 15:17:27 - INFO:\ttrain #1200 lr = 8.87e-05 loss = 0.381312 train = 0.871094 valid = 0.747157\n",
            "2022-01-09 15:17:31 - INFO:\tSaved test = 0.745543\n",
            "2022-01-09 15:17:59 - INFO:\ttrain #1210 lr = 8.86e-05 loss = 0.384765 train = 0.875977 valid = 0.767465\n",
            "2022-01-09 15:18:28 - INFO:\ttrain #1220 lr = 8.85e-05 loss = 0.376192 train = 0.879687 valid = 0.770715 updated\n",
            "2022-01-09 15:18:56 - INFO:\ttrain #1230 lr = 8.84e-05 loss = 0.360139 train = 0.878711 valid = 0.764216\n",
            "2022-01-09 15:19:24 - INFO:\ttrain #1240 lr = 8.83e-05 loss = 0.346653 train = 0.883984 valid = 0.769903\n",
            "2022-01-09 15:19:52 - INFO:\ttrain #1250 lr = 8.82e-05 loss = 0.336798 train = 0.886523 valid = 0.770106\n",
            "2022-01-09 15:20:20 - INFO:\ttrain #1260 lr = 8.82e-05 loss = 0.337463 train = 0.887109 valid = 0.758733\n",
            "2022-01-09 15:20:49 - INFO:\ttrain #1270 lr = 8.81e-05 loss = 0.337816 train = 0.883398 valid = 0.748578\n",
            "2022-01-09 15:21:17 - INFO:\ttrain #1280 lr = 8.80e-05 loss = 0.354668 train = 0.882422 valid = 0.755890\n",
            "2022-01-09 15:21:45 - INFO:\ttrain #1290 lr = 8.79e-05 loss = 0.361724 train = 0.880273 valid = 0.765028\n",
            "2022-01-09 15:22:13 - INFO:\ttrain #1300 lr = 8.78e-05 loss = 0.361052 train = 0.876367 valid = 0.772746 updated\n",
            "2022-01-09 15:22:17 - INFO:\tSaved test = 0.773096\n",
            "2022-01-09 15:22:45 - INFO:\ttrain #1310 lr = 8.77e-05 loss = 0.314064 train = 0.896875 valid = 0.750609\n",
            "2022-01-09 15:23:14 - INFO:\ttrain #1320 lr = 8.76e-05 loss = 0.344511 train = 0.886133 valid = 0.779854 updated\n",
            "2022-01-09 15:23:42 - INFO:\ttrain #1330 lr = 8.75e-05 loss = 0.340617 train = 0.887109 valid = 0.775995\n",
            "2022-01-09 15:24:10 - INFO:\ttrain #1340 lr = 8.75e-05 loss = 0.320885 train = 0.893359 valid = 0.758733\n",
            "2022-01-09 15:24:38 - INFO:\ttrain #1350 lr = 8.74e-05 loss = 0.335378 train = 0.887891 valid = 0.757108\n",
            "2022-01-09 15:25:06 - INFO:\ttrain #1360 lr = 8.73e-05 loss = 0.335434 train = 0.890430 valid = 0.779041\n",
            "2022-01-09 15:25:34 - INFO:\ttrain #1370 lr = 8.72e-05 loss = 0.332553 train = 0.891602 valid = 0.777620\n",
            "2022-01-09 15:26:02 - INFO:\ttrain #1380 lr = 8.71e-05 loss = 0.329646 train = 0.890039 valid = 0.767262\n",
            "2022-01-09 15:26:30 - INFO:\ttrain #1390 lr = 8.70e-05 loss = 0.308641 train = 0.899414 valid = 0.774980\n",
            "2022-01-09 15:26:59 - INFO:\ttrain #1400 lr = 8.69e-05 loss = 0.311674 train = 0.893555 valid = 0.776401\n",
            "2022-01-09 15:27:02 - INFO:\tSaved test = 0.767018\n",
            "2022-01-09 15:27:30 - INFO:\ttrain #1410 lr = 8.68e-05 loss = 0.303879 train = 0.896484 valid = 0.745126\n",
            "2022-01-09 15:27:58 - INFO:\ttrain #1420 lr = 8.68e-05 loss = 0.321973 train = 0.894922 valid = 0.775183\n",
            "2022-01-09 15:28:26 - INFO:\ttrain #1430 lr = 8.67e-05 loss = 0.324977 train = 0.891406 valid = 0.774980\n",
            "2022-01-09 15:28:55 - INFO:\ttrain #1440 lr = 8.66e-05 loss = 0.301790 train = 0.898633 valid = 0.778838\n",
            "2022-01-09 15:29:23 - INFO:\ttrain #1450 lr = 8.65e-05 loss = 0.296666 train = 0.901367 valid = 0.747969\n",
            "2022-01-09 15:29:51 - INFO:\ttrain #1460 lr = 8.64e-05 loss = 0.274890 train = 0.911719 valid = 0.779448\n",
            "2022-01-09 15:30:19 - INFO:\ttrain #1470 lr = 8.63e-05 loss = 0.295356 train = 0.902148 valid = 0.765841\n",
            "2022-01-09 15:30:47 - INFO:\ttrain #1480 lr = 8.62e-05 loss = 0.318276 train = 0.890820 valid = 0.752031\n",
            "2022-01-09 15:31:15 - INFO:\ttrain #1490 lr = 8.62e-05 loss = 0.284125 train = 0.905469 valid = 0.777011\n",
            "2022-01-09 15:31:44 - INFO:\ttrain #1500 lr = 8.61e-05 loss = 0.306644 train = 0.898242 valid = 0.772746\n",
            "2022-01-09 15:31:47 - INFO:\tSaved test = 0.788493\n",
            "2022-01-09 15:32:16 - INFO:\ttrain #1510 lr = 8.60e-05 loss = 0.308172 train = 0.896680 valid = 0.768278\n",
            "2022-01-09 15:32:44 - INFO:\ttrain #1520 lr = 8.59e-05 loss = 0.303223 train = 0.897461 valid = 0.774574\n",
            "2022-01-09 15:33:12 - INFO:\ttrain #1530 lr = 8.58e-05 loss = 0.291181 train = 0.904102 valid = 0.785946 updated\n",
            "2022-01-09 15:33:40 - INFO:\ttrain #1540 lr = 8.57e-05 loss = 0.294275 train = 0.897656 valid = 0.774167\n",
            "2022-01-09 15:34:08 - INFO:\ttrain #1550 lr = 8.56e-05 loss = 0.289690 train = 0.903711 valid = 0.773761\n",
            "2022-01-09 15:34:37 - INFO:\ttrain #1560 lr = 8.56e-05 loss = 0.287613 train = 0.904883 valid = 0.786353 updated\n",
            "2022-01-09 15:35:05 - INFO:\ttrain #1570 lr = 8.55e-05 loss = 0.286798 train = 0.908008 valid = 0.782697\n",
            "2022-01-09 15:35:33 - INFO:\ttrain #1580 lr = 8.54e-05 loss = 0.265419 train = 0.911719 valid = 0.772746\n",
            "2022-01-09 15:36:01 - INFO:\ttrain #1590 lr = 8.53e-05 loss = 0.286778 train = 0.904883 valid = 0.760561\n",
            "2022-01-09 15:36:30 - INFO:\ttrain #1600 lr = 8.52e-05 loss = 0.267790 train = 0.909766 valid = 0.762591\n",
            "2022-01-09 15:36:33 - INFO:\tSaved test = 0.749190\n",
            "2022-01-09 15:37:01 - INFO:\ttrain #1610 lr = 8.51e-05 loss = 0.276485 train = 0.903125 valid = 0.774574\n",
            "2022-01-09 15:37:29 - INFO:\ttrain #1620 lr = 8.50e-05 loss = 0.285214 train = 0.903711 valid = 0.784322\n",
            "2022-01-09 15:37:57 - INFO:\ttrain #1630 lr = 8.50e-05 loss = 0.261104 train = 0.910547 valid = 0.793867 updated\n",
            "2022-01-09 15:38:26 - INFO:\ttrain #1640 lr = 8.49e-05 loss = 0.280654 train = 0.902930 valid = 0.781682\n",
            "2022-01-09 15:38:54 - INFO:\ttrain #1650 lr = 8.48e-05 loss = 0.278597 train = 0.904102 valid = 0.788993\n",
            "2022-01-09 15:39:22 - INFO:\ttrain #1660 lr = 8.47e-05 loss = 0.254236 train = 0.914648 valid = 0.790211\n",
            "2022-01-09 15:39:50 - INFO:\ttrain #1670 lr = 8.46e-05 loss = 0.241613 train = 0.923047 valid = 0.786759\n",
            "2022-01-09 15:40:18 - INFO:\ttrain #1680 lr = 8.45e-05 loss = 0.254957 train = 0.910547 valid = 0.756296\n",
            "2022-01-09 15:40:46 - INFO:\ttrain #1690 lr = 8.45e-05 loss = 0.266872 train = 0.908594 valid = 0.759342\n",
            "2022-01-09 15:41:15 - INFO:\ttrain #1700 lr = 8.44e-05 loss = 0.273970 train = 0.908594 valid = 0.770106\n",
            "2022-01-09 15:41:18 - INFO:\tSaved test = 0.775932\n",
            "2022-01-09 15:41:46 - INFO:\ttrain #1710 lr = 8.43e-05 loss = 0.250037 train = 0.919141 valid = 0.781478\n",
            "2022-01-09 15:42:15 - INFO:\ttrain #1720 lr = 8.42e-05 loss = 0.280631 train = 0.905273 valid = 0.776198\n",
            "2022-01-09 15:42:43 - INFO:\ttrain #1730 lr = 8.41e-05 loss = 0.264685 train = 0.910742 valid = 0.785540\n",
            "2022-01-09 15:43:11 - INFO:\ttrain #1740 lr = 8.40e-05 loss = 0.249641 train = 0.917969 valid = 0.782291\n",
            "2022-01-09 15:43:39 - INFO:\ttrain #1750 lr = 8.39e-05 loss = 0.256541 train = 0.909766 valid = 0.778635\n",
            "2022-01-09 15:44:07 - INFO:\ttrain #1760 lr = 8.39e-05 loss = 0.233419 train = 0.923438 valid = 0.788383\n",
            "2022-01-09 15:44:35 - INFO:\ttrain #1770 lr = 8.38e-05 loss = 0.265730 train = 0.910937 valid = 0.780666\n",
            "2022-01-09 15:45:03 - INFO:\ttrain #1780 lr = 8.37e-05 loss = 0.268875 train = 0.908594 valid = 0.781275\n",
            "2022-01-09 15:45:31 - INFO:\ttrain #1790 lr = 8.36e-05 loss = 0.253839 train = 0.915039 valid = 0.795695 updated\n",
            "2022-01-09 15:45:59 - INFO:\ttrain #1800 lr = 8.35e-05 loss = 0.253662 train = 0.916797 valid = 0.795898 updated\n",
            "2022-01-09 15:46:03 - INFO:\tSaved test = 0.789708\n",
            "2022-01-09 15:46:31 - INFO:\ttrain #1810 lr = 8.34e-05 loss = 0.229215 train = 0.927148 valid = 0.767059\n",
            "2022-01-09 15:46:59 - INFO:\ttrain #1820 lr = 8.34e-05 loss = 0.267041 train = 0.910742 valid = 0.785946\n",
            "2022-01-09 15:47:27 - INFO:\ttrain #1830 lr = 8.33e-05 loss = 0.244045 train = 0.919141 valid = 0.779041\n",
            "2022-01-09 15:47:55 - INFO:\ttrain #1840 lr = 8.32e-05 loss = 0.243366 train = 0.917773 valid = 0.770918\n",
            "2022-01-09 15:48:24 - INFO:\ttrain #1850 lr = 8.31e-05 loss = 0.259688 train = 0.915234 valid = 0.790820\n",
            "2022-01-09 15:48:52 - INFO:\ttrain #1860 lr = 8.30e-05 loss = 0.251964 train = 0.919141 valid = 0.795695\n",
            "2022-01-09 15:49:20 - INFO:\ttrain #1870 lr = 8.29e-05 loss = 0.221242 train = 0.925977 valid = 0.789399\n",
            "2022-01-09 15:49:48 - INFO:\ttrain #1880 lr = 8.29e-05 loss = 0.228960 train = 0.921094 valid = 0.785540\n",
            "2022-01-09 15:50:16 - INFO:\ttrain #1890 lr = 8.28e-05 loss = 0.242099 train = 0.916016 valid = 0.779854\n",
            "2022-01-09 15:50:44 - INFO:\ttrain #1900 lr = 8.27e-05 loss = 0.210255 train = 0.928906 valid = 0.780666\n",
            "2022-01-09 15:50:48 - INFO:\tSaved test = 0.775932\n",
            "2022-01-09 15:51:16 - INFO:\ttrain #1910 lr = 8.26e-05 loss = 0.238199 train = 0.918164 valid = 0.748578\n",
            "2022-01-09 15:51:44 - INFO:\ttrain #1920 lr = 8.25e-05 loss = 0.241983 train = 0.915625 valid = 0.796913 updated\n",
            "2022-01-09 15:52:13 - INFO:\ttrain #1930 lr = 8.24e-05 loss = 0.231746 train = 0.922070 valid = 0.782697\n",
            "2022-01-09 15:52:41 - INFO:\ttrain #1940 lr = 8.24e-05 loss = 0.210630 train = 0.932422 valid = 0.798132 updated\n",
            "2022-01-09 15:53:09 - INFO:\ttrain #1950 lr = 8.23e-05 loss = 0.225842 train = 0.926758 valid = 0.775386\n",
            "2022-01-09 15:53:37 - INFO:\ttrain #1960 lr = 8.22e-05 loss = 0.228506 train = 0.923047 valid = 0.788993\n",
            "2022-01-09 15:54:06 - INFO:\ttrain #1970 lr = 8.21e-05 loss = 0.231752 train = 0.920508 valid = 0.795491\n",
            "2022-01-09 15:54:34 - INFO:\ttrain #1980 lr = 8.20e-05 loss = 0.211987 train = 0.930664 valid = 0.785337\n",
            "2022-01-09 15:55:02 - INFO:\ttrain #1990 lr = 8.20e-05 loss = 0.213130 train = 0.930664 valid = 0.785946\n",
            "2022-01-09 15:55:30 - INFO:\ttrain #2000 lr = 8.19e-05 loss = 0.215788 train = 0.930273 valid = 0.790211\n",
            "2022-01-09 15:55:34 - INFO:\tSaved test = 0.796596\n",
            "2022-01-09 15:56:02 - INFO:\ttrain #2010 lr = 8.18e-05 loss = 0.216291 train = 0.927148 valid = 0.797725\n",
            "2022-01-09 15:56:30 - INFO:\ttrain #2020 lr = 8.17e-05 loss = 0.222388 train = 0.923828 valid = 0.776807\n",
            "2022-01-09 15:56:59 - INFO:\ttrain #2030 lr = 8.16e-05 loss = 0.226542 train = 0.921484 valid = 0.784119\n",
            "2022-01-09 15:57:27 - INFO:\ttrain #2040 lr = 8.15e-05 loss = 0.236128 train = 0.921094 valid = 0.760561\n",
            "2022-01-09 15:57:55 - INFO:\ttrain #2050 lr = 8.15e-05 loss = 0.231593 train = 0.925195 valid = 0.788383\n",
            "2022-01-09 15:58:23 - INFO:\ttrain #2060 lr = 8.14e-05 loss = 0.223905 train = 0.927539 valid = 0.773355\n",
            "2022-01-09 15:58:51 - INFO:\ttrain #2070 lr = 8.13e-05 loss = 0.209182 train = 0.927734 valid = 0.795085\n",
            "2022-01-09 15:59:19 - INFO:\ttrain #2080 lr = 8.12e-05 loss = 0.214006 train = 0.926367 valid = 0.781682\n",
            "2022-01-09 15:59:47 - INFO:\ttrain #2090 lr = 8.11e-05 loss = 0.222197 train = 0.924219 valid = 0.769090\n",
            "2022-01-09 16:00:16 - INFO:\ttrain #2100 lr = 8.11e-05 loss = 0.232182 train = 0.923633 valid = 0.777417\n",
            "2022-01-09 16:00:19 - INFO:\tSaved test = 0.771475\n",
            "2022-01-09 16:00:47 - INFO:\ttrain #2110 lr = 8.10e-05 loss = 0.203018 train = 0.929297 valid = 0.795085\n",
            "2022-01-09 16:01:15 - INFO:\ttrain #2120 lr = 8.09e-05 loss = 0.208480 train = 0.927344 valid = 0.778026\n",
            "2022-01-09 16:01:43 - INFO:\ttrain #2130 lr = 8.08e-05 loss = 0.199644 train = 0.934570 valid = 0.787368\n",
            "2022-01-09 16:02:11 - INFO:\ttrain #2140 lr = 8.07e-05 loss = 0.203313 train = 0.933008 valid = 0.785540\n",
            "2022-01-09 16:02:40 - INFO:\ttrain #2150 lr = 8.07e-05 loss = 0.197564 train = 0.935352 valid = 0.785134\n",
            "2022-01-09 16:03:08 - INFO:\ttrain #2160 lr = 8.06e-05 loss = 0.193387 train = 0.935547 valid = 0.792039\n",
            "2022-01-09 16:03:36 - INFO:\ttrain #2170 lr = 8.05e-05 loss = 0.214008 train = 0.928906 valid = 0.771527\n",
            "2022-01-09 16:04:04 - INFO:\ttrain #2180 lr = 8.04e-05 loss = 0.216502 train = 0.926562 valid = 0.784322\n",
            "2022-01-09 16:04:32 - INFO:\ttrain #2190 lr = 8.03e-05 loss = 0.200897 train = 0.930273 valid = 0.801178 updated\n",
            "2022-01-09 16:05:01 - INFO:\ttrain #2200 lr = 8.03e-05 loss = 0.207512 train = 0.930469 valid = 0.789399\n",
            "2022-01-09 16:05:04 - INFO:\tSaved test = 0.779173\n",
            "2022-01-09 16:05:32 - INFO:\ttrain #2210 lr = 8.02e-05 loss = 0.191144 train = 0.935352 valid = 0.795898\n",
            "2022-01-09 16:06:01 - INFO:\ttrain #2220 lr = 8.01e-05 loss = 0.185791 train = 0.936133 valid = 0.781072\n",
            "2022-01-09 16:06:29 - INFO:\ttrain #2230 lr = 8.00e-05 loss = 0.189523 train = 0.935742 valid = 0.800975\n",
            "2022-01-09 16:06:57 - INFO:\ttrain #2240 lr = 7.99e-05 loss = 0.180227 train = 0.939063 valid = 0.782088\n",
            "2022-01-09 16:07:25 - INFO:\ttrain #2250 lr = 7.99e-05 loss = 0.181954 train = 0.939258 valid = 0.772136\n",
            "2022-01-09 16:07:53 - INFO:\ttrain #2260 lr = 7.98e-05 loss = 0.192343 train = 0.934375 valid = 0.796101\n",
            "2022-01-09 16:08:21 - INFO:\ttrain #2270 lr = 7.97e-05 loss = 0.200030 train = 0.932813 valid = 0.788587\n",
            "2022-01-09 16:08:50 - INFO:\ttrain #2280 lr = 7.96e-05 loss = 0.213529 train = 0.928711 valid = 0.796913\n",
            "2022-01-09 16:09:18 - INFO:\ttrain #2290 lr = 7.95e-05 loss = 0.206531 train = 0.929688 valid = 0.791024\n",
            "2022-01-09 16:09:46 - INFO:\ttrain #2300 lr = 7.95e-05 loss = 0.180628 train = 0.938867 valid = 0.779448\n",
            "2022-01-09 16:09:50 - INFO:\tSaved test = 0.785251\n",
            "2022-01-09 16:10:18 - INFO:\ttrain #2310 lr = 7.94e-05 loss = 0.167783 train = 0.944336 valid = 0.789602\n",
            "2022-01-09 16:10:46 - INFO:\ttrain #2320 lr = 7.93e-05 loss = 0.175339 train = 0.945508 valid = 0.795898\n",
            "2022-01-09 16:11:14 - INFO:\ttrain #2330 lr = 7.92e-05 loss = 0.168521 train = 0.942187 valid = 0.782291\n",
            "2022-01-09 16:11:43 - INFO:\ttrain #2340 lr = 7.91e-05 loss = 0.180154 train = 0.939648 valid = 0.790820\n",
            "2022-01-09 16:12:11 - INFO:\ttrain #2350 lr = 7.91e-05 loss = 0.183457 train = 0.936914 valid = 0.778635\n",
            "2022-01-09 16:12:39 - INFO:\ttrain #2360 lr = 7.90e-05 loss = 0.182540 train = 0.941016 valid = 0.796304\n",
            "2022-01-09 16:13:07 - INFO:\ttrain #2370 lr = 7.89e-05 loss = 0.181779 train = 0.940234 valid = 0.804224 updated\n",
            "2022-01-09 16:13:35 - INFO:\ttrain #2380 lr = 7.88e-05 loss = 0.186671 train = 0.936914 valid = 0.802396\n",
            "2022-01-09 16:14:03 - INFO:\ttrain #2390 lr = 7.87e-05 loss = 0.185556 train = 0.938281 valid = 0.788993\n",
            "2022-01-09 16:14:31 - INFO:\ttrain #2400 lr = 7.87e-05 loss = 0.173365 train = 0.943164 valid = 0.799553\n",
            "2022-01-09 16:14:35 - INFO:\tSaved test = 0.788088\n",
            "2022-01-09 16:15:03 - INFO:\ttrain #2410 lr = 7.86e-05 loss = 0.201246 train = 0.929492 valid = 0.791024\n",
            "2022-01-09 16:15:32 - INFO:\ttrain #2420 lr = 7.85e-05 loss = 0.178494 train = 0.939648 valid = 0.790414\n",
            "2022-01-09 16:16:00 - INFO:\ttrain #2430 lr = 7.84e-05 loss = 0.178692 train = 0.941602 valid = 0.802803\n",
            "2022-01-09 16:16:28 - INFO:\ttrain #2440 lr = 7.83e-05 loss = 0.185874 train = 0.938281 valid = 0.797116\n",
            "2022-01-09 16:16:56 - INFO:\ttrain #2450 lr = 7.83e-05 loss = 0.182265 train = 0.937109 valid = 0.790617\n",
            "2022-01-09 16:17:24 - INFO:\ttrain #2460 lr = 7.82e-05 loss = 0.176398 train = 0.940430 valid = 0.790414\n",
            "2022-01-09 16:17:52 - INFO:\ttrain #2470 lr = 7.81e-05 loss = 0.172874 train = 0.944141 valid = 0.788180\n",
            "2022-01-09 16:18:21 - INFO:\ttrain #2480 lr = 7.80e-05 loss = 0.170506 train = 0.939453 valid = 0.792445\n",
            "2022-01-09 16:18:49 - INFO:\ttrain #2490 lr = 7.80e-05 loss = 0.168804 train = 0.941797 valid = 0.792445\n",
            "2022-01-09 16:19:17 - INFO:\ttrain #2500 lr = 7.79e-05 loss = 0.163680 train = 0.944336 valid = 0.763201\n",
            "2022-01-09 16:19:21 - INFO:\tSaved test = 0.754457\n",
            "2022-01-09 16:19:49 - INFO:\ttrain #2510 lr = 7.78e-05 loss = 0.191883 train = 0.937500 valid = 0.783509\n",
            "2022-01-09 16:20:17 - INFO:\ttrain #2520 lr = 7.77e-05 loss = 0.188710 train = 0.936523 valid = 0.785337\n",
            "2022-01-09 16:20:45 - INFO:\ttrain #2530 lr = 7.76e-05 loss = 0.165201 train = 0.947266 valid = 0.792648\n",
            "2022-01-09 16:21:13 - INFO:\ttrain #2540 lr = 7.76e-05 loss = 0.166380 train = 0.942578 valid = 0.796710\n",
            "2022-01-09 16:21:42 - INFO:\ttrain #2550 lr = 7.75e-05 loss = 0.154552 train = 0.948438 valid = 0.788993\n",
            "2022-01-09 16:22:10 - INFO:\ttrain #2560 lr = 7.74e-05 loss = 0.160108 train = 0.943750 valid = 0.790008\n",
            "2022-01-09 16:22:38 - INFO:\ttrain #2570 lr = 7.73e-05 loss = 0.177439 train = 0.939258 valid = 0.799553\n",
            "2022-01-09 16:23:06 - INFO:\ttrain #2580 lr = 7.73e-05 loss = 0.176527 train = 0.939648 valid = 0.792851\n",
            "2022-01-09 16:23:34 - INFO:\ttrain #2590 lr = 7.72e-05 loss = 0.175519 train = 0.939648 valid = 0.790617\n",
            "2022-01-09 16:24:03 - INFO:\ttrain #2600 lr = 7.71e-05 loss = 0.177238 train = 0.940625 valid = 0.799553\n",
            "2022-01-09 16:24:06 - INFO:\tSaved test = 0.786062\n",
            "2022-01-09 16:24:34 - INFO:\ttrain #2610 lr = 7.70e-05 loss = 0.157834 train = 0.947070 valid = 0.798335\n",
            "2022-01-09 16:25:03 - INFO:\ttrain #2620 lr = 7.70e-05 loss = 0.171681 train = 0.943164 valid = 0.802193\n",
            "2022-01-09 16:25:31 - INFO:\ttrain #2630 lr = 7.69e-05 loss = 0.175532 train = 0.940820 valid = 0.796304\n",
            "2022-01-09 16:25:59 - INFO:\ttrain #2640 lr = 7.68e-05 loss = 0.168025 train = 0.946094 valid = 0.802803\n",
            "2022-01-09 16:26:27 - INFO:\ttrain #2650 lr = 7.67e-05 loss = 0.152584 train = 0.949219 valid = 0.800162\n",
            "2022-01-09 16:26:55 - INFO:\ttrain #2660 lr = 7.66e-05 loss = 0.146593 train = 0.951562 valid = 0.792851\n",
            "2022-01-09 16:27:23 - INFO:\ttrain #2670 lr = 7.66e-05 loss = 0.138112 train = 0.953516 valid = 0.799350\n",
            "2022-01-09 16:27:51 - INFO:\ttrain #2680 lr = 7.65e-05 loss = 0.164599 train = 0.942187 valid = 0.792648\n",
            "2022-01-09 16:28:19 - INFO:\ttrain #2690 lr = 7.64e-05 loss = 0.162817 train = 0.943164 valid = 0.803006\n",
            "2022-01-09 16:28:48 - INFO:\ttrain #2700 lr = 7.63e-05 loss = 0.157439 train = 0.948047 valid = 0.800975\n",
            "2022-01-09 16:28:51 - INFO:\tSaved test = 0.791734\n",
            "2022-01-09 16:29:19 - INFO:\ttrain #2710 lr = 7.63e-05 loss = 0.170714 train = 0.944727 valid = 0.803006\n",
            "2022-01-09 16:29:48 - INFO:\ttrain #2720 lr = 7.62e-05 loss = 0.163431 train = 0.945312 valid = 0.784119\n",
            "2022-01-09 16:30:16 - INFO:\ttrain #2730 lr = 7.61e-05 loss = 0.163250 train = 0.944141 valid = 0.796710\n",
            "2022-01-09 16:30:44 - INFO:\ttrain #2740 lr = 7.60e-05 loss = 0.169322 train = 0.943750 valid = 0.796913\n",
            "2022-01-09 16:31:12 - INFO:\ttrain #2750 lr = 7.60e-05 loss = 0.166599 train = 0.945117 valid = 0.757920\n",
            "2022-01-09 16:31:41 - INFO:\ttrain #2760 lr = 7.59e-05 loss = 0.152841 train = 0.949805 valid = 0.803615\n",
            "2022-01-09 16:32:09 - INFO:\ttrain #2770 lr = 7.58e-05 loss = 0.143974 train = 0.950781 valid = 0.801178\n",
            "2022-01-09 16:32:37 - INFO:\ttrain #2780 lr = 7.57e-05 loss = 0.147310 train = 0.950000 valid = 0.789196\n",
            "2022-01-09 16:33:05 - INFO:\ttrain #2790 lr = 7.57e-05 loss = 0.141475 train = 0.953906 valid = 0.805240 updated\n",
            "2022-01-09 16:33:33 - INFO:\ttrain #2800 lr = 7.56e-05 loss = 0.149077 train = 0.947461 valid = 0.799553\n",
            "2022-01-09 16:33:37 - INFO:\tSaved test = 0.782820\n",
            "2022-01-09 16:34:05 - INFO:\ttrain #2810 lr = 7.55e-05 loss = 0.155860 train = 0.943945 valid = 0.804021\n",
            "2022-01-09 16:34:33 - INFO:\ttrain #2820 lr = 7.54e-05 loss = 0.143882 train = 0.950000 valid = 0.779651\n",
            "2022-01-09 16:35:02 - INFO:\ttrain #2830 lr = 7.54e-05 loss = 0.145242 train = 0.950391 valid = 0.792445\n",
            "2022-01-09 16:35:30 - INFO:\ttrain #2840 lr = 7.53e-05 loss = 0.141409 train = 0.953125 valid = 0.801990\n",
            "2022-01-09 16:35:58 - INFO:\ttrain #2850 lr = 7.52e-05 loss = 0.162594 train = 0.941406 valid = 0.795085\n",
            "2022-01-09 16:36:26 - INFO:\ttrain #2860 lr = 7.51e-05 loss = 0.161837 train = 0.940430 valid = 0.777214\n",
            "2022-01-09 16:36:54 - INFO:\ttrain #2870 lr = 7.51e-05 loss = 0.158183 train = 0.948633 valid = 0.796101\n",
            "2022-01-09 16:37:23 - INFO:\ttrain #2880 lr = 7.50e-05 loss = 0.158841 train = 0.947852 valid = 0.785743\n",
            "2022-01-09 16:37:51 - INFO:\ttrain #2890 lr = 7.49e-05 loss = 0.153985 train = 0.949414 valid = 0.806661 updated\n",
            "2022-01-09 16:38:19 - INFO:\ttrain #2900 lr = 7.48e-05 loss = 0.152651 train = 0.949609 valid = 0.794679\n",
            "2022-01-09 16:38:23 - INFO:\tSaved test = 0.779173\n",
            "2022-01-09 16:38:51 - INFO:\ttrain #2910 lr = 7.48e-05 loss = 0.140949 train = 0.952344 valid = 0.799147\n",
            "2022-01-09 16:39:19 - INFO:\ttrain #2920 lr = 7.47e-05 loss = 0.138802 train = 0.954102 valid = 0.792648\n",
            "2022-01-09 16:39:47 - INFO:\ttrain #2930 lr = 7.46e-05 loss = 0.157471 train = 0.946680 valid = 0.803615\n",
            "2022-01-09 16:40:15 - INFO:\ttrain #2940 lr = 7.45e-05 loss = 0.161949 train = 0.947266 valid = 0.809301 updated\n",
            "2022-01-09 16:40:44 - INFO:\ttrain #2950 lr = 7.45e-05 loss = 0.133540 train = 0.956250 valid = 0.794882\n",
            "2022-01-09 16:41:12 - INFO:\ttrain #2960 lr = 7.44e-05 loss = 0.145075 train = 0.950195 valid = 0.797929\n",
            "2022-01-09 16:41:40 - INFO:\ttrain #2970 lr = 7.43e-05 loss = 0.149252 train = 0.950977 valid = 0.804630\n",
            "2022-01-09 16:42:08 - INFO:\ttrain #2980 lr = 7.42e-05 loss = 0.147238 train = 0.951367 valid = 0.793664\n",
            "2022-01-09 16:42:37 - INFO:\ttrain #2990 lr = 7.42e-05 loss = 0.133480 train = 0.957031 valid = 0.795695\n",
            "2022-01-09 16:43:05 - INFO:\ttrain #3000 lr = 7.41e-05 loss = 0.134336 train = 0.955078 valid = 0.813160 updated\n",
            "2022-01-09 16:43:09 - INFO:\tSaved test = 0.791734\n",
            "2022-01-09 16:43:37 - INFO:\ttrain #3010 lr = 7.40e-05 loss = 0.139669 train = 0.952539 valid = 0.803615\n",
            "2022-01-09 16:44:05 - INFO:\ttrain #3020 lr = 7.39e-05 loss = 0.151889 train = 0.947266 valid = 0.796913\n",
            "2022-01-09 16:44:33 - INFO:\ttrain #3030 lr = 7.39e-05 loss = 0.142613 train = 0.953516 valid = 0.796101\n",
            "2022-01-09 16:45:01 - INFO:\ttrain #3040 lr = 7.38e-05 loss = 0.155156 train = 0.946094 valid = 0.802193\n",
            "2022-01-09 16:45:30 - INFO:\ttrain #3050 lr = 7.37e-05 loss = 0.134162 train = 0.955273 valid = 0.792445\n",
            "2022-01-09 16:45:58 - INFO:\ttrain #3060 lr = 7.36e-05 loss = 0.138532 train = 0.951953 valid = 0.785946\n",
            "2022-01-09 16:46:26 - INFO:\ttrain #3070 lr = 7.36e-05 loss = 0.143190 train = 0.950977 valid = 0.794476\n",
            "2022-01-09 16:46:54 - INFO:\ttrain #3080 lr = 7.35e-05 loss = 0.143538 train = 0.951758 valid = 0.801178\n",
            "2022-01-09 16:47:22 - INFO:\ttrain #3090 lr = 7.34e-05 loss = 0.145833 train = 0.950586 valid = 0.801990\n",
            "2022-01-09 16:47:50 - INFO:\ttrain #3100 lr = 7.33e-05 loss = 0.137172 train = 0.955078 valid = 0.808083\n",
            "2022-01-09 16:47:54 - INFO:\tSaved test = 0.788898\n",
            "2022-01-09 16:48:22 - INFO:\ttrain #3110 lr = 7.33e-05 loss = 0.137168 train = 0.952539 valid = 0.805849\n",
            "2022-01-09 16:48:50 - INFO:\ttrain #3120 lr = 7.32e-05 loss = 0.134202 train = 0.952930 valid = 0.794476\n",
            "2022-01-09 16:49:18 - INFO:\ttrain #3130 lr = 7.31e-05 loss = 0.150665 train = 0.947656 valid = 0.792851\n",
            "2022-01-09 16:49:47 - INFO:\ttrain #3140 lr = 7.31e-05 loss = 0.147043 train = 0.948438 valid = 0.806864\n",
            "2022-01-09 16:50:15 - INFO:\ttrain #3150 lr = 7.30e-05 loss = 0.121707 train = 0.957812 valid = 0.803615\n",
            "2022-01-09 16:50:42 - INFO:\ttrain #3160 lr = 7.29e-05 loss = 0.132436 train = 0.955273 valid = 0.804427\n",
            "2022-01-09 16:51:11 - INFO:\ttrain #3170 lr = 7.28e-05 loss = 0.128395 train = 0.957227 valid = 0.787165\n",
            "2022-01-09 16:51:39 - INFO:\ttrain #3180 lr = 7.28e-05 loss = 0.135127 train = 0.952734 valid = 0.793461\n",
            "2022-01-09 16:52:07 - INFO:\ttrain #3190 lr = 7.27e-05 loss = 0.130947 train = 0.955469 valid = 0.803615\n",
            "2022-01-09 16:52:35 - INFO:\ttrain #3200 lr = 7.26e-05 loss = 0.139435 train = 0.953125 valid = 0.798944\n",
            "2022-01-09 16:52:39 - INFO:\tSaved test = 0.788898\n",
            "2022-01-09 16:53:07 - INFO:\ttrain #3210 lr = 7.25e-05 loss = 0.140448 train = 0.954688 valid = 0.796507\n",
            "2022-01-09 16:53:35 - INFO:\ttrain #3220 lr = 7.25e-05 loss = 0.122814 train = 0.958008 valid = 0.795695\n",
            "2022-01-09 16:54:03 - INFO:\ttrain #3230 lr = 7.24e-05 loss = 0.123758 train = 0.957422 valid = 0.806661\n",
            "2022-01-09 16:54:32 - INFO:\ttrain #3240 lr = 7.23e-05 loss = 0.128877 train = 0.956836 valid = 0.802600\n",
            "2022-01-09 16:55:00 - INFO:\ttrain #3250 lr = 7.23e-05 loss = 0.134522 train = 0.954688 valid = 0.798741\n",
            "2022-01-09 16:55:28 - INFO:\ttrain #3260 lr = 7.22e-05 loss = 0.133398 train = 0.955078 valid = 0.797522\n",
            "2022-01-09 16:55:56 - INFO:\ttrain #3270 lr = 7.21e-05 loss = 0.125780 train = 0.958789 valid = 0.802396\n",
            "2022-01-09 16:56:24 - INFO:\ttrain #3280 lr = 7.20e-05 loss = 0.123524 train = 0.958398 valid = 0.808692\n",
            "2022-01-09 16:56:52 - INFO:\ttrain #3290 lr = 7.20e-05 loss = 0.115549 train = 0.961133 valid = 0.807067\n",
            "2022-01-09 16:57:20 - INFO:\ttrain #3300 lr = 7.19e-05 loss = 0.123134 train = 0.958789 valid = 0.808286\n",
            "2022-01-09 16:57:24 - INFO:\tSaved test = 0.809157\n",
            "2022-01-09 16:57:52 - INFO:\ttrain #3310 lr = 7.18e-05 loss = 0.126880 train = 0.958594 valid = 0.793258\n",
            "2022-01-09 16:58:20 - INFO:\ttrain #3320 lr = 7.17e-05 loss = 0.140355 train = 0.953516 valid = 0.798741\n",
            "2022-01-09 16:58:49 - INFO:\ttrain #3330 lr = 7.17e-05 loss = 0.124749 train = 0.959375 valid = 0.782291\n",
            "2022-01-09 16:59:17 - INFO:\ttrain #3340 lr = 7.16e-05 loss = 0.123390 train = 0.957422 valid = 0.806661\n",
            "2022-01-09 16:59:45 - INFO:\ttrain #3350 lr = 7.15e-05 loss = 0.119437 train = 0.959570 valid = 0.803818\n",
            "2022-01-09 17:00:13 - INFO:\ttrain #3360 lr = 7.15e-05 loss = 0.132369 train = 0.955859 valid = 0.796507\n",
            "2022-01-09 17:00:41 - INFO:\ttrain #3370 lr = 7.14e-05 loss = 0.129767 train = 0.957227 valid = 0.798538\n",
            "2022-01-09 17:01:10 - INFO:\ttrain #3380 lr = 7.13e-05 loss = 0.114687 train = 0.959570 valid = 0.802396\n",
            "2022-01-09 17:01:38 - INFO:\ttrain #3390 lr = 7.12e-05 loss = 0.127431 train = 0.959570 valid = 0.782900\n",
            "2022-01-09 17:02:06 - INFO:\ttrain #3400 lr = 7.12e-05 loss = 0.113788 train = 0.961523 valid = 0.800975\n",
            "2022-01-09 17:02:10 - INFO:\tSaved test = 0.790113\n",
            "2022-01-09 17:02:38 - INFO:\ttrain #3410 lr = 7.11e-05 loss = 0.127180 train = 0.958398 valid = 0.799147\n",
            "2022-01-09 17:03:06 - INFO:\ttrain #3420 lr = 7.10e-05 loss = 0.117885 train = 0.959961 valid = 0.810317\n",
            "2022-01-09 17:03:34 - INFO:\ttrain #3430 lr = 7.10e-05 loss = 0.114791 train = 0.961133 valid = 0.803412\n",
            "2022-01-09 17:04:02 - INFO:\ttrain #3440 lr = 7.09e-05 loss = 0.125075 train = 0.956836 valid = 0.799553\n",
            "2022-01-09 17:04:30 - INFO:\ttrain #3450 lr = 7.08e-05 loss = 0.124007 train = 0.956641 valid = 0.803412\n",
            "2022-01-09 17:04:59 - INFO:\ttrain #3460 lr = 7.08e-05 loss = 0.120038 train = 0.958398 valid = 0.804630\n",
            "2022-01-09 17:05:27 - INFO:\ttrain #3470 lr = 7.07e-05 loss = 0.122710 train = 0.956250 valid = 0.802803\n",
            "2022-01-09 17:05:55 - INFO:\ttrain #3480 lr = 7.06e-05 loss = 0.119473 train = 0.956836 valid = 0.807474\n",
            "2022-01-09 17:06:23 - INFO:\ttrain #3490 lr = 7.05e-05 loss = 0.129161 train = 0.958008 valid = 0.804833\n",
            "2022-01-09 17:06:51 - INFO:\ttrain #3500 lr = 7.05e-05 loss = 0.119799 train = 0.957617 valid = 0.796507\n",
            "2022-01-09 17:06:55 - INFO:\tSaved test = 0.788493\n",
            "2022-01-09 17:07:23 - INFO:\ttrain #3510 lr = 7.04e-05 loss = 0.118607 train = 0.961328 valid = 0.807677\n",
            "2022-01-09 17:07:51 - INFO:\ttrain #3520 lr = 7.03e-05 loss = 0.117158 train = 0.961133 valid = 0.795695\n",
            "2022-01-09 17:08:19 - INFO:\ttrain #3530 lr = 7.03e-05 loss = 0.130926 train = 0.954102 valid = 0.791430\n",
            "2022-01-09 17:08:48 - INFO:\ttrain #3540 lr = 7.02e-05 loss = 0.116836 train = 0.958984 valid = 0.802396\n",
            "2022-01-09 17:09:16 - INFO:\ttrain #3550 lr = 7.01e-05 loss = 0.117834 train = 0.959766 valid = 0.796304\n",
            "2022-01-09 17:09:44 - INFO:\ttrain #3560 lr = 7.00e-05 loss = 0.119884 train = 0.958398 valid = 0.785946\n",
            "2022-01-09 17:10:12 - INFO:\ttrain #3570 lr = 7.00e-05 loss = 0.113920 train = 0.960938 valid = 0.797116\n",
            "2022-01-09 17:10:41 - INFO:\ttrain #3580 lr = 6.99e-05 loss = 0.105243 train = 0.965625 valid = 0.798944\n",
            "2022-01-09 17:11:09 - INFO:\ttrain #3590 lr = 6.98e-05 loss = 0.115201 train = 0.960547 valid = 0.806661\n",
            "2022-01-09 17:11:37 - INFO:\ttrain #3600 lr = 6.98e-05 loss = 0.117217 train = 0.960938 valid = 0.800772\n",
            "2022-01-09 17:11:41 - INFO:\tSaved test = 0.794976\n",
            "2022-01-09 17:12:09 - INFO:\ttrain #3610 lr = 6.97e-05 loss = 0.096084 train = 0.967773 valid = 0.807271\n",
            "2022-01-09 17:12:37 - INFO:\ttrain #3620 lr = 6.96e-05 loss = 0.117884 train = 0.960156 valid = 0.798335\n",
            "2022-01-09 17:13:05 - INFO:\ttrain #3630 lr = 6.96e-05 loss = 0.116035 train = 0.959570 valid = 0.801178\n",
            "2022-01-09 17:13:34 - INFO:\ttrain #3640 lr = 6.95e-05 loss = 0.106764 train = 0.964453 valid = 0.781682\n",
            "2022-01-09 17:14:02 - INFO:\ttrain #3650 lr = 6.94e-05 loss = 0.133331 train = 0.955469 valid = 0.794882\n",
            "2022-01-09 17:14:30 - INFO:\ttrain #3660 lr = 6.93e-05 loss = 0.126653 train = 0.955664 valid = 0.800162\n",
            "2022-01-09 17:14:58 - INFO:\ttrain #3670 lr = 6.93e-05 loss = 0.109232 train = 0.965625 valid = 0.810520\n",
            "2022-01-09 17:15:26 - INFO:\ttrain #3680 lr = 6.92e-05 loss = 0.113659 train = 0.959375 valid = 0.805646\n",
            "2022-01-09 17:15:54 - INFO:\ttrain #3690 lr = 6.91e-05 loss = 0.121811 train = 0.957812 valid = 0.792851\n",
            "2022-01-09 17:16:23 - INFO:\ttrain #3700 lr = 6.91e-05 loss = 0.132538 train = 0.954297 valid = 0.796101\n",
            "2022-01-09 17:16:26 - INFO:\tSaved test = 0.800243\n",
            "2022-01-09 17:16:54 - INFO:\ttrain #3710 lr = 6.90e-05 loss = 0.117598 train = 0.958203 valid = 0.801990\n",
            "2022-01-09 17:17:23 - INFO:\ttrain #3720 lr = 6.89e-05 loss = 0.106294 train = 0.965039 valid = 0.801584\n",
            "2022-01-09 17:17:51 - INFO:\ttrain #3730 lr = 6.89e-05 loss = 0.104418 train = 0.964648 valid = 0.816206 updated\n",
            "2022-01-09 17:18:19 - INFO:\ttrain #3740 lr = 6.88e-05 loss = 0.096479 train = 0.966211 valid = 0.814785\n",
            "2022-01-09 17:18:47 - INFO:\ttrain #3750 lr = 6.87e-05 loss = 0.108157 train = 0.961914 valid = 0.806255\n",
            "2022-01-09 17:19:15 - INFO:\ttrain #3760 lr = 6.87e-05 loss = 0.113159 train = 0.960938 valid = 0.809098\n",
            "2022-01-09 17:19:44 - INFO:\ttrain #3770 lr = 6.86e-05 loss = 0.112118 train = 0.963086 valid = 0.808489\n",
            "2022-01-09 17:20:12 - INFO:\ttrain #3780 lr = 6.85e-05 loss = 0.116354 train = 0.959570 valid = 0.806864\n",
            "2022-01-09 17:20:40 - INFO:\ttrain #3790 lr = 6.85e-05 loss = 0.097647 train = 0.967773 valid = 0.812957\n",
            "2022-01-09 17:21:08 - INFO:\ttrain #3800 lr = 6.84e-05 loss = 0.108880 train = 0.963281 valid = 0.805849\n",
            "2022-01-09 17:21:11 - INFO:\tSaved test = 0.798622\n",
            "2022-01-09 17:21:39 - INFO:\ttrain #3810 lr = 6.83e-05 loss = 0.101836 train = 0.966406 valid = 0.806255\n",
            "2022-01-09 17:22:07 - INFO:\ttrain #3820 lr = 6.82e-05 loss = 0.115234 train = 0.959961 valid = 0.799350\n",
            "2022-01-09 17:22:36 - INFO:\ttrain #3830 lr = 6.82e-05 loss = 0.098268 train = 0.969531 valid = 0.800366\n",
            "2022-01-09 17:23:04 - INFO:\ttrain #3840 lr = 6.81e-05 loss = 0.088408 train = 0.968555 valid = 0.796304\n",
            "2022-01-09 17:23:32 - INFO:\ttrain #3850 lr = 6.80e-05 loss = 0.102509 train = 0.965430 valid = 0.810114\n",
            "2022-01-09 17:24:00 - INFO:\ttrain #3860 lr = 6.80e-05 loss = 0.098000 train = 0.967773 valid = 0.806458\n",
            "2022-01-09 17:24:28 - INFO:\ttrain #3870 lr = 6.79e-05 loss = 0.105791 train = 0.962109 valid = 0.805037\n",
            "2022-01-09 17:24:57 - INFO:\ttrain #3880 lr = 6.78e-05 loss = 0.108562 train = 0.962500 valid = 0.803209\n",
            "2022-01-09 17:25:25 - INFO:\ttrain #3890 lr = 6.78e-05 loss = 0.112834 train = 0.961523 valid = 0.805037\n",
            "2022-01-09 17:25:53 - INFO:\ttrain #3900 lr = 6.77e-05 loss = 0.094982 train = 0.966211 valid = 0.801178\n",
            "2022-01-09 17:25:57 - INFO:\tSaved test = 0.803485\n",
            "2022-01-09 17:26:25 - INFO:\ttrain #3910 lr = 6.76e-05 loss = 0.107521 train = 0.960938 valid = 0.810114\n",
            "2022-01-09 17:26:53 - INFO:\ttrain #3920 lr = 6.76e-05 loss = 0.102701 train = 0.968555 valid = 0.798538\n",
            "2022-01-09 17:27:21 - INFO:\ttrain #3930 lr = 6.75e-05 loss = 0.105857 train = 0.964063 valid = 0.798335\n",
            "2022-01-09 17:27:49 - INFO:\ttrain #3940 lr = 6.74e-05 loss = 0.108678 train = 0.962695 valid = 0.788180\n",
            "2022-01-09 17:28:17 - INFO:\ttrain #3950 lr = 6.74e-05 loss = 0.112725 train = 0.962109 valid = 0.789805\n",
            "2022-01-09 17:28:45 - INFO:\ttrain #3960 lr = 6.73e-05 loss = 0.101289 train = 0.966211 valid = 0.813363\n",
            "2022-01-09 17:29:13 - INFO:\ttrain #3970 lr = 6.72e-05 loss = 0.119719 train = 0.961133 valid = 0.803615\n",
            "2022-01-09 17:29:41 - INFO:\ttrain #3980 lr = 6.72e-05 loss = 0.096374 train = 0.966016 valid = 0.811535\n",
            "2022-01-09 17:30:09 - INFO:\ttrain #3990 lr = 6.71e-05 loss = 0.098987 train = 0.964844 valid = 0.804833\n",
            "2022-01-09 17:30:37 - INFO:\ttrain #4000 lr = 6.70e-05 loss = 0.091471 train = 0.968164 valid = 0.808692\n",
            "2022-01-09 17:30:41 - INFO:\tSaved test = 0.802674\n",
            "2022-01-09 17:31:09 - INFO:\ttrain #4010 lr = 6.70e-05 loss = 0.098808 train = 0.967187 valid = 0.811129\n",
            "2022-01-09 17:31:37 - INFO:\ttrain #4020 lr = 6.69e-05 loss = 0.110324 train = 0.963086 valid = 0.810926\n",
            "2022-01-09 17:32:05 - INFO:\ttrain #4030 lr = 6.68e-05 loss = 0.112355 train = 0.962109 valid = 0.814785\n",
            "2022-01-09 17:32:34 - INFO:\ttrain #4040 lr = 6.68e-05 loss = 0.106574 train = 0.965820 valid = 0.809504\n",
            "2022-01-09 17:33:02 - INFO:\ttrain #4050 lr = 6.67e-05 loss = 0.092885 train = 0.970508 valid = 0.809301\n",
            "2022-01-09 17:33:30 - INFO:\ttrain #4060 lr = 6.66e-05 loss = 0.096190 train = 0.966406 valid = 0.805646\n",
            "2022-01-09 17:33:58 - INFO:\ttrain #4070 lr = 6.66e-05 loss = 0.098857 train = 0.968164 valid = 0.809301\n",
            "2022-01-09 17:34:26 - INFO:\ttrain #4080 lr = 6.65e-05 loss = 0.101929 train = 0.963867 valid = 0.803615\n",
            "2022-01-09 17:34:54 - INFO:\ttrain #4090 lr = 6.64e-05 loss = 0.103416 train = 0.964063 valid = 0.788790\n",
            "2022-01-09 17:35:22 - INFO:\ttrain #4100 lr = 6.64e-05 loss = 0.114771 train = 0.963086 valid = 0.799147\n",
            "2022-01-09 17:35:26 - INFO:\tSaved test = 0.784441\n",
            "2022-01-09 17:35:54 - INFO:\ttrain #4110 lr = 6.63e-05 loss = 0.094881 train = 0.968555 valid = 0.806052\n",
            "2022-01-09 17:36:22 - INFO:\ttrain #4120 lr = 6.62e-05 loss = 0.097797 train = 0.966016 valid = 0.801178\n",
            "2022-01-09 17:36:49 - INFO:\ttrain #4130 lr = 6.62e-05 loss = 0.113747 train = 0.958594 valid = 0.798741\n",
            "2022-01-09 17:37:17 - INFO:\ttrain #4140 lr = 6.61e-05 loss = 0.107594 train = 0.963672 valid = 0.801990\n",
            "2022-01-09 17:37:45 - INFO:\ttrain #4150 lr = 6.60e-05 loss = 0.092009 train = 0.968750 valid = 0.808286\n",
            "2022-01-09 17:38:14 - INFO:\ttrain #4160 lr = 6.60e-05 loss = 0.088738 train = 0.966602 valid = 0.813363\n",
            "2022-01-09 17:38:42 - INFO:\ttrain #4170 lr = 6.59e-05 loss = 0.085744 train = 0.972070 valid = 0.800569\n",
            "2022-01-09 17:39:10 - INFO:\ttrain #4180 lr = 6.58e-05 loss = 0.100782 train = 0.967969 valid = 0.803615\n",
            "2022-01-09 17:39:38 - INFO:\ttrain #4190 lr = 6.58e-05 loss = 0.096052 train = 0.966211 valid = 0.805646\n",
            "2022-01-09 17:40:06 - INFO:\ttrain #4200 lr = 6.57e-05 loss = 0.107584 train = 0.961133 valid = 0.795695\n",
            "2022-01-09 17:40:10 - INFO:\tSaved test = 0.792950\n",
            "2022-01-09 17:40:38 - INFO:\ttrain #4210 lr = 6.56e-05 loss = 0.095956 train = 0.964844 valid = 0.812145\n",
            "2022-01-09 17:41:07 - INFO:\ttrain #4220 lr = 6.56e-05 loss = 0.092915 train = 0.967578 valid = 0.816613 updated\n",
            "2022-01-09 17:41:34 - INFO:\ttrain #4230 lr = 6.55e-05 loss = 0.088636 train = 0.969922 valid = 0.813769\n",
            "2022-01-09 17:42:03 - INFO:\ttrain #4240 lr = 6.54e-05 loss = 0.078815 train = 0.973828 valid = 0.809301\n",
            "2022-01-09 17:42:31 - INFO:\ttrain #4250 lr = 6.54e-05 loss = 0.083610 train = 0.974023 valid = 0.812754\n",
            "2022-01-09 17:42:59 - INFO:\ttrain #4260 lr = 6.53e-05 loss = 0.083445 train = 0.970703 valid = 0.807880\n",
            "2022-01-09 17:43:27 - INFO:\ttrain #4270 lr = 6.52e-05 loss = 0.090612 train = 0.967187 valid = 0.799756\n",
            "2022-01-09 17:43:55 - INFO:\ttrain #4280 lr = 6.52e-05 loss = 0.090606 train = 0.968555 valid = 0.799147\n",
            "2022-01-09 17:44:24 - INFO:\ttrain #4290 lr = 6.51e-05 loss = 0.097010 train = 0.964063 valid = 0.797116\n",
            "2022-01-09 17:44:52 - INFO:\ttrain #4300 lr = 6.50e-05 loss = 0.086624 train = 0.969531 valid = 0.798741\n",
            "2022-01-09 17:44:55 - INFO:\tSaved test = 0.790519\n",
            "2022-01-09 17:45:23 - INFO:\ttrain #4310 lr = 6.50e-05 loss = 0.100595 train = 0.964063 valid = 0.789602\n",
            "2022-01-09 17:45:52 - INFO:\ttrain #4320 lr = 6.49e-05 loss = 0.101904 train = 0.965039 valid = 0.811942\n",
            "2022-01-09 17:46:20 - INFO:\ttrain #4330 lr = 6.49e-05 loss = 0.094644 train = 0.967187 valid = 0.799756\n",
            "2022-01-09 17:46:48 - INFO:\ttrain #4340 lr = 6.48e-05 loss = 0.082220 train = 0.970508 valid = 0.804021\n",
            "2022-01-09 17:47:16 - INFO:\ttrain #4350 lr = 6.47e-05 loss = 0.094893 train = 0.969922 valid = 0.805240\n",
            "2022-01-09 17:47:44 - INFO:\ttrain #4360 lr = 6.47e-05 loss = 0.087397 train = 0.970508 valid = 0.812145\n",
            "2022-01-09 17:48:12 - INFO:\ttrain #4370 lr = 6.46e-05 loss = 0.096467 train = 0.966992 valid = 0.805646\n",
            "2022-01-09 17:48:40 - INFO:\ttrain #4380 lr = 6.45e-05 loss = 0.092700 train = 0.968750 valid = 0.804021\n",
            "2022-01-09 17:49:08 - INFO:\ttrain #4390 lr = 6.45e-05 loss = 0.090282 train = 0.967578 valid = 0.803209\n",
            "2022-01-09 17:49:36 - INFO:\ttrain #4400 lr = 6.44e-05 loss = 0.089024 train = 0.968555 valid = 0.807677\n",
            "2022-01-09 17:49:40 - INFO:\tSaved test = 0.794976\n",
            "2022-01-09 17:50:08 - INFO:\ttrain #4410 lr = 6.43e-05 loss = 0.089421 train = 0.968555 valid = 0.811129\n",
            "2022-01-09 17:50:36 - INFO:\ttrain #4420 lr = 6.43e-05 loss = 0.087580 train = 0.969531 valid = 0.806255\n",
            "2022-01-09 17:51:04 - INFO:\ttrain #4430 lr = 6.42e-05 loss = 0.090058 train = 0.967969 valid = 0.813566\n",
            "2022-01-09 17:51:32 - INFO:\ttrain #4440 lr = 6.41e-05 loss = 0.089899 train = 0.969141 valid = 0.807880\n",
            "2022-01-09 17:52:01 - INFO:\ttrain #4450 lr = 6.41e-05 loss = 0.078878 train = 0.972656 valid = 0.819050 updated\n",
            "2022-01-09 17:52:29 - INFO:\ttrain #4460 lr = 6.40e-05 loss = 0.091594 train = 0.970898 valid = 0.814785\n",
            "2022-01-09 17:52:57 - INFO:\ttrain #4470 lr = 6.40e-05 loss = 0.084217 train = 0.970898 valid = 0.808489\n",
            "2022-01-09 17:53:25 - INFO:\ttrain #4480 lr = 6.39e-05 loss = 0.091126 train = 0.965039 valid = 0.804833\n",
            "2022-01-09 17:53:53 - INFO:\ttrain #4490 lr = 6.38e-05 loss = 0.092374 train = 0.967383 valid = 0.808083\n",
            "2022-01-09 17:54:22 - INFO:\ttrain #4500 lr = 6.38e-05 loss = 0.084426 train = 0.969531 valid = 0.810520\n",
            "2022-01-09 17:54:25 - INFO:\tSaved test = 0.802674\n",
            "2022-01-09 17:54:53 - INFO:\ttrain #4510 lr = 6.37e-05 loss = 0.081485 train = 0.970703 valid = 0.818643\n",
            "2022-01-09 17:55:21 - INFO:\ttrain #4520 lr = 6.36e-05 loss = 0.074868 train = 0.974219 valid = 0.814175\n",
            "2022-01-09 17:55:49 - INFO:\ttrain #4530 lr = 6.36e-05 loss = 0.094034 train = 0.968555 valid = 0.805240\n",
            "2022-01-09 17:56:18 - INFO:\ttrain #4540 lr = 6.35e-05 loss = 0.091670 train = 0.969922 valid = 0.799959\n",
            "2022-01-09 17:56:46 - INFO:\ttrain #4550 lr = 6.34e-05 loss = 0.090370 train = 0.971094 valid = 0.810926\n",
            "2022-01-09 17:57:14 - INFO:\ttrain #4560 lr = 6.34e-05 loss = 0.099811 train = 0.966406 valid = 0.814582\n",
            "2022-01-09 17:57:41 - INFO:\ttrain #4570 lr = 6.33e-05 loss = 0.091203 train = 0.970508 valid = 0.810723\n",
            "2022-01-09 17:58:09 - INFO:\ttrain #4580 lr = 6.33e-05 loss = 0.095300 train = 0.966211 valid = 0.797929\n",
            "2022-01-09 17:58:37 - INFO:\ttrain #4590 lr = 6.32e-05 loss = 0.079419 train = 0.972266 valid = 0.807067\n",
            "2022-01-09 17:59:05 - INFO:\ttrain #4600 lr = 6.31e-05 loss = 0.083216 train = 0.970898 valid = 0.801787\n",
            "2022-01-09 17:59:09 - INFO:\tSaved test = 0.791734\n",
            "2022-01-09 17:59:37 - INFO:\ttrain #4610 lr = 6.31e-05 loss = 0.083063 train = 0.970313 valid = 0.805037\n",
            "2022-01-09 18:00:05 - INFO:\ttrain #4620 lr = 6.30e-05 loss = 0.082187 train = 0.972656 valid = 0.812957\n",
            "2022-01-09 18:00:33 - INFO:\ttrain #4630 lr = 6.29e-05 loss = 0.088952 train = 0.967773 valid = 0.813972\n",
            "2022-01-09 18:01:01 - INFO:\ttrain #4640 lr = 6.29e-05 loss = 0.090373 train = 0.967383 valid = 0.798944\n",
            "2022-01-09 18:01:29 - INFO:\ttrain #4650 lr = 6.28e-05 loss = 0.081711 train = 0.974805 valid = 0.814379\n",
            "2022-01-09 18:01:57 - INFO:\ttrain #4660 lr = 6.27e-05 loss = 0.077999 train = 0.974023 valid = 0.804021\n",
            "2022-01-09 18:02:26 - INFO:\ttrain #4670 lr = 6.27e-05 loss = 0.089847 train = 0.969141 valid = 0.814988\n",
            "2022-01-09 18:02:54 - INFO:\ttrain #4680 lr = 6.26e-05 loss = 0.087910 train = 0.970703 valid = 0.805849\n",
            "2022-01-09 18:03:22 - INFO:\ttrain #4690 lr = 6.26e-05 loss = 0.090017 train = 0.970508 valid = 0.806864\n",
            "2022-01-09 18:03:50 - INFO:\ttrain #4700 lr = 6.25e-05 loss = 0.101498 train = 0.963281 valid = 0.818237\n",
            "2022-01-09 18:03:54 - INFO:\tSaved test = 0.797407\n",
            "2022-01-09 18:04:22 - INFO:\ttrain #4710 lr = 6.24e-05 loss = 0.086380 train = 0.971289 valid = 0.809098\n",
            "2022-01-09 18:04:50 - INFO:\ttrain #4720 lr = 6.24e-05 loss = 0.097810 train = 0.964453 valid = 0.809708\n",
            "2022-01-09 18:05:18 - INFO:\ttrain #4730 lr = 6.23e-05 loss = 0.093049 train = 0.968555 valid = 0.805443\n",
            "2022-01-09 18:05:47 - INFO:\ttrain #4740 lr = 6.22e-05 loss = 0.087978 train = 0.970898 valid = 0.816613\n",
            "2022-01-09 18:06:15 - INFO:\ttrain #4750 lr = 6.22e-05 loss = 0.081896 train = 0.972656 valid = 0.805849\n",
            "2022-01-09 18:06:43 - INFO:\ttrain #4760 lr = 6.21e-05 loss = 0.076878 train = 0.974805 valid = 0.812957\n",
            "2022-01-09 18:07:11 - INFO:\ttrain #4770 lr = 6.21e-05 loss = 0.074903 train = 0.974414 valid = 0.814582\n",
            "2022-01-09 18:07:39 - INFO:\ttrain #4780 lr = 6.20e-05 loss = 0.090505 train = 0.968164 valid = 0.805037\n",
            "2022-01-09 18:08:07 - INFO:\ttrain #4790 lr = 6.19e-05 loss = 0.089929 train = 0.967773 valid = 0.816206\n",
            "2022-01-09 18:08:35 - INFO:\ttrain #4800 lr = 6.19e-05 loss = 0.091389 train = 0.967578 valid = 0.812957\n",
            "2022-01-09 18:08:39 - INFO:\tSaved test = 0.802674\n",
            "2022-01-09 18:09:07 - INFO:\ttrain #4810 lr = 6.18e-05 loss = 0.079083 train = 0.973437 valid = 0.819050\n",
            "2022-01-09 18:09:35 - INFO:\ttrain #4820 lr = 6.18e-05 loss = 0.081439 train = 0.972656 valid = 0.811738\n",
            "2022-01-09 18:10:03 - INFO:\ttrain #4830 lr = 6.17e-05 loss = 0.086224 train = 0.971875 valid = 0.807677\n",
            "2022-01-09 18:10:32 - INFO:\ttrain #4840 lr = 6.16e-05 loss = 0.091788 train = 0.968555 valid = 0.800162\n",
            "2022-01-09 18:11:00 - INFO:\ttrain #4850 lr = 6.16e-05 loss = 0.083035 train = 0.971094 valid = 0.812957\n",
            "2022-01-09 18:11:28 - INFO:\ttrain #4860 lr = 6.15e-05 loss = 0.071707 train = 0.975781 valid = 0.818643\n",
            "2022-01-09 18:11:56 - INFO:\ttrain #4870 lr = 6.14e-05 loss = 0.073674 train = 0.972852 valid = 0.815394\n",
            "2022-01-09 18:12:24 - INFO:\ttrain #4880 lr = 6.14e-05 loss = 0.074512 train = 0.973633 valid = 0.812348\n",
            "2022-01-09 18:12:52 - INFO:\ttrain #4890 lr = 6.13e-05 loss = 0.069666 train = 0.976562 valid = 0.805443\n",
            "2022-01-09 18:13:21 - INFO:\ttrain #4900 lr = 6.13e-05 loss = 0.071964 train = 0.976562 valid = 0.806255\n",
            "2022-01-09 18:13:24 - INFO:\tSaved test = 0.797812\n",
            "2022-01-09 18:13:52 - INFO:\ttrain #4910 lr = 6.12e-05 loss = 0.083552 train = 0.973047 valid = 0.810926\n",
            "2022-01-09 18:14:21 - INFO:\ttrain #4920 lr = 6.11e-05 loss = 0.087974 train = 0.967383 valid = 0.806661\n",
            "2022-01-09 18:14:49 - INFO:\ttrain #4930 lr = 6.11e-05 loss = 0.072953 train = 0.976367 valid = 0.817019\n",
            "2022-01-09 18:15:17 - INFO:\ttrain #4940 lr = 6.10e-05 loss = 0.081985 train = 0.971484 valid = 0.813363\n",
            "2022-01-09 18:15:45 - INFO:\ttrain #4950 lr = 6.10e-05 loss = 0.077331 train = 0.974219 valid = 0.811129\n",
            "2022-01-09 18:16:13 - INFO:\ttrain #4960 lr = 6.09e-05 loss = 0.076406 train = 0.973047 valid = 0.815394\n",
            "2022-01-09 18:16:41 - INFO:\ttrain #4970 lr = 6.08e-05 loss = 0.078422 train = 0.973828 valid = 0.814175\n",
            "2022-01-09 18:17:10 - INFO:\ttrain #4980 lr = 6.08e-05 loss = 0.081577 train = 0.975000 valid = 0.811129\n",
            "2022-01-09 18:17:38 - INFO:\ttrain #4990 lr = 6.07e-05 loss = 0.094404 train = 0.965430 valid = 0.805037\n",
            "2022-01-09 18:18:06 - INFO:\ttrain #5000 lr = 6.07e-05 loss = 0.089043 train = 0.970508 valid = 0.808286\n",
            "2022-01-09 18:18:10 - INFO:\tSaved test = 0.807131\n",
            "2022-01-09 18:18:38 - INFO:\ttrain #5010 lr = 6.06e-05 loss = 0.077951 train = 0.974219 valid = 0.806661\n",
            "2022-01-09 18:19:06 - INFO:\ttrain #5020 lr = 6.05e-05 loss = 0.071565 train = 0.974805 valid = 0.811332\n",
            "2022-01-09 18:19:34 - INFO:\ttrain #5030 lr = 6.05e-05 loss = 0.075993 train = 0.973828 valid = 0.816206\n",
            "2022-01-09 18:20:02 - INFO:\ttrain #5040 lr = 6.04e-05 loss = 0.074622 train = 0.975586 valid = 0.812551\n",
            "2022-01-09 18:20:30 - INFO:\ttrain #5050 lr = 6.03e-05 loss = 0.078987 train = 0.972852 valid = 0.817425\n",
            "2022-01-09 18:20:59 - INFO:\ttrain #5060 lr = 6.03e-05 loss = 0.064950 train = 0.980078 valid = 0.815800\n",
            "2022-01-09 18:21:27 - INFO:\ttrain #5070 lr = 6.02e-05 loss = 0.086122 train = 0.969922 valid = 0.816003\n",
            "2022-01-09 18:21:55 - INFO:\ttrain #5080 lr = 6.02e-05 loss = 0.076082 train = 0.974219 valid = 0.813972\n",
            "2022-01-09 18:22:23 - INFO:\ttrain #5090 lr = 6.01e-05 loss = 0.081896 train = 0.972656 valid = 0.820065 updated\n",
            "2022-01-09 18:22:51 - INFO:\ttrain #5100 lr = 6.00e-05 loss = 0.068011 train = 0.975781 valid = 0.815597\n",
            "2022-01-09 18:22:55 - INFO:\tSaved test = 0.806321\n",
            "2022-01-09 18:23:23 - INFO:\ttrain #5110 lr = 6.00e-05 loss = 0.070693 train = 0.975195 valid = 0.816613\n",
            "2022-01-09 18:23:51 - INFO:\ttrain #5120 lr = 5.99e-05 loss = 0.077721 train = 0.974023 valid = 0.811535\n",
            "2022-01-09 18:24:19 - INFO:\ttrain #5130 lr = 5.99e-05 loss = 0.081630 train = 0.970508 valid = 0.810926\n",
            "2022-01-09 18:24:47 - INFO:\ttrain #5140 lr = 5.98e-05 loss = 0.085558 train = 0.968945 valid = 0.812145\n",
            "2022-01-09 18:25:15 - INFO:\ttrain #5150 lr = 5.97e-05 loss = 0.072869 train = 0.976953 valid = 0.816206\n",
            "2022-01-09 18:25:44 - INFO:\ttrain #5160 lr = 5.97e-05 loss = 0.078398 train = 0.973437 valid = 0.805240\n",
            "2022-01-09 18:26:12 - INFO:\ttrain #5170 lr = 5.96e-05 loss = 0.082879 train = 0.970703 valid = 0.814988\n",
            "2022-01-09 18:26:40 - INFO:\ttrain #5180 lr = 5.96e-05 loss = 0.067982 train = 0.974805 valid = 0.817628\n",
            "2022-01-09 18:27:08 - INFO:\ttrain #5190 lr = 5.95e-05 loss = 0.073421 train = 0.977930 valid = 0.819862\n",
            "2022-01-09 18:27:36 - INFO:\ttrain #5200 lr = 5.95e-05 loss = 0.074733 train = 0.971680 valid = 0.811738\n",
            "2022-01-09 18:27:40 - INFO:\tSaved test = 0.791734\n",
            "2022-01-09 18:28:08 - INFO:\ttrain #5210 lr = 5.94e-05 loss = 0.074446 train = 0.972852 valid = 0.821487 updated\n",
            "2022-01-09 18:28:36 - INFO:\ttrain #5220 lr = 5.93e-05 loss = 0.069523 train = 0.975586 valid = 0.812348\n",
            "2022-01-09 18:29:05 - INFO:\ttrain #5230 lr = 5.93e-05 loss = 0.067174 train = 0.976172 valid = 0.820877\n",
            "2022-01-09 18:29:33 - INFO:\ttrain #5240 lr = 5.92e-05 loss = 0.073978 train = 0.975781 valid = 0.809911\n",
            "2022-01-09 18:30:01 - INFO:\ttrain #5250 lr = 5.92e-05 loss = 0.070028 train = 0.977344 valid = 0.815800\n",
            "2022-01-09 18:30:29 - INFO:\ttrain #5260 lr = 5.91e-05 loss = 0.065337 train = 0.979102 valid = 0.818237\n",
            "2022-01-09 18:30:57 - INFO:\ttrain #5270 lr = 5.90e-05 loss = 0.076284 train = 0.973828 valid = 0.818846\n",
            "2022-01-09 18:31:25 - INFO:\ttrain #5280 lr = 5.90e-05 loss = 0.076811 train = 0.972852 valid = 0.812551\n",
            "2022-01-09 18:31:54 - INFO:\ttrain #5290 lr = 5.89e-05 loss = 0.081727 train = 0.971875 valid = 0.812145\n",
            "2022-01-09 18:32:22 - INFO:\ttrain #5300 lr = 5.89e-05 loss = 0.077896 train = 0.975000 valid = 0.819659\n",
            "2022-01-09 18:32:25 - INFO:\tSaved test = 0.805511\n",
            "2022-01-09 18:32:54 - INFO:\ttrain #5310 lr = 5.88e-05 loss = 0.067801 train = 0.976953 valid = 0.816206\n",
            "2022-01-09 18:33:22 - INFO:\ttrain #5320 lr = 5.87e-05 loss = 0.073141 train = 0.975000 valid = 0.819659\n",
            "2022-01-09 18:33:50 - INFO:\ttrain #5330 lr = 5.87e-05 loss = 0.086727 train = 0.970703 valid = 0.814785\n",
            "2022-01-09 18:34:18 - INFO:\ttrain #5340 lr = 5.86e-05 loss = 0.070486 train = 0.974219 valid = 0.817831\n",
            "2022-01-09 18:34:47 - INFO:\ttrain #5350 lr = 5.86e-05 loss = 0.067649 train = 0.976367 valid = 0.814582\n",
            "2022-01-09 18:35:15 - INFO:\ttrain #5360 lr = 5.85e-05 loss = 0.074845 train = 0.977930 valid = 0.815394\n",
            "2022-01-09 18:35:43 - INFO:\ttrain #5370 lr = 5.84e-05 loss = 0.064613 train = 0.978906 valid = 0.818846\n",
            "2022-01-09 18:36:11 - INFO:\ttrain #5380 lr = 5.84e-05 loss = 0.061395 train = 0.977734 valid = 0.818237\n",
            "2022-01-09 18:36:40 - INFO:\ttrain #5390 lr = 5.83e-05 loss = 0.072396 train = 0.975781 valid = 0.823721 updated\n",
            "2022-01-09 18:37:08 - INFO:\ttrain #5400 lr = 5.83e-05 loss = 0.060646 train = 0.980273 valid = 0.814582\n",
            "2022-01-09 18:37:11 - INFO:\tSaved test = 0.808752\n",
            "2022-01-09 18:37:40 - INFO:\ttrain #5410 lr = 5.82e-05 loss = 0.067445 train = 0.974609 valid = 0.816816\n",
            "2022-01-09 18:38:08 - INFO:\ttrain #5420 lr = 5.82e-05 loss = 0.075274 train = 0.975391 valid = 0.797319\n",
            "2022-01-09 18:38:36 - INFO:\ttrain #5430 lr = 5.81e-05 loss = 0.072749 train = 0.974805 valid = 0.814175\n",
            "2022-01-09 18:39:04 - INFO:\ttrain #5440 lr = 5.80e-05 loss = 0.069919 train = 0.976758 valid = 0.803412\n",
            "2022-01-09 18:39:33 - INFO:\ttrain #5450 lr = 5.80e-05 loss = 0.063987 train = 0.978711 valid = 0.814379\n",
            "2022-01-09 18:40:01 - INFO:\ttrain #5460 lr = 5.79e-05 loss = 0.069813 train = 0.976758 valid = 0.819253\n",
            "2022-01-09 18:40:29 - INFO:\ttrain #5470 lr = 5.79e-05 loss = 0.073530 train = 0.975000 valid = 0.824533 updated\n",
            "2022-01-09 18:40:57 - INFO:\ttrain #5480 lr = 5.78e-05 loss = 0.069615 train = 0.975977 valid = 0.811129\n",
            "2022-01-09 18:41:26 - INFO:\ttrain #5490 lr = 5.78e-05 loss = 0.065174 train = 0.978125 valid = 0.818643\n",
            "2022-01-09 18:41:54 - INFO:\ttrain #5500 lr = 5.77e-05 loss = 0.069042 train = 0.974805 valid = 0.802396\n",
            "2022-01-09 18:41:57 - INFO:\tSaved test = 0.800243\n",
            "2022-01-09 18:42:25 - INFO:\ttrain #5510 lr = 5.76e-05 loss = 0.074515 train = 0.973828 valid = 0.802396\n",
            "2022-01-09 18:42:54 - INFO:\ttrain #5520 lr = 5.76e-05 loss = 0.066268 train = 0.978711 valid = 0.806052\n",
            "2022-01-09 18:43:22 - INFO:\ttrain #5530 lr = 5.75e-05 loss = 0.062557 train = 0.980078 valid = 0.809301\n",
            "2022-01-09 18:43:50 - INFO:\ttrain #5540 lr = 5.75e-05 loss = 0.056932 train = 0.980859 valid = 0.821893\n",
            "2022-01-09 18:44:18 - INFO:\ttrain #5550 lr = 5.74e-05 loss = 0.065649 train = 0.977734 valid = 0.818440\n",
            "2022-01-09 18:44:46 - INFO:\ttrain #5560 lr = 5.73e-05 loss = 0.066390 train = 0.975391 valid = 0.810317\n",
            "2022-01-09 18:45:15 - INFO:\ttrain #5570 lr = 5.73e-05 loss = 0.086056 train = 0.968750 valid = 0.813160\n",
            "2022-01-09 18:45:42 - INFO:\ttrain #5580 lr = 5.72e-05 loss = 0.066187 train = 0.978516 valid = 0.814582\n",
            "2022-01-09 18:46:11 - INFO:\ttrain #5590 lr = 5.72e-05 loss = 0.078371 train = 0.972852 valid = 0.803006\n",
            "2022-01-09 18:46:39 - INFO:\ttrain #5600 lr = 5.71e-05 loss = 0.060847 train = 0.979688 valid = 0.817425\n",
            "2022-01-09 18:46:42 - INFO:\tSaved test = 0.802269\n",
            "2022-01-09 18:47:11 - INFO:\ttrain #5610 lr = 5.71e-05 loss = 0.065746 train = 0.977734 valid = 0.816003\n",
            "2022-01-09 18:47:39 - INFO:\ttrain #5620 lr = 5.70e-05 loss = 0.059557 train = 0.978320 valid = 0.813972\n",
            "2022-01-09 18:48:07 - INFO:\ttrain #5630 lr = 5.69e-05 loss = 0.064153 train = 0.977344 valid = 0.818440\n",
            "2022-01-09 18:48:35 - INFO:\ttrain #5640 lr = 5.69e-05 loss = 0.064559 train = 0.977734 valid = 0.810723\n",
            "2022-01-09 18:49:04 - INFO:\ttrain #5650 lr = 5.68e-05 loss = 0.062635 train = 0.978711 valid = 0.820674\n",
            "2022-01-09 18:49:32 - INFO:\ttrain #5660 lr = 5.68e-05 loss = 0.069265 train = 0.976367 valid = 0.813160\n",
            "2022-01-09 18:50:00 - INFO:\ttrain #5670 lr = 5.67e-05 loss = 0.073191 train = 0.974805 valid = 0.810520\n",
            "2022-01-09 18:50:28 - INFO:\ttrain #5680 lr = 5.67e-05 loss = 0.062098 train = 0.979492 valid = 0.806661\n",
            "2022-01-09 18:50:56 - INFO:\ttrain #5690 lr = 5.66e-05 loss = 0.069468 train = 0.975000 valid = 0.817425\n",
            "2022-01-09 18:51:25 - INFO:\ttrain #5700 lr = 5.66e-05 loss = 0.068121 train = 0.977539 valid = 0.805240\n",
            "2022-01-09 18:51:28 - INFO:\tSaved test = 0.802674\n",
            "2022-01-09 18:51:57 - INFO:\ttrain #5710 lr = 5.65e-05 loss = 0.060500 train = 0.980273 valid = 0.817831\n",
            "2022-01-09 18:52:25 - INFO:\ttrain #5720 lr = 5.64e-05 loss = 0.072288 train = 0.975781 valid = 0.810114\n",
            "2022-01-09 18:52:53 - INFO:\ttrain #5730 lr = 5.64e-05 loss = 0.073012 train = 0.975586 valid = 0.798335\n",
            "2022-01-09 18:53:21 - INFO:\ttrain #5740 lr = 5.63e-05 loss = 0.065779 train = 0.977148 valid = 0.809911\n",
            "2022-01-09 18:53:50 - INFO:\ttrain #5750 lr = 5.63e-05 loss = 0.053370 train = 0.981250 valid = 0.813566\n",
            "2022-01-09 18:54:18 - INFO:\ttrain #5760 lr = 5.62e-05 loss = 0.055896 train = 0.981250 valid = 0.811942\n",
            "2022-01-09 18:54:46 - INFO:\ttrain #5770 lr = 5.62e-05 loss = 0.057670 train = 0.981250 valid = 0.809301\n",
            "2022-01-09 18:55:15 - INFO:\ttrain #5780 lr = 5.61e-05 loss = 0.056776 train = 0.981641 valid = 0.814379\n",
            "2022-01-09 18:55:43 - INFO:\ttrain #5790 lr = 5.60e-05 loss = 0.056818 train = 0.981836 valid = 0.817019\n",
            "2022-01-09 18:56:12 - INFO:\ttrain #5800 lr = 5.60e-05 loss = 0.066972 train = 0.977539 valid = 0.817831\n",
            "2022-01-09 18:56:16 - INFO:\tSaved test = 0.807942\n",
            "2022-01-09 18:56:46 - INFO:\ttrain #5810 lr = 5.59e-05 loss = 0.064780 train = 0.976953 valid = 0.808489\n",
            "2022-01-09 18:57:14 - INFO:\ttrain #5820 lr = 5.59e-05 loss = 0.065214 train = 0.977734 valid = 0.813972\n",
            "2022-01-09 18:57:43 - INFO:\ttrain #5830 lr = 5.58e-05 loss = 0.076486 train = 0.974805 valid = 0.807880\n",
            "2022-01-09 18:58:11 - INFO:\ttrain #5840 lr = 5.58e-05 loss = 0.055063 train = 0.982812 valid = 0.796304\n",
            "2022-01-09 18:58:40 - INFO:\ttrain #5850 lr = 5.57e-05 loss = 0.057584 train = 0.979492 valid = 0.812957\n",
            "2022-01-09 18:59:08 - INFO:\ttrain #5860 lr = 5.57e-05 loss = 0.065645 train = 0.978516 valid = 0.809098\n",
            "2022-01-09 18:59:37 - INFO:\ttrain #5870 lr = 5.56e-05 loss = 0.064807 train = 0.978516 valid = 0.809301\n",
            "2022-01-09 19:00:05 - INFO:\ttrain #5880 lr = 5.55e-05 loss = 0.060949 train = 0.978516 valid = 0.811535\n",
            "2022-01-09 19:00:34 - INFO:\ttrain #5890 lr = 5.55e-05 loss = 0.048741 train = 0.983789 valid = 0.814175\n",
            "2022-01-09 19:01:02 - INFO:\ttrain #5900 lr = 5.54e-05 loss = 0.061374 train = 0.975781 valid = 0.810723\n",
            "2022-01-09 19:01:06 - INFO:\tSaved test = 0.815235\n",
            "2022-01-09 19:01:35 - INFO:\ttrain #5910 lr = 5.54e-05 loss = 0.053835 train = 0.983398 valid = 0.813160\n",
            "2022-01-09 19:02:03 - INFO:\ttrain #5920 lr = 5.53e-05 loss = 0.069690 train = 0.976172 valid = 0.793054\n",
            "2022-01-09 19:02:31 - INFO:\ttrain #5930 lr = 5.53e-05 loss = 0.059926 train = 0.981055 valid = 0.808692\n",
            "2022-01-09 19:03:00 - INFO:\ttrain #5940 lr = 5.52e-05 loss = 0.059257 train = 0.979688 valid = 0.806052\n",
            "2022-01-09 19:03:28 - INFO:\ttrain #5950 lr = 5.52e-05 loss = 0.059425 train = 0.979688 valid = 0.810520\n",
            "2022-01-09 19:03:57 - INFO:\ttrain #5960 lr = 5.51e-05 loss = 0.062269 train = 0.978125 valid = 0.816206\n",
            "2022-01-09 19:04:24 - INFO:\ttrain #5970 lr = 5.50e-05 loss = 0.055773 train = 0.981445 valid = 0.809504\n",
            "2022-01-09 19:04:53 - INFO:\ttrain #5980 lr = 5.50e-05 loss = 0.057977 train = 0.980469 valid = 0.817019\n",
            "2022-01-09 19:05:21 - INFO:\ttrain #5990 lr = 5.49e-05 loss = 0.049488 train = 0.983398 valid = 0.818846\n",
            "2022-01-09 19:05:49 - INFO:\ttrain #6000 lr = 5.49e-05 loss = 0.061287 train = 0.978906 valid = 0.813363\n",
            "2022-01-09 19:05:53 - INFO:\tSaved test = 0.798622\n",
            "2022-01-09 19:06:21 - INFO:\ttrain #6010 lr = 5.48e-05 loss = 0.050891 train = 0.982227 valid = 0.819862\n",
            "2022-01-09 19:06:49 - INFO:\ttrain #6020 lr = 5.48e-05 loss = 0.056378 train = 0.981445 valid = 0.818846\n",
            "2022-01-09 19:07:17 - INFO:\ttrain #6030 lr = 5.47e-05 loss = 0.058739 train = 0.981836 valid = 0.810520\n",
            "2022-01-09 19:07:45 - INFO:\ttrain #6040 lr = 5.47e-05 loss = 0.058992 train = 0.978320 valid = 0.806864\n",
            "2022-01-09 19:08:13 - INFO:\ttrain #6050 lr = 5.46e-05 loss = 0.060468 train = 0.980664 valid = 0.809098\n",
            "2022-01-09 19:08:42 - INFO:\ttrain #6060 lr = 5.46e-05 loss = 0.062325 train = 0.977930 valid = 0.808692\n",
            "2022-01-09 19:09:10 - INFO:\ttrain #6070 lr = 5.45e-05 loss = 0.092702 train = 0.968945 valid = 0.809301\n",
            "2022-01-09 19:09:39 - INFO:\ttrain #6080 lr = 5.44e-05 loss = 0.075254 train = 0.974023 valid = 0.801584\n",
            "2022-01-09 19:10:07 - INFO:\ttrain #6090 lr = 5.44e-05 loss = 0.061304 train = 0.978320 valid = 0.812957\n",
            "2022-01-09 19:10:36 - INFO:\ttrain #6100 lr = 5.43e-05 loss = 0.060150 train = 0.981055 valid = 0.815800\n",
            "2022-01-09 19:10:39 - INFO:\tSaved test = 0.807536\n",
            "2022-01-09 19:11:08 - INFO:\ttrain #6110 lr = 5.43e-05 loss = 0.054454 train = 0.982227 valid = 0.815597\n",
            "2022-01-09 19:11:37 - INFO:\ttrain #6120 lr = 5.42e-05 loss = 0.051832 train = 0.980469 valid = 0.824939 updated\n",
            "2022-01-09 19:12:05 - INFO:\ttrain #6130 lr = 5.42e-05 loss = 0.051448 train = 0.982422 valid = 0.825142 updated\n",
            "2022-01-09 19:12:34 - INFO:\ttrain #6140 lr = 5.41e-05 loss = 0.054384 train = 0.980273 valid = 0.815191\n",
            "2022-01-09 19:13:03 - INFO:\ttrain #6150 lr = 5.41e-05 loss = 0.062532 train = 0.978125 valid = 0.811332\n",
            "2022-01-09 19:13:31 - INFO:\ttrain #6160 lr = 5.40e-05 loss = 0.053722 train = 0.983594 valid = 0.809911\n",
            "2022-01-09 19:13:59 - INFO:\ttrain #6170 lr = 5.40e-05 loss = 0.053926 train = 0.980664 valid = 0.815191\n",
            "2022-01-09 19:14:28 - INFO:\ttrain #6180 lr = 5.39e-05 loss = 0.063901 train = 0.978516 valid = 0.811129\n",
            "2022-01-09 19:14:56 - INFO:\ttrain #6190 lr = 5.38e-05 loss = 0.060919 train = 0.979883 valid = 0.817628\n",
            "2022-01-09 19:15:25 - INFO:\ttrain #6200 lr = 5.38e-05 loss = 0.056365 train = 0.980664 valid = 0.820877\n",
            "2022-01-09 19:15:28 - INFO:\tSaved test = 0.809157\n",
            "2022-01-09 19:15:57 - INFO:\ttrain #6210 lr = 5.37e-05 loss = 0.054161 train = 0.981445 valid = 0.811129\n",
            "2022-01-09 19:16:26 - INFO:\ttrain #6220 lr = 5.37e-05 loss = 0.052165 train = 0.981445 valid = 0.815191\n",
            "2022-01-09 19:16:54 - INFO:\ttrain #6230 lr = 5.36e-05 loss = 0.056777 train = 0.981055 valid = 0.822908\n",
            "2022-01-09 19:17:23 - INFO:\ttrain #6240 lr = 5.36e-05 loss = 0.055485 train = 0.982617 valid = 0.809708\n",
            "2022-01-09 19:17:52 - INFO:\ttrain #6250 lr = 5.35e-05 loss = 0.058306 train = 0.980469 valid = 0.815191\n",
            "2022-01-09 19:18:20 - INFO:\ttrain #6260 lr = 5.35e-05 loss = 0.049688 train = 0.982617 valid = 0.820471\n",
            "2022-01-09 19:18:49 - INFO:\ttrain #6270 lr = 5.34e-05 loss = 0.063621 train = 0.979102 valid = 0.795288\n",
            "2022-01-09 19:19:17 - INFO:\ttrain #6280 lr = 5.34e-05 loss = 0.047335 train = 0.983984 valid = 0.818846\n",
            "2022-01-09 19:19:45 - INFO:\ttrain #6290 lr = 5.33e-05 loss = 0.051063 train = 0.982812 valid = 0.817628\n",
            "2022-01-09 19:20:14 - INFO:\ttrain #6300 lr = 5.33e-05 loss = 0.049142 train = 0.983789 valid = 0.817831\n",
            "2022-01-09 19:20:18 - INFO:\tSaved test = 0.808752\n",
            "2022-01-09 19:20:46 - INFO:\ttrain #6310 lr = 5.32e-05 loss = 0.052170 train = 0.983789 valid = 0.821690\n",
            "2022-01-09 19:21:14 - INFO:\ttrain #6320 lr = 5.32e-05 loss = 0.052822 train = 0.982227 valid = 0.810317\n",
            "2022-01-09 19:21:42 - INFO:\ttrain #6330 lr = 5.31e-05 loss = 0.065037 train = 0.977344 valid = 0.819862\n",
            "2022-01-09 19:22:09 - INFO:\ttrain #6340 lr = 5.30e-05 loss = 0.065869 train = 0.976758 valid = 0.815394\n",
            "2022-01-09 19:22:38 - INFO:\ttrain #6350 lr = 5.30e-05 loss = 0.063632 train = 0.979297 valid = 0.825548 updated\n",
            "2022-01-09 19:23:06 - INFO:\ttrain #6360 lr = 5.29e-05 loss = 0.057512 train = 0.978320 valid = 0.819456\n",
            "2022-01-09 19:23:34 - INFO:\ttrain #6370 lr = 5.29e-05 loss = 0.053467 train = 0.982422 valid = 0.817019\n",
            "2022-01-09 19:24:02 - INFO:\ttrain #6380 lr = 5.28e-05 loss = 0.044582 train = 0.985156 valid = 0.817425\n",
            "2022-01-09 19:24:30 - INFO:\ttrain #6390 lr = 5.28e-05 loss = 0.055509 train = 0.980664 valid = 0.815800\n",
            "2022-01-09 19:24:58 - INFO:\ttrain #6400 lr = 5.27e-05 loss = 0.051419 train = 0.983203 valid = 0.822502\n",
            "2022-01-09 19:25:02 - INFO:\tSaved test = 0.809157\n",
            "2022-01-09 19:25:30 - INFO:\ttrain #6410 lr = 5.27e-05 loss = 0.053950 train = 0.981641 valid = 0.813566\n",
            "2022-01-09 19:25:59 - INFO:\ttrain #6420 lr = 5.26e-05 loss = 0.062033 train = 0.978320 valid = 0.820877\n",
            "2022-01-09 19:26:27 - INFO:\ttrain #6430 lr = 5.26e-05 loss = 0.057968 train = 0.980664 valid = 0.807677\n",
            "2022-01-09 19:26:55 - INFO:\ttrain #6440 lr = 5.25e-05 loss = 0.059199 train = 0.979492 valid = 0.818846\n",
            "2022-01-09 19:27:24 - INFO:\ttrain #6450 lr = 5.25e-05 loss = 0.054410 train = 0.980469 valid = 0.808083\n",
            "2022-01-09 19:27:52 - INFO:\ttrain #6460 lr = 5.24e-05 loss = 0.049712 train = 0.982031 valid = 0.820471\n",
            "2022-01-09 19:28:20 - INFO:\ttrain #6470 lr = 5.24e-05 loss = 0.058027 train = 0.979883 valid = 0.820674\n",
            "2022-01-09 19:28:48 - INFO:\ttrain #6480 lr = 5.23e-05 loss = 0.046576 train = 0.983984 valid = 0.824127\n",
            "2022-01-09 19:29:17 - INFO:\ttrain #6490 lr = 5.23e-05 loss = 0.063603 train = 0.977930 valid = 0.806458\n",
            "2022-01-09 19:29:45 - INFO:\ttrain #6500 lr = 5.22e-05 loss = 0.063592 train = 0.979492 valid = 0.806864\n",
            "2022-01-09 19:29:49 - INFO:\tSaved test = 0.799838\n",
            "2022-01-09 19:30:17 - INFO:\ttrain #6510 lr = 5.22e-05 loss = 0.044353 train = 0.986328 valid = 0.825548\n",
            "2022-01-09 19:30:45 - INFO:\ttrain #6520 lr = 5.21e-05 loss = 0.049605 train = 0.983008 valid = 0.822908\n",
            "2022-01-09 19:31:13 - INFO:\ttrain #6530 lr = 5.20e-05 loss = 0.052641 train = 0.982227 valid = 0.819456\n",
            "2022-01-09 19:31:42 - INFO:\ttrain #6540 lr = 5.20e-05 loss = 0.060918 train = 0.978320 valid = 0.808286\n",
            "2022-01-09 19:32:10 - INFO:\ttrain #6550 lr = 5.19e-05 loss = 0.052931 train = 0.981641 valid = 0.822299\n",
            "2022-01-09 19:32:38 - INFO:\ttrain #6560 lr = 5.19e-05 loss = 0.048649 train = 0.983984 valid = 0.804224\n",
            "2022-01-09 19:33:06 - INFO:\ttrain #6570 lr = 5.18e-05 loss = 0.053044 train = 0.980273 valid = 0.817831\n",
            "2022-01-09 19:33:34 - INFO:\ttrain #6580 lr = 5.18e-05 loss = 0.052090 train = 0.983789 valid = 0.808692\n",
            "2022-01-09 19:34:02 - INFO:\ttrain #6590 lr = 5.17e-05 loss = 0.060436 train = 0.978320 valid = 0.817222\n",
            "2022-01-09 19:34:30 - INFO:\ttrain #6600 lr = 5.17e-05 loss = 0.049920 train = 0.984766 valid = 0.821080\n",
            "2022-01-09 19:34:34 - INFO:\tSaved test = 0.813209\n",
            "2022-01-09 19:35:02 - INFO:\ttrain #6610 lr = 5.16e-05 loss = 0.053923 train = 0.981445 valid = 0.820268\n",
            "2022-01-09 19:35:30 - INFO:\ttrain #6620 lr = 5.16e-05 loss = 0.051011 train = 0.982617 valid = 0.809504\n",
            "2022-01-09 19:35:58 - INFO:\ttrain #6630 lr = 5.15e-05 loss = 0.065274 train = 0.977930 valid = 0.811738\n",
            "2022-01-09 19:36:25 - INFO:\ttrain #6640 lr = 5.15e-05 loss = 0.049635 train = 0.982617 valid = 0.822908\n",
            "2022-01-09 19:36:53 - INFO:\ttrain #6650 lr = 5.14e-05 loss = 0.037560 train = 0.985938 valid = 0.819862\n",
            "2022-01-09 19:37:21 - INFO:\ttrain #6660 lr = 5.14e-05 loss = 0.053947 train = 0.982227 valid = 0.803006\n",
            "2022-01-09 19:37:50 - INFO:\ttrain #6670 lr = 5.13e-05 loss = 0.056100 train = 0.979883 valid = 0.819659\n",
            "2022-01-09 19:38:18 - INFO:\ttrain #6680 lr = 5.13e-05 loss = 0.044046 train = 0.985156 valid = 0.805443\n",
            "2022-01-09 19:38:45 - INFO:\ttrain #6690 lr = 5.12e-05 loss = 0.047453 train = 0.984375 valid = 0.817831\n",
            "2022-01-09 19:39:13 - INFO:\ttrain #6700 lr = 5.12e-05 loss = 0.057740 train = 0.981055 valid = 0.811738\n",
            "2022-01-09 19:39:17 - INFO:\tSaved test = 0.807131\n",
            "2022-01-09 19:39:45 - INFO:\ttrain #6710 lr = 5.11e-05 loss = 0.047891 train = 0.983008 valid = 0.806255\n",
            "2022-01-09 19:40:13 - INFO:\ttrain #6720 lr = 5.11e-05 loss = 0.040703 train = 0.987891 valid = 0.818237\n",
            "2022-01-09 19:40:41 - INFO:\ttrain #6730 lr = 5.10e-05 loss = 0.046456 train = 0.984766 valid = 0.819050\n",
            "2022-01-09 19:41:09 - INFO:\ttrain #6740 lr = 5.10e-05 loss = 0.052858 train = 0.980273 valid = 0.810723\n",
            "2022-01-09 19:41:37 - INFO:\ttrain #6750 lr = 5.09e-05 loss = 0.050866 train = 0.982422 valid = 0.809301\n",
            "2022-01-09 19:42:04 - INFO:\ttrain #6760 lr = 5.09e-05 loss = 0.047094 train = 0.983984 valid = 0.817222\n",
            "2022-01-09 19:42:32 - INFO:\ttrain #6770 lr = 5.08e-05 loss = 0.054564 train = 0.980273 valid = 0.810723\n",
            "2022-01-09 19:43:00 - INFO:\ttrain #6780 lr = 5.08e-05 loss = 0.059401 train = 0.977148 valid = 0.817425\n",
            "2022-01-09 19:43:29 - INFO:\ttrain #6790 lr = 5.07e-05 loss = 0.055671 train = 0.980469 valid = 0.812957\n",
            "2022-01-09 19:43:57 - INFO:\ttrain #6800 lr = 5.07e-05 loss = 0.054605 train = 0.981445 valid = 0.823721\n",
            "2022-01-09 19:44:00 - INFO:\tSaved test = 0.821313\n",
            "2022-01-09 19:44:28 - INFO:\ttrain #6810 lr = 5.06e-05 loss = 0.043179 train = 0.986914 valid = 0.817222\n",
            "2022-01-09 19:44:56 - INFO:\ttrain #6820 lr = 5.06e-05 loss = 0.048484 train = 0.984375 valid = 0.819050\n",
            "2022-01-09 19:45:24 - INFO:\ttrain #6830 lr = 5.05e-05 loss = 0.046733 train = 0.983984 valid = 0.815597\n",
            "2022-01-09 19:45:52 - INFO:\ttrain #6840 lr = 5.05e-05 loss = 0.038822 train = 0.988672 valid = 0.824533\n",
            "2022-01-09 19:46:21 - INFO:\ttrain #6850 lr = 5.04e-05 loss = 0.043408 train = 0.985547 valid = 0.817831\n",
            "2022-01-09 19:46:49 - INFO:\ttrain #6860 lr = 5.04e-05 loss = 0.057872 train = 0.976562 valid = 0.813566\n",
            "2022-01-09 19:47:17 - INFO:\ttrain #6870 lr = 5.03e-05 loss = 0.055628 train = 0.981641 valid = 0.817222\n",
            "2022-01-09 19:47:45 - INFO:\ttrain #6880 lr = 5.03e-05 loss = 0.047438 train = 0.982617 valid = 0.820877\n",
            "2022-01-09 19:48:13 - INFO:\ttrain #6890 lr = 5.02e-05 loss = 0.053863 train = 0.982422 valid = 0.815394\n",
            "2022-01-09 19:48:41 - INFO:\ttrain #6900 lr = 5.02e-05 loss = 0.053164 train = 0.982227 valid = 0.815191\n",
            "2022-01-09 19:48:45 - INFO:\tSaved test = 0.801864\n",
            "2022-01-09 19:49:13 - INFO:\ttrain #6910 lr = 5.01e-05 loss = 0.053372 train = 0.981641 valid = 0.814582\n",
            "2022-01-09 19:49:41 - INFO:\ttrain #6920 lr = 5.01e-05 loss = 0.046152 train = 0.983984 valid = 0.810926\n",
            "2022-01-09 19:50:09 - INFO:\ttrain #6930 lr = 5.00e-05 loss = 0.048568 train = 0.983203 valid = 0.819050\n",
            "2022-01-09 19:50:37 - INFO:\ttrain #6940 lr = 5.00e-05 loss = 0.052232 train = 0.983203 valid = 0.813972\n",
            "2022-01-09 19:51:05 - INFO:\ttrain #6950 lr = 4.99e-05 loss = 0.049962 train = 0.983594 valid = 0.807067\n",
            "2022-01-09 19:51:33 - INFO:\ttrain #6960 lr = 4.99e-05 loss = 0.050945 train = 0.980078 valid = 0.815597\n",
            "2022-01-09 19:52:01 - INFO:\ttrain #6970 lr = 4.98e-05 loss = 0.049756 train = 0.984180 valid = 0.814785\n",
            "2022-01-09 19:52:29 - INFO:\ttrain #6980 lr = 4.98e-05 loss = 0.046846 train = 0.984180 valid = 0.824736\n",
            "2022-01-09 19:52:57 - INFO:\ttrain #6990 lr = 4.97e-05 loss = 0.041079 train = 0.986328 valid = 0.821893\n",
            "2022-01-09 19:53:25 - INFO:\ttrain #7000 lr = 4.97e-05 loss = 0.044020 train = 0.984766 valid = 0.820268\n",
            "2022-01-09 19:53:29 - INFO:\tSaved test = 0.810373\n",
            "2022-01-09 19:53:57 - INFO:\ttrain #7010 lr = 4.96e-05 loss = 0.040515 train = 0.986523 valid = 0.821080\n",
            "2022-01-09 19:54:26 - INFO:\ttrain #7020 lr = 4.96e-05 loss = 0.051268 train = 0.981836 valid = 0.813769\n",
            "2022-01-09 19:54:54 - INFO:\ttrain #7030 lr = 4.95e-05 loss = 0.038236 train = 0.987109 valid = 0.818237\n",
            "2022-01-09 19:55:22 - INFO:\ttrain #7040 lr = 4.95e-05 loss = 0.040906 train = 0.985352 valid = 0.821893\n",
            "2022-01-09 19:55:51 - INFO:\ttrain #7050 lr = 4.94e-05 loss = 0.048463 train = 0.982617 valid = 0.819253\n",
            "2022-01-09 19:56:19 - INFO:\ttrain #7060 lr = 4.94e-05 loss = 0.050691 train = 0.981836 valid = 0.821690\n",
            "2022-01-09 19:56:47 - INFO:\ttrain #7070 lr = 4.93e-05 loss = 0.048992 train = 0.983398 valid = 0.811535\n",
            "2022-01-09 19:57:16 - INFO:\ttrain #7080 lr = 4.93e-05 loss = 0.044100 train = 0.983789 valid = 0.824330\n",
            "2022-01-09 19:57:44 - INFO:\ttrain #7090 lr = 4.92e-05 loss = 0.048498 train = 0.984570 valid = 0.817425\n",
            "2022-01-09 19:58:12 - INFO:\ttrain #7100 lr = 4.92e-05 loss = 0.047150 train = 0.983008 valid = 0.813363\n",
            "2022-01-09 19:58:16 - INFO:\tSaved test = 0.809968\n",
            "2022-01-09 19:58:44 - INFO:\ttrain #7110 lr = 4.91e-05 loss = 0.051852 train = 0.983008 valid = 0.826361 updated\n",
            "2022-01-09 19:59:12 - INFO:\ttrain #7120 lr = 4.91e-05 loss = 0.049222 train = 0.982227 valid = 0.821690\n",
            "2022-01-09 19:59:40 - INFO:\ttrain #7130 lr = 4.90e-05 loss = 0.043088 train = 0.982812 valid = 0.817425\n",
            "2022-01-09 20:00:09 - INFO:\ttrain #7140 lr = 4.90e-05 loss = 0.047186 train = 0.983008 valid = 0.809301\n",
            "2022-01-09 20:00:37 - INFO:\ttrain #7150 lr = 4.89e-05 loss = 0.046518 train = 0.983594 valid = 0.824939\n",
            "2022-01-09 20:01:05 - INFO:\ttrain #7160 lr = 4.89e-05 loss = 0.041363 train = 0.986523 valid = 0.820268\n",
            "2022-01-09 20:01:33 - INFO:\ttrain #7170 lr = 4.88e-05 loss = 0.042887 train = 0.983789 valid = 0.817831\n",
            "2022-01-09 20:02:02 - INFO:\ttrain #7180 lr = 4.88e-05 loss = 0.041301 train = 0.985547 valid = 0.821487\n",
            "2022-01-09 20:02:30 - INFO:\ttrain #7190 lr = 4.87e-05 loss = 0.048318 train = 0.984375 valid = 0.816206\n",
            "2022-01-09 20:02:59 - INFO:\ttrain #7200 lr = 4.87e-05 loss = 0.045709 train = 0.984766 valid = 0.808083\n",
            "2022-01-09 20:03:02 - INFO:\tSaved test = 0.804295\n",
            "2022-01-09 20:03:31 - INFO:\ttrain #7210 lr = 4.86e-05 loss = 0.052310 train = 0.981836 valid = 0.813972\n",
            "2022-01-09 20:03:59 - INFO:\ttrain #7220 lr = 4.86e-05 loss = 0.053112 train = 0.981445 valid = 0.822096\n",
            "2022-01-09 20:04:28 - INFO:\ttrain #7230 lr = 4.85e-05 loss = 0.043177 train = 0.986719 valid = 0.814582\n",
            "2022-01-09 20:04:55 - INFO:\ttrain #7240 lr = 4.85e-05 loss = 0.047524 train = 0.983398 valid = 0.816816\n",
            "2022-01-09 20:05:23 - INFO:\ttrain #7250 lr = 4.84e-05 loss = 0.044979 train = 0.983398 valid = 0.818440\n",
            "2022-01-09 20:05:50 - INFO:\ttrain #7260 lr = 4.84e-05 loss = 0.042398 train = 0.985547 valid = 0.811332\n",
            "2022-01-09 20:06:18 - INFO:\ttrain #7270 lr = 4.83e-05 loss = 0.047294 train = 0.981641 valid = 0.816613\n",
            "2022-01-09 20:06:46 - INFO:\ttrain #7280 lr = 4.83e-05 loss = 0.051381 train = 0.981641 valid = 0.811535\n",
            "2022-01-09 20:07:13 - INFO:\ttrain #7290 lr = 4.82e-05 loss = 0.053325 train = 0.983594 valid = 0.821487\n",
            "2022-01-09 20:07:42 - INFO:\ttrain #7300 lr = 4.82e-05 loss = 0.042360 train = 0.985742 valid = 0.821284\n",
            "2022-01-09 20:07:45 - INFO:\tSaved test = 0.809968\n",
            "2022-01-09 20:08:12 - INFO:\ttrain #7310 lr = 4.81e-05 loss = 0.044399 train = 0.984375 valid = 0.821690\n",
            "2022-01-09 20:08:40 - INFO:\ttrain #7320 lr = 4.81e-05 loss = 0.051636 train = 0.981250 valid = 0.811535\n",
            "2022-01-09 20:09:08 - INFO:\ttrain #7330 lr = 4.80e-05 loss = 0.039291 train = 0.988477 valid = 0.809911\n",
            "2022-01-09 20:09:35 - INFO:\ttrain #7340 lr = 4.80e-05 loss = 0.044708 train = 0.986523 valid = 0.810520\n",
            "2022-01-09 20:10:03 - INFO:\ttrain #7350 lr = 4.79e-05 loss = 0.042756 train = 0.984375 valid = 0.816003\n",
            "2022-01-09 20:10:30 - INFO:\ttrain #7360 lr = 4.79e-05 loss = 0.037512 train = 0.986328 valid = 0.818643\n",
            "2022-01-09 20:10:58 - INFO:\ttrain #7370 lr = 4.79e-05 loss = 0.042598 train = 0.986328 valid = 0.820268\n",
            "2022-01-09 20:11:26 - INFO:\ttrain #7380 lr = 4.78e-05 loss = 0.038092 train = 0.988281 valid = 0.811535\n",
            "2022-01-09 20:11:55 - INFO:\ttrain #7390 lr = 4.78e-05 loss = 0.045750 train = 0.984570 valid = 0.808895\n",
            "2022-01-09 20:12:22 - INFO:\ttrain #7400 lr = 4.77e-05 loss = 0.041359 train = 0.986133 valid = 0.821284\n",
            "2022-01-09 20:12:26 - INFO:\tSaved test = 0.818882\n",
            "2022-01-09 20:12:53 - INFO:\ttrain #7410 lr = 4.77e-05 loss = 0.039918 train = 0.986914 valid = 0.817019\n",
            "2022-01-09 20:13:20 - INFO:\ttrain #7420 lr = 4.76e-05 loss = 0.040598 train = 0.987695 valid = 0.820065\n",
            "2022-01-09 20:13:48 - INFO:\ttrain #7430 lr = 4.76e-05 loss = 0.041754 train = 0.984961 valid = 0.817019\n",
            "2022-01-09 20:14:15 - INFO:\ttrain #7440 lr = 4.75e-05 loss = 0.043237 train = 0.985156 valid = 0.821893\n",
            "2022-01-09 20:14:43 - INFO:\ttrain #7450 lr = 4.75e-05 loss = 0.045083 train = 0.984570 valid = 0.806255\n",
            "2022-01-09 20:15:10 - INFO:\ttrain #7460 lr = 4.74e-05 loss = 0.045415 train = 0.984180 valid = 0.812348\n",
            "2022-01-09 20:15:38 - INFO:\ttrain #7470 lr = 4.74e-05 loss = 0.049827 train = 0.981445 valid = 0.819456\n",
            "2022-01-09 20:16:05 - INFO:\ttrain #7480 lr = 4.73e-05 loss = 0.035855 train = 0.987695 valid = 0.812754\n",
            "2022-01-09 20:16:34 - INFO:\ttrain #7490 lr = 4.73e-05 loss = 0.032398 train = 0.989453 valid = 0.816816\n",
            "2022-01-09 20:17:01 - INFO:\ttrain #7500 lr = 4.72e-05 loss = 0.036507 train = 0.990234 valid = 0.812957\n",
            "2022-01-09 20:17:05 - INFO:\tSaved test = 0.816045\n",
            "2022-01-09 20:17:33 - INFO:\ttrain #7510 lr = 4.72e-05 loss = 0.036877 train = 0.987305 valid = 0.821284\n",
            "2022-01-09 20:18:00 - INFO:\ttrain #7520 lr = 4.71e-05 loss = 0.041536 train = 0.986133 valid = 0.810317\n",
            "2022-01-09 20:18:28 - INFO:\ttrain #7530 lr = 4.71e-05 loss = 0.044890 train = 0.983594 valid = 0.825548\n",
            "2022-01-09 20:18:57 - INFO:\ttrain #7540 lr = 4.70e-05 loss = 0.042566 train = 0.984961 valid = 0.815597\n",
            "2022-01-09 20:19:25 - INFO:\ttrain #7550 lr = 4.70e-05 loss = 0.048097 train = 0.983594 valid = 0.816613\n",
            "2022-01-09 20:19:54 - INFO:\ttrain #7560 lr = 4.70e-05 loss = 0.039335 train = 0.986328 valid = 0.815191\n",
            "2022-01-09 20:20:22 - INFO:\ttrain #7570 lr = 4.69e-05 loss = 0.043778 train = 0.985547 valid = 0.820674\n",
            "2022-01-09 20:20:50 - INFO:\ttrain #7580 lr = 4.69e-05 loss = 0.033084 train = 0.989453 valid = 0.822299\n",
            "2022-01-09 20:21:19 - INFO:\ttrain #7590 lr = 4.68e-05 loss = 0.033568 train = 0.988086 valid = 0.817831\n",
            "2022-01-09 20:21:47 - INFO:\ttrain #7600 lr = 4.68e-05 loss = 0.034446 train = 0.987500 valid = 0.818643\n",
            "2022-01-09 20:21:51 - INFO:\tSaved test = 0.818476\n",
            "2022-01-09 20:22:19 - INFO:\ttrain #7610 lr = 4.67e-05 loss = 0.034413 train = 0.989453 valid = 0.819050\n",
            "2022-01-09 20:22:48 - INFO:\ttrain #7620 lr = 4.67e-05 loss = 0.053293 train = 0.982812 valid = 0.816613\n",
            "2022-01-09 20:23:17 - INFO:\ttrain #7630 lr = 4.66e-05 loss = 0.043394 train = 0.984375 valid = 0.823314\n",
            "2022-01-09 20:23:46 - INFO:\ttrain #7640 lr = 4.66e-05 loss = 0.051744 train = 0.980273 valid = 0.805443\n",
            "2022-01-09 20:24:14 - INFO:\ttrain #7650 lr = 4.65e-05 loss = 0.042732 train = 0.984961 valid = 0.812145\n",
            "2022-01-09 20:24:44 - INFO:\ttrain #7660 lr = 4.65e-05 loss = 0.046257 train = 0.982422 valid = 0.813160\n",
            "2022-01-09 20:25:13 - INFO:\ttrain #7670 lr = 4.64e-05 loss = 0.035896 train = 0.987891 valid = 0.811942\n",
            "2022-01-09 20:25:42 - INFO:\ttrain #7680 lr = 4.64e-05 loss = 0.038698 train = 0.985938 valid = 0.813769\n",
            "2022-01-09 20:26:11 - INFO:\ttrain #7690 lr = 4.63e-05 loss = 0.041058 train = 0.987109 valid = 0.814582\n",
            "2022-01-09 20:26:40 - INFO:\ttrain #7700 lr = 4.63e-05 loss = 0.043240 train = 0.985156 valid = 0.820877\n",
            "2022-01-09 20:26:44 - INFO:\tSaved test = 0.811994\n",
            "2022-01-09 20:27:14 - INFO:\ttrain #7710 lr = 4.63e-05 loss = 0.038822 train = 0.987109 valid = 0.816003\n",
            "2022-01-09 20:27:43 - INFO:\ttrain #7720 lr = 4.62e-05 loss = 0.032867 train = 0.990234 valid = 0.822299\n",
            "2022-01-09 20:28:13 - INFO:\ttrain #7730 lr = 4.62e-05 loss = 0.039734 train = 0.986719 valid = 0.826564 updated\n",
            "2022-01-09 20:28:43 - INFO:\ttrain #7740 lr = 4.61e-05 loss = 0.046068 train = 0.985352 valid = 0.815394\n",
            "2022-01-09 20:29:12 - INFO:\ttrain #7750 lr = 4.61e-05 loss = 0.048181 train = 0.982812 valid = 0.823111\n",
            "2022-01-09 20:29:40 - INFO:\ttrain #7760 lr = 4.60e-05 loss = 0.039847 train = 0.986914 valid = 0.824939\n",
            "2022-01-09 20:30:09 - INFO:\ttrain #7770 lr = 4.60e-05 loss = 0.044859 train = 0.984766 valid = 0.812145\n",
            "2022-01-09 20:30:38 - INFO:\ttrain #7780 lr = 4.59e-05 loss = 0.044675 train = 0.984570 valid = 0.821284\n",
            "2022-01-09 20:31:06 - INFO:\ttrain #7790 lr = 4.59e-05 loss = 0.036194 train = 0.989453 valid = 0.814175\n",
            "2022-01-09 20:31:35 - INFO:\ttrain #7800 lr = 4.58e-05 loss = 0.033967 train = 0.989648 valid = 0.826361\n",
            "2022-01-09 20:31:39 - INFO:\tSaved test = 0.819287\n",
            "2022-01-09 20:32:07 - INFO:\ttrain #7810 lr = 4.58e-05 loss = 0.031874 train = 0.990430 valid = 0.810926\n",
            "2022-01-09 20:32:36 - INFO:\ttrain #7820 lr = 4.57e-05 loss = 0.035448 train = 0.988867 valid = 0.818034\n",
            "2022-01-09 20:33:05 - INFO:\ttrain #7830 lr = 4.57e-05 loss = 0.041989 train = 0.986133 valid = 0.812348\n",
            "2022-01-09 20:33:33 - INFO:\ttrain #7840 lr = 4.57e-05 loss = 0.044615 train = 0.983789 valid = 0.817831\n",
            "2022-01-09 20:34:02 - INFO:\ttrain #7850 lr = 4.56e-05 loss = 0.047639 train = 0.983008 valid = 0.823924\n",
            "2022-01-09 20:34:31 - INFO:\ttrain #7860 lr = 4.56e-05 loss = 0.043588 train = 0.984766 valid = 0.817222\n",
            "2022-01-09 20:35:00 - INFO:\ttrain #7870 lr = 4.55e-05 loss = 0.036740 train = 0.988086 valid = 0.819659\n",
            "2022-01-09 20:35:30 - INFO:\ttrain #7880 lr = 4.55e-05 loss = 0.040638 train = 0.986719 valid = 0.816206\n",
            "2022-01-09 20:35:59 - INFO:\ttrain #7890 lr = 4.54e-05 loss = 0.036335 train = 0.987109 valid = 0.823924\n",
            "2022-01-09 20:36:28 - INFO:\ttrain #7900 lr = 4.54e-05 loss = 0.031136 train = 0.989062 valid = 0.823924\n",
            "2022-01-09 20:36:32 - INFO:\tSaved test = 0.813209\n",
            "2022-01-09 20:37:02 - INFO:\ttrain #7910 lr = 4.53e-05 loss = 0.032252 train = 0.988477 valid = 0.824939\n",
            "2022-01-09 20:37:30 - INFO:\ttrain #7920 lr = 4.53e-05 loss = 0.038493 train = 0.985352 valid = 0.824939\n",
            "2022-01-09 20:37:59 - INFO:\ttrain #7930 lr = 4.52e-05 loss = 0.037171 train = 0.986133 valid = 0.822096\n",
            "2022-01-09 20:38:27 - INFO:\ttrain #7940 lr = 4.52e-05 loss = 0.033689 train = 0.989844 valid = 0.823111\n",
            "2022-01-09 20:38:56 - INFO:\ttrain #7950 lr = 4.52e-05 loss = 0.038790 train = 0.985547 valid = 0.811129\n",
            "2022-01-09 20:39:24 - INFO:\ttrain #7960 lr = 4.51e-05 loss = 0.036128 train = 0.988477 valid = 0.823314\n",
            "2022-01-09 20:39:54 - INFO:\ttrain #7970 lr = 4.51e-05 loss = 0.033690 train = 0.987695 valid = 0.813160\n",
            "2022-01-09 20:40:24 - INFO:\ttrain #7980 lr = 4.50e-05 loss = 0.037431 train = 0.986719 valid = 0.816003\n",
            "2022-01-09 20:40:52 - INFO:\ttrain #7990 lr = 4.50e-05 loss = 0.030820 train = 0.989844 valid = 0.804021\n",
            "2022-01-09 20:41:20 - INFO:\ttrain #8000 lr = 4.49e-05 loss = 0.036778 train = 0.986914 valid = 0.822705\n",
            "2022-01-09 20:41:24 - INFO:\tSaved test = 0.807536\n",
            "2022-01-09 20:41:53 - INFO:\ttrain #8010 lr = 4.49e-05 loss = 0.034874 train = 0.988281 valid = 0.817019\n",
            "2022-01-09 20:42:22 - INFO:\ttrain #8020 lr = 4.48e-05 loss = 0.028535 train = 0.989844 valid = 0.818237\n",
            "2022-01-09 20:42:52 - INFO:\ttrain #8030 lr = 4.48e-05 loss = 0.035363 train = 0.989258 valid = 0.820877\n",
            "2022-01-09 20:43:22 - INFO:\ttrain #8040 lr = 4.48e-05 loss = 0.042563 train = 0.987109 valid = 0.821690\n",
            "2022-01-09 20:43:50 - INFO:\ttrain #8050 lr = 4.47e-05 loss = 0.038917 train = 0.987891 valid = 0.821080\n",
            "2022-01-09 20:44:19 - INFO:\ttrain #8060 lr = 4.47e-05 loss = 0.052824 train = 0.981641 valid = 0.800975\n",
            "2022-01-09 20:44:48 - INFO:\ttrain #8070 lr = 4.46e-05 loss = 0.039731 train = 0.985938 valid = 0.821487\n",
            "2022-01-09 20:45:17 - INFO:\ttrain #8080 lr = 4.46e-05 loss = 0.032599 train = 0.989062 valid = 0.822096\n",
            "2022-01-09 20:45:46 - INFO:\ttrain #8090 lr = 4.45e-05 loss = 0.031047 train = 0.990625 valid = 0.822299\n",
            "2022-01-09 20:46:15 - INFO:\ttrain #8100 lr = 4.45e-05 loss = 0.032953 train = 0.988086 valid = 0.820065\n",
            "2022-01-09 20:46:19 - INFO:\tSaved test = 0.812399\n",
            "2022-01-09 20:46:47 - INFO:\ttrain #8110 lr = 4.44e-05 loss = 0.037958 train = 0.988281 valid = 0.821893\n",
            "2022-01-09 20:47:15 - INFO:\ttrain #8120 lr = 4.44e-05 loss = 0.037399 train = 0.988086 valid = 0.820065\n",
            "2022-01-09 20:47:45 - INFO:\ttrain #8130 lr = 4.44e-05 loss = 0.039810 train = 0.985547 valid = 0.823314\n",
            "2022-01-09 20:48:13 - INFO:\ttrain #8140 lr = 4.43e-05 loss = 0.036870 train = 0.987500 valid = 0.819659\n",
            "2022-01-09 20:48:43 - INFO:\ttrain #8150 lr = 4.43e-05 loss = 0.035122 train = 0.988672 valid = 0.814785\n",
            "2022-01-09 20:49:11 - INFO:\ttrain #8160 lr = 4.42e-05 loss = 0.028324 train = 0.992773 valid = 0.823111\n",
            "2022-01-09 20:49:40 - INFO:\ttrain #8170 lr = 4.42e-05 loss = 0.043022 train = 0.985156 valid = 0.813769\n",
            "2022-01-09 20:50:09 - INFO:\ttrain #8180 lr = 4.41e-05 loss = 0.046842 train = 0.986328 valid = 0.811942\n",
            "2022-01-09 20:50:38 - INFO:\ttrain #8190 lr = 4.41e-05 loss = 0.041675 train = 0.985938 valid = 0.812145\n",
            "2022-01-09 20:51:07 - INFO:\ttrain #8200 lr = 4.40e-05 loss = 0.037101 train = 0.987891 valid = 0.817019\n",
            "2022-01-09 20:51:11 - INFO:\tSaved test = 0.812399\n",
            "2022-01-09 20:51:39 - INFO:\ttrain #8210 lr = 4.40e-05 loss = 0.039740 train = 0.986133 valid = 0.814582\n",
            "2022-01-09 20:52:08 - INFO:\ttrain #8220 lr = 4.40e-05 loss = 0.035290 train = 0.988672 valid = 0.819456\n",
            "2022-01-09 20:52:37 - INFO:\ttrain #8230 lr = 4.39e-05 loss = 0.035097 train = 0.988867 valid = 0.825955\n",
            "2022-01-09 20:53:07 - INFO:\ttrain #8240 lr = 4.39e-05 loss = 0.034099 train = 0.989453 valid = 0.825142\n",
            "2022-01-09 20:53:37 - INFO:\ttrain #8250 lr = 4.38e-05 loss = 0.032867 train = 0.987891 valid = 0.823314\n",
            "2022-01-09 20:54:06 - INFO:\ttrain #8260 lr = 4.38e-05 loss = 0.028667 train = 0.991016 valid = 0.821080\n",
            "2022-01-09 20:54:35 - INFO:\ttrain #8270 lr = 4.37e-05 loss = 0.030509 train = 0.989453 valid = 0.822705\n",
            "2022-01-09 20:55:05 - INFO:\ttrain #8280 lr = 4.37e-05 loss = 0.033771 train = 0.987695 valid = 0.823111\n",
            "2022-01-09 20:55:34 - INFO:\ttrain #8290 lr = 4.36e-05 loss = 0.036942 train = 0.987500 valid = 0.822908\n",
            "2022-01-09 20:56:04 - INFO:\ttrain #8300 lr = 4.36e-05 loss = 0.035113 train = 0.989453 valid = 0.819050\n",
            "2022-01-09 20:56:08 - INFO:\tSaved test = 0.808347\n",
            "2022-01-09 20:56:38 - INFO:\ttrain #8310 lr = 4.36e-05 loss = 0.030778 train = 0.991016 valid = 0.822908\n",
            "2022-01-09 20:57:07 - INFO:\ttrain #8320 lr = 4.35e-05 loss = 0.029712 train = 0.989844 valid = 0.820471\n",
            "2022-01-09 20:57:37 - INFO:\ttrain #8330 lr = 4.35e-05 loss = 0.035841 train = 0.987695 valid = 0.823111\n",
            "2022-01-09 20:58:06 - INFO:\ttrain #8340 lr = 4.34e-05 loss = 0.035112 train = 0.987695 valid = 0.821284\n",
            "2022-01-09 20:58:35 - INFO:\ttrain #8350 lr = 4.34e-05 loss = 0.031661 train = 0.990234 valid = 0.822908\n",
            "2022-01-09 20:59:05 - INFO:\ttrain #8360 lr = 4.33e-05 loss = 0.034355 train = 0.988086 valid = 0.825345\n",
            "2022-01-09 20:59:34 - INFO:\ttrain #8370 lr = 4.33e-05 loss = 0.029519 train = 0.990430 valid = 0.825955\n",
            "2022-01-09 21:00:04 - INFO:\ttrain #8380 lr = 4.33e-05 loss = 0.031218 train = 0.989844 valid = 0.816613\n",
            "2022-01-09 21:00:34 - INFO:\ttrain #8390 lr = 4.32e-05 loss = 0.038048 train = 0.986328 valid = 0.827782 updated\n",
            "2022-01-09 21:01:03 - INFO:\ttrain #8400 lr = 4.32e-05 loss = 0.037481 train = 0.988086 valid = 0.821080\n",
            "2022-01-09 21:01:06 - INFO:\tSaved test = 0.806726\n",
            "2022-01-09 21:01:35 - INFO:\ttrain #8410 lr = 4.31e-05 loss = 0.033390 train = 0.989258 valid = 0.821690\n",
            "2022-01-09 21:02:04 - INFO:\ttrain #8420 lr = 4.31e-05 loss = 0.037717 train = 0.985352 valid = 0.825345\n",
            "2022-01-09 21:02:33 - INFO:\ttrain #8430 lr = 4.30e-05 loss = 0.029638 train = 0.991016 valid = 0.824939\n",
            "2022-01-09 21:03:03 - INFO:\ttrain #8440 lr = 4.30e-05 loss = 0.034020 train = 0.988086 valid = 0.820065\n",
            "2022-01-09 21:03:33 - INFO:\ttrain #8450 lr = 4.30e-05 loss = 0.027940 train = 0.991211 valid = 0.828392 updated\n",
            "2022-01-09 21:04:02 - INFO:\ttrain #8460 lr = 4.29e-05 loss = 0.039021 train = 0.985742 valid = 0.824330\n",
            "2022-01-09 21:04:31 - INFO:\ttrain #8470 lr = 4.29e-05 loss = 0.032386 train = 0.989453 valid = 0.816003\n",
            "2022-01-09 21:05:00 - INFO:\ttrain #8480 lr = 4.28e-05 loss = 0.030772 train = 0.989453 valid = 0.821690\n",
            "2022-01-09 21:05:30 - INFO:\ttrain #8490 lr = 4.28e-05 loss = 0.028293 train = 0.989844 valid = 0.818643\n",
            "2022-01-09 21:05:59 - INFO:\ttrain #8500 lr = 4.27e-05 loss = 0.040065 train = 0.984961 valid = 0.821080\n",
            "2022-01-09 21:06:03 - INFO:\tSaved test = 0.814425\n",
            "2022-01-09 21:06:32 - INFO:\ttrain #8510 lr = 4.27e-05 loss = 0.035197 train = 0.990234 valid = 0.817019\n",
            "2022-01-09 21:07:01 - INFO:\ttrain #8520 lr = 4.27e-05 loss = 0.026743 train = 0.991406 valid = 0.818846\n",
            "2022-01-09 21:07:29 - INFO:\ttrain #8530 lr = 4.26e-05 loss = 0.031991 train = 0.988867 valid = 0.825548\n",
            "2022-01-09 21:07:57 - INFO:\ttrain #8540 lr = 4.26e-05 loss = 0.035026 train = 0.987500 valid = 0.827376\n",
            "2022-01-09 21:08:26 - INFO:\ttrain #8550 lr = 4.25e-05 loss = 0.035391 train = 0.989062 valid = 0.821080\n",
            "2022-01-09 21:08:54 - INFO:\ttrain #8560 lr = 4.25e-05 loss = 0.033113 train = 0.988477 valid = 0.826970\n",
            "2022-01-09 21:09:22 - INFO:\ttrain #8570 lr = 4.24e-05 loss = 0.032265 train = 0.989844 valid = 0.824533\n",
            "2022-01-09 21:09:51 - INFO:\ttrain #8580 lr = 4.24e-05 loss = 0.027269 train = 0.991016 valid = 0.821690\n",
            "2022-01-09 21:10:19 - INFO:\ttrain #8590 lr = 4.24e-05 loss = 0.037840 train = 0.986133 valid = 0.816409\n",
            "2022-01-09 21:10:48 - INFO:\ttrain #8600 lr = 4.23e-05 loss = 0.030027 train = 0.989453 valid = 0.823111\n",
            "2022-01-09 21:10:52 - INFO:\tSaved test = 0.808752\n",
            "2022-01-09 21:11:20 - INFO:\ttrain #8610 lr = 4.23e-05 loss = 0.027300 train = 0.991406 valid = 0.820065\n",
            "2022-01-09 21:11:48 - INFO:\ttrain #8620 lr = 4.22e-05 loss = 0.034112 train = 0.989062 valid = 0.819050\n",
            "2022-01-09 21:12:17 - INFO:\ttrain #8630 lr = 4.22e-05 loss = 0.031198 train = 0.989844 valid = 0.822096\n",
            "2022-01-09 21:12:45 - INFO:\ttrain #8640 lr = 4.21e-05 loss = 0.039845 train = 0.986914 valid = 0.814582\n",
            "2022-01-09 21:13:13 - INFO:\ttrain #8650 lr = 4.21e-05 loss = 0.040751 train = 0.987109 valid = 0.822299\n",
            "2022-01-09 21:13:41 - INFO:\ttrain #8660 lr = 4.21e-05 loss = 0.034737 train = 0.988281 valid = 0.813769\n",
            "2022-01-09 21:14:10 - INFO:\ttrain #8670 lr = 4.20e-05 loss = 0.040846 train = 0.985938 valid = 0.817628\n",
            "2022-01-09 21:14:38 - INFO:\ttrain #8680 lr = 4.20e-05 loss = 0.031986 train = 0.988672 valid = 0.812957\n",
            "2022-01-09 21:15:06 - INFO:\ttrain #8690 lr = 4.19e-05 loss = 0.026401 train = 0.991016 valid = 0.811129\n",
            "2022-01-09 21:15:35 - INFO:\ttrain #8700 lr = 4.19e-05 loss = 0.034884 train = 0.987695 valid = 0.816409\n",
            "2022-01-09 21:15:38 - INFO:\tSaved test = 0.818476\n",
            "2022-01-09 21:16:07 - INFO:\ttrain #8710 lr = 4.19e-05 loss = 0.024387 train = 0.992578 valid = 0.825345\n",
            "2022-01-09 21:16:35 - INFO:\ttrain #8720 lr = 4.18e-05 loss = 0.023639 train = 0.991797 valid = 0.824533\n",
            "2022-01-09 21:17:03 - INFO:\ttrain #8730 lr = 4.18e-05 loss = 0.030423 train = 0.990039 valid = 0.823111\n",
            "2022-01-09 21:17:31 - INFO:\ttrain #8740 lr = 4.17e-05 loss = 0.032086 train = 0.989453 valid = 0.820674\n",
            "2022-01-09 21:18:00 - INFO:\ttrain #8750 lr = 4.17e-05 loss = 0.026980 train = 0.991406 valid = 0.819456\n",
            "2022-01-09 21:18:28 - INFO:\ttrain #8760 lr = 4.16e-05 loss = 0.032539 train = 0.989258 valid = 0.814379\n",
            "2022-01-09 21:18:56 - INFO:\ttrain #8770 lr = 4.16e-05 loss = 0.039595 train = 0.986328 valid = 0.805037\n",
            "2022-01-09 21:19:25 - INFO:\ttrain #8780 lr = 4.16e-05 loss = 0.031860 train = 0.989648 valid = 0.816206\n",
            "2022-01-09 21:19:53 - INFO:\ttrain #8790 lr = 4.15e-05 loss = 0.027281 train = 0.990820 valid = 0.822705\n",
            "2022-01-09 21:20:21 - INFO:\ttrain #8800 lr = 4.15e-05 loss = 0.026349 train = 0.991406 valid = 0.818643\n",
            "2022-01-09 21:20:25 - INFO:\tSaved test = 0.807131\n",
            "2022-01-09 21:20:53 - INFO:\ttrain #8810 lr = 4.14e-05 loss = 0.031553 train = 0.989258 valid = 0.821690\n",
            "2022-01-09 21:21:21 - INFO:\ttrain #8820 lr = 4.14e-05 loss = 0.034474 train = 0.987109 valid = 0.819659\n",
            "2022-01-09 21:21:49 - INFO:\ttrain #8830 lr = 4.14e-05 loss = 0.035819 train = 0.988281 valid = 0.821284\n",
            "2022-01-09 21:22:18 - INFO:\ttrain #8840 lr = 4.13e-05 loss = 0.029602 train = 0.991016 valid = 0.822096\n",
            "2022-01-09 21:22:46 - INFO:\ttrain #8850 lr = 4.13e-05 loss = 0.029432 train = 0.990234 valid = 0.820674\n",
            "2022-01-09 21:23:14 - INFO:\ttrain #8860 lr = 4.12e-05 loss = 0.031274 train = 0.987109 valid = 0.814379\n",
            "2022-01-09 21:23:42 - INFO:\ttrain #8870 lr = 4.12e-05 loss = 0.036219 train = 0.987109 valid = 0.809098\n",
            "2022-01-09 21:24:10 - INFO:\ttrain #8880 lr = 4.11e-05 loss = 0.027892 train = 0.989258 valid = 0.823517\n",
            "2022-01-09 21:24:39 - INFO:\ttrain #8890 lr = 4.11e-05 loss = 0.024948 train = 0.990820 valid = 0.822299\n",
            "2022-01-09 21:25:07 - INFO:\ttrain #8900 lr = 4.11e-05 loss = 0.031512 train = 0.989844 valid = 0.819253\n",
            "2022-01-09 21:25:11 - INFO:\tSaved test = 0.818882\n",
            "2022-01-09 21:25:39 - INFO:\ttrain #8910 lr = 4.10e-05 loss = 0.027164 train = 0.991211 valid = 0.820674\n",
            "2022-01-09 21:26:07 - INFO:\ttrain #8920 lr = 4.10e-05 loss = 0.044174 train = 0.984180 valid = 0.804021\n",
            "2022-01-09 21:26:35 - INFO:\ttrain #8930 lr = 4.09e-05 loss = 0.039356 train = 0.987109 valid = 0.819050\n",
            "2022-01-09 21:27:03 - INFO:\ttrain #8940 lr = 4.09e-05 loss = 0.031169 train = 0.991211 valid = 0.813972\n",
            "2022-01-09 21:27:32 - INFO:\ttrain #8950 lr = 4.09e-05 loss = 0.028071 train = 0.991016 valid = 0.816816\n",
            "2022-01-09 21:28:00 - INFO:\ttrain #8960 lr = 4.08e-05 loss = 0.034393 train = 0.988281 valid = 0.808489\n",
            "2022-01-09 21:28:28 - INFO:\ttrain #8970 lr = 4.08e-05 loss = 0.036428 train = 0.988281 valid = 0.818643\n",
            "2022-01-09 21:28:56 - INFO:\ttrain #8980 lr = 4.07e-05 loss = 0.027515 train = 0.990820 valid = 0.821284\n",
            "2022-01-09 21:29:24 - INFO:\ttrain #8990 lr = 4.07e-05 loss = 0.031098 train = 0.989453 valid = 0.819050\n",
            "2022-01-09 21:29:53 - INFO:\ttrain #9000 lr = 4.07e-05 loss = 0.031277 train = 0.989258 valid = 0.819050\n",
            "2022-01-09 21:29:56 - INFO:\tSaved test = 0.812399\n",
            "2022-01-09 21:30:24 - INFO:\ttrain #9010 lr = 4.06e-05 loss = 0.021440 train = 0.993945 valid = 0.823517\n",
            "2022-01-09 21:30:53 - INFO:\ttrain #9020 lr = 4.06e-05 loss = 0.022776 train = 0.992578 valid = 0.822502\n",
            "2022-01-09 21:31:21 - INFO:\ttrain #9030 lr = 4.05e-05 loss = 0.027584 train = 0.990625 valid = 0.816003\n",
            "2022-01-09 21:31:49 - INFO:\ttrain #9040 lr = 4.05e-05 loss = 0.021980 train = 0.992773 valid = 0.823517\n",
            "2022-01-09 21:32:17 - INFO:\ttrain #9050 lr = 4.05e-05 loss = 0.021084 train = 0.993359 valid = 0.824939\n",
            "2022-01-09 21:32:46 - INFO:\ttrain #9060 lr = 4.04e-05 loss = 0.021125 train = 0.992969 valid = 0.824533\n",
            "2022-01-09 21:33:14 - INFO:\ttrain #9070 lr = 4.04e-05 loss = 0.027625 train = 0.990430 valid = 0.820065\n",
            "2022-01-09 21:33:42 - INFO:\ttrain #9080 lr = 4.03e-05 loss = 0.031184 train = 0.989453 valid = 0.826361\n",
            "2022-01-09 21:34:10 - INFO:\ttrain #9090 lr = 4.03e-05 loss = 0.030875 train = 0.989062 valid = 0.817628\n",
            "2022-01-09 21:34:38 - INFO:\ttrain #9100 lr = 4.03e-05 loss = 0.029854 train = 0.990625 valid = 0.810520\n",
            "2022-01-09 21:34:42 - INFO:\tSaved test = 0.794976\n",
            "2022-01-09 21:35:10 - INFO:\ttrain #9110 lr = 4.02e-05 loss = 0.029861 train = 0.990430 valid = 0.818034\n",
            "2022-01-09 21:35:39 - INFO:\ttrain #9120 lr = 4.02e-05 loss = 0.029339 train = 0.989258 valid = 0.809708\n",
            "2022-01-09 21:36:07 - INFO:\ttrain #9130 lr = 4.01e-05 loss = 0.030987 train = 0.989258 valid = 0.818237\n",
            "2022-01-09 21:36:35 - INFO:\ttrain #9140 lr = 4.01e-05 loss = 0.033188 train = 0.989258 valid = 0.822299\n",
            "2022-01-09 21:37:02 - INFO:\ttrain #9150 lr = 4.00e-05 loss = 0.023205 train = 0.992578 valid = 0.815394\n",
            "2022-01-09 21:37:29 - INFO:\ttrain #9160 lr = 4.00e-05 loss = 0.025940 train = 0.991992 valid = 0.822502\n",
            "2022-01-09 21:37:56 - INFO:\ttrain #9170 lr = 4.00e-05 loss = 0.023637 train = 0.992188 valid = 0.828392\n",
            "2022-01-09 21:38:24 - INFO:\ttrain #9180 lr = 3.99e-05 loss = 0.020013 train = 0.992969 valid = 0.825955\n",
            "2022-01-09 21:38:51 - INFO:\ttrain #9190 lr = 3.99e-05 loss = 0.022968 train = 0.992969 valid = 0.824330\n",
            "2022-01-09 21:39:19 - INFO:\ttrain #9200 lr = 3.99e-05 loss = 0.027257 train = 0.989648 valid = 0.819456\n",
            "2022-01-09 21:39:22 - INFO:\tSaved test = 0.816856\n",
            "2022-01-09 21:39:50 - INFO:\ttrain #9210 lr = 3.98e-05 loss = 0.035340 train = 0.987500 valid = 0.818846\n",
            "2022-01-09 21:40:18 - INFO:\ttrain #9220 lr = 3.98e-05 loss = 0.025159 train = 0.992578 valid = 0.819456\n",
            "2022-01-09 21:40:45 - INFO:\ttrain #9230 lr = 3.97e-05 loss = 0.027296 train = 0.990430 valid = 0.822096\n",
            "2022-01-09 21:41:14 - INFO:\ttrain #9240 lr = 3.97e-05 loss = 0.026614 train = 0.990234 valid = 0.817831\n",
            "2022-01-09 21:41:44 - INFO:\ttrain #9250 lr = 3.97e-05 loss = 0.027707 train = 0.991406 valid = 0.820471\n",
            "2022-01-09 21:42:13 - INFO:\ttrain #9260 lr = 3.96e-05 loss = 0.020225 train = 0.993945 valid = 0.823111\n",
            "2022-01-09 21:42:42 - INFO:\ttrain #9270 lr = 3.96e-05 loss = 0.027671 train = 0.990625 valid = 0.821284\n",
            "2022-01-09 21:43:10 - INFO:\ttrain #9280 lr = 3.95e-05 loss = 0.034638 train = 0.988281 valid = 0.819253\n",
            "2022-01-09 21:43:39 - INFO:\ttrain #9290 lr = 3.95e-05 loss = 0.036287 train = 0.986914 valid = 0.817628\n",
            "2022-01-09 21:44:07 - INFO:\ttrain #9300 lr = 3.95e-05 loss = 0.032339 train = 0.987891 valid = 0.821284\n",
            "2022-01-09 21:44:10 - INFO:\tSaved test = 0.814019\n",
            "2022-01-09 21:44:39 - INFO:\ttrain #9310 lr = 3.94e-05 loss = 0.034734 train = 0.987109 valid = 0.823517\n",
            "2022-01-09 21:45:07 - INFO:\ttrain #9320 lr = 3.94e-05 loss = 0.029846 train = 0.989453 valid = 0.818440\n",
            "2022-01-09 21:45:35 - INFO:\ttrain #9330 lr = 3.93e-05 loss = 0.023832 train = 0.991992 valid = 0.822096\n",
            "2022-01-09 21:46:03 - INFO:\ttrain #9340 lr = 3.93e-05 loss = 0.020817 train = 0.994141 valid = 0.819456\n",
            "2022-01-09 21:46:31 - INFO:\ttrain #9350 lr = 3.93e-05 loss = 0.027026 train = 0.989453 valid = 0.825345\n",
            "2022-01-09 21:47:00 - INFO:\ttrain #9360 lr = 3.92e-05 loss = 0.027908 train = 0.991406 valid = 0.823314\n",
            "2022-01-09 21:47:28 - INFO:\ttrain #9370 lr = 3.92e-05 loss = 0.026493 train = 0.991016 valid = 0.823517\n",
            "2022-01-09 21:47:56 - INFO:\ttrain #9380 lr = 3.91e-05 loss = 0.027351 train = 0.991406 valid = 0.821893\n",
            "2022-01-09 21:48:24 - INFO:\ttrain #9390 lr = 3.91e-05 loss = 0.024947 train = 0.991992 valid = 0.821893\n",
            "2022-01-09 21:48:52 - INFO:\ttrain #9400 lr = 3.91e-05 loss = 0.034408 train = 0.988281 valid = 0.822908\n",
            "2022-01-09 21:48:56 - INFO:\tSaved test = 0.822123\n",
            "2022-01-09 21:49:24 - INFO:\ttrain #9410 lr = 3.90e-05 loss = 0.026517 train = 0.991016 valid = 0.823517\n",
            "2022-01-09 21:49:52 - INFO:\ttrain #9420 lr = 3.90e-05 loss = 0.028264 train = 0.990234 valid = 0.819050\n",
            "2022-01-09 21:50:20 - INFO:\ttrain #9430 lr = 3.89e-05 loss = 0.022373 train = 0.992188 valid = 0.816816\n",
            "2022-01-09 21:50:49 - INFO:\ttrain #9440 lr = 3.89e-05 loss = 0.030507 train = 0.989258 valid = 0.818237\n",
            "2022-01-09 21:51:17 - INFO:\ttrain #9450 lr = 3.89e-05 loss = 0.022640 train = 0.993164 valid = 0.823111\n",
            "2022-01-09 21:51:45 - INFO:\ttrain #9460 lr = 3.88e-05 loss = 0.024376 train = 0.990625 valid = 0.819050\n",
            "2022-01-09 21:52:13 - INFO:\ttrain #9470 lr = 3.88e-05 loss = 0.018894 train = 0.993750 valid = 0.821690\n",
            "2022-01-09 21:52:41 - INFO:\ttrain #9480 lr = 3.87e-05 loss = 0.022966 train = 0.990820 valid = 0.817222\n",
            "2022-01-09 21:53:09 - INFO:\ttrain #9490 lr = 3.87e-05 loss = 0.030424 train = 0.991602 valid = 0.816003\n",
            "2022-01-09 21:53:38 - INFO:\ttrain #9500 lr = 3.87e-05 loss = 0.025068 train = 0.991406 valid = 0.817831\n",
            "2022-01-09 21:53:41 - INFO:\tSaved test = 0.814019\n",
            "2022-01-09 21:54:10 - INFO:\ttrain #9510 lr = 3.86e-05 loss = 0.028584 train = 0.990039 valid = 0.822705\n",
            "2022-01-09 21:54:38 - INFO:\ttrain #9520 lr = 3.86e-05 loss = 0.024793 train = 0.992383 valid = 0.822096\n",
            "2022-01-09 21:55:06 - INFO:\ttrain #9530 lr = 3.86e-05 loss = 0.026885 train = 0.991016 valid = 0.817628\n",
            "2022-01-09 21:55:34 - INFO:\ttrain #9540 lr = 3.85e-05 loss = 0.027824 train = 0.990039 valid = 0.823314\n",
            "2022-01-09 21:56:02 - INFO:\ttrain #9550 lr = 3.85e-05 loss = 0.021301 train = 0.993750 valid = 0.820471\n",
            "2022-01-09 21:56:31 - INFO:\ttrain #9560 lr = 3.84e-05 loss = 0.018854 train = 0.993945 valid = 0.823924\n",
            "2022-01-09 21:56:59 - INFO:\ttrain #9570 lr = 3.84e-05 loss = 0.029268 train = 0.990625 valid = 0.815597\n",
            "2022-01-09 21:57:28 - INFO:\ttrain #9580 lr = 3.84e-05 loss = 0.027313 train = 0.991797 valid = 0.812145\n",
            "2022-01-09 21:57:56 - INFO:\ttrain #9590 lr = 3.83e-05 loss = 0.030461 train = 0.991406 valid = 0.819050\n",
            "2022-01-09 21:58:25 - INFO:\ttrain #9600 lr = 3.83e-05 loss = 0.025896 train = 0.990820 valid = 0.815394\n",
            "2022-01-09 21:58:28 - INFO:\tSaved test = 0.811994\n",
            "2022-01-09 21:58:58 - INFO:\ttrain #9610 lr = 3.82e-05 loss = 0.018192 train = 0.993945 valid = 0.819862\n",
            "2022-01-09 21:59:27 - INFO:\ttrain #9620 lr = 3.82e-05 loss = 0.018522 train = 0.995313 valid = 0.823111\n",
            "2022-01-09 21:59:55 - INFO:\ttrain #9630 lr = 3.82e-05 loss = 0.031968 train = 0.989648 valid = 0.814785\n",
            "2022-01-09 22:00:23 - INFO:\ttrain #9640 lr = 3.81e-05 loss = 0.025773 train = 0.991797 valid = 0.815597\n",
            "2022-01-09 22:00:52 - INFO:\ttrain #9650 lr = 3.81e-05 loss = 0.034246 train = 0.987695 valid = 0.822096\n",
            "2022-01-09 22:01:22 - INFO:\ttrain #9660 lr = 3.81e-05 loss = 0.032889 train = 0.988477 valid = 0.810520\n",
            "2022-01-09 22:01:51 - INFO:\ttrain #9670 lr = 3.80e-05 loss = 0.029215 train = 0.992773 valid = 0.815191\n",
            "2022-01-09 22:02:20 - INFO:\ttrain #9680 lr = 3.80e-05 loss = 0.025280 train = 0.991016 valid = 0.821284\n",
            "2022-01-09 22:02:50 - INFO:\ttrain #9690 lr = 3.79e-05 loss = 0.021611 train = 0.994141 valid = 0.823111\n",
            "2022-01-09 22:03:20 - INFO:\ttrain #9700 lr = 3.79e-05 loss = 0.020735 train = 0.994141 valid = 0.825142\n",
            "2022-01-09 22:03:24 - INFO:\tSaved test = 0.817261\n",
            "2022-01-09 22:03:53 - INFO:\ttrain #9710 lr = 3.79e-05 loss = 0.023601 train = 0.992188 valid = 0.821080\n",
            "2022-01-09 22:04:22 - INFO:\ttrain #9720 lr = 3.78e-05 loss = 0.024869 train = 0.991211 valid = 0.820268\n",
            "2022-01-09 22:04:51 - INFO:\ttrain #9730 lr = 3.78e-05 loss = 0.020526 train = 0.992383 valid = 0.821487\n",
            "2022-01-09 22:05:21 - INFO:\ttrain #9740 lr = 3.78e-05 loss = 0.025379 train = 0.990430 valid = 0.823721\n",
            "2022-01-09 22:05:51 - INFO:\ttrain #9750 lr = 3.77e-05 loss = 0.022490 train = 0.992578 valid = 0.825548\n",
            "2022-01-09 22:06:20 - INFO:\ttrain #9760 lr = 3.77e-05 loss = 0.023221 train = 0.991992 valid = 0.831844 updated\n",
            "2022-01-09 22:06:50 - INFO:\ttrain #9770 lr = 3.76e-05 loss = 0.024647 train = 0.991016 valid = 0.826361\n",
            "2022-01-09 22:07:18 - INFO:\ttrain #9780 lr = 3.76e-05 loss = 0.025968 train = 0.991602 valid = 0.822908\n",
            "2022-01-09 22:07:48 - INFO:\ttrain #9790 lr = 3.76e-05 loss = 0.020300 train = 0.993945 valid = 0.824330\n",
            "2022-01-09 22:08:18 - INFO:\ttrain #9800 lr = 3.75e-05 loss = 0.023500 train = 0.991406 valid = 0.825955\n",
            "2022-01-09 22:08:22 - INFO:\tSaved test = 0.808752\n",
            "2022-01-09 22:08:52 - INFO:\ttrain #9810 lr = 3.75e-05 loss = 0.023685 train = 0.992383 valid = 0.819862\n",
            "2022-01-09 22:09:20 - INFO:\ttrain #9820 lr = 3.75e-05 loss = 0.025073 train = 0.991602 valid = 0.824330\n",
            "2022-01-09 22:09:48 - INFO:\ttrain #9830 lr = 3.74e-05 loss = 0.023931 train = 0.991992 valid = 0.820877\n",
            "2022-01-09 22:10:16 - INFO:\ttrain #9840 lr = 3.74e-05 loss = 0.022076 train = 0.992969 valid = 0.820877\n",
            "2022-01-09 22:10:44 - INFO:\ttrain #9850 lr = 3.73e-05 loss = 0.031163 train = 0.990430 valid = 0.825548\n",
            "2022-01-09 22:11:12 - INFO:\ttrain #9860 lr = 3.73e-05 loss = 0.020575 train = 0.992969 valid = 0.820268\n",
            "2022-01-09 22:11:39 - INFO:\ttrain #9870 lr = 3.73e-05 loss = 0.020850 train = 0.992773 valid = 0.822299\n",
            "2022-01-09 22:12:07 - INFO:\ttrain #9880 lr = 3.72e-05 loss = 0.018990 train = 0.994141 valid = 0.824330\n",
            "2022-01-09 22:12:34 - INFO:\ttrain #9890 lr = 3.72e-05 loss = 0.020589 train = 0.993359 valid = 0.823721\n",
            "2022-01-09 22:13:02 - INFO:\ttrain #9900 lr = 3.72e-05 loss = 0.023082 train = 0.992969 valid = 0.823314\n",
            "2022-01-09 22:13:05 - INFO:\tSaved test = 0.810373\n",
            "2022-01-09 22:13:33 - INFO:\ttrain #9910 lr = 3.71e-05 loss = 0.022577 train = 0.991992 valid = 0.821487\n",
            "2022-01-09 22:14:01 - INFO:\ttrain #9920 lr = 3.71e-05 loss = 0.017956 train = 0.994727 valid = 0.824736\n",
            "2022-01-09 22:14:28 - INFO:\ttrain #9930 lr = 3.70e-05 loss = 0.025228 train = 0.991992 valid = 0.821690\n",
            "2022-01-09 22:14:56 - INFO:\ttrain #9940 lr = 3.70e-05 loss = 0.020641 train = 0.993164 valid = 0.825955\n",
            "2022-01-09 22:15:24 - INFO:\ttrain #9950 lr = 3.70e-05 loss = 0.031188 train = 0.989062 valid = 0.816409\n",
            "2022-01-09 22:15:51 - INFO:\ttrain #9960 lr = 3.69e-05 loss = 0.030711 train = 0.989648 valid = 0.821080\n",
            "2022-01-09 22:16:19 - INFO:\ttrain #9970 lr = 3.69e-05 loss = 0.024709 train = 0.992188 valid = 0.829610\n",
            "2022-01-09 22:16:47 - INFO:\ttrain #9980 lr = 3.69e-05 loss = 0.024940 train = 0.991797 valid = 0.831641\n",
            "2022-01-09 22:17:14 - INFO:\ttrain #9990 lr = 3.68e-05 loss = 0.024598 train = 0.990430 valid = 0.821690\n",
            "2022-01-09 22:17:42 - INFO:\ttrain #10000 lr = 3.68e-05 loss = 0.020964 train = 0.993555 valid = 0.823111\n",
            "2022-01-09 22:17:46 - INFO:\tSaved test = 0.806726\n",
            "2022-01-09 22:18:13 - INFO:\ttrain #10010 lr = 3.67e-05 loss = 0.028574 train = 0.990234 valid = 0.811738\n",
            "2022-01-09 22:18:41 - INFO:\ttrain #10020 lr = 3.67e-05 loss = 0.029606 train = 0.989844 valid = 0.823314\n",
            "2022-01-09 22:19:09 - INFO:\ttrain #10030 lr = 3.67e-05 loss = 0.017978 train = 0.994531 valid = 0.830219\n",
            "2022-01-09 22:19:37 - INFO:\ttrain #10040 lr = 3.66e-05 loss = 0.020794 train = 0.992969 valid = 0.826361\n",
            "2022-01-09 22:20:04 - INFO:\ttrain #10050 lr = 3.66e-05 loss = 0.022563 train = 0.992773 valid = 0.821690\n",
            "2022-01-09 22:20:32 - INFO:\ttrain #10060 lr = 3.66e-05 loss = 0.020182 train = 0.992969 valid = 0.824533\n",
            "2022-01-09 22:20:59 - INFO:\ttrain #10070 lr = 3.65e-05 loss = 0.026972 train = 0.990820 valid = 0.824127\n",
            "2022-01-09 22:21:27 - INFO:\ttrain #10080 lr = 3.65e-05 loss = 0.016613 train = 0.995313 valid = 0.825142\n",
            "2022-01-09 22:21:54 - INFO:\ttrain #10090 lr = 3.65e-05 loss = 0.020767 train = 0.992383 valid = 0.825345\n",
            "2022-01-09 22:22:22 - INFO:\ttrain #10100 lr = 3.64e-05 loss = 0.019404 train = 0.993555 valid = 0.825548\n",
            "2022-01-09 22:22:26 - INFO:\tSaved test = 0.812804\n",
            "2022-01-09 22:22:54 - INFO:\ttrain #10110 lr = 3.64e-05 loss = 0.020920 train = 0.993750 valid = 0.821893\n",
            "2022-01-09 22:23:22 - INFO:\ttrain #10120 lr = 3.63e-05 loss = 0.018746 train = 0.995313 valid = 0.820674\n",
            "2022-01-09 22:23:49 - INFO:\ttrain #10130 lr = 3.63e-05 loss = 0.026635 train = 0.990234 valid = 0.823111\n",
            "2022-01-09 22:24:17 - INFO:\ttrain #10140 lr = 3.63e-05 loss = 0.016977 train = 0.994336 valid = 0.818846\n",
            "2022-01-09 22:24:45 - INFO:\ttrain #10150 lr = 3.62e-05 loss = 0.022867 train = 0.993555 valid = 0.821893\n",
            "2022-01-09 22:25:12 - INFO:\ttrain #10160 lr = 3.62e-05 loss = 0.021621 train = 0.992773 valid = 0.820065\n",
            "2022-01-09 22:25:40 - INFO:\ttrain #10170 lr = 3.62e-05 loss = 0.017252 train = 0.993555 valid = 0.826767\n",
            "2022-01-09 22:26:08 - INFO:\ttrain #10180 lr = 3.61e-05 loss = 0.025265 train = 0.992383 valid = 0.822908\n",
            "2022-01-09 22:26:35 - INFO:\ttrain #10190 lr = 3.61e-05 loss = 0.027565 train = 0.990820 valid = 0.821893\n",
            "2022-01-09 22:27:04 - INFO:\ttrain #10200 lr = 3.61e-05 loss = 0.019900 train = 0.993750 valid = 0.826970\n",
            "2022-01-09 22:27:07 - INFO:\tSaved test = 0.816045\n",
            "2022-01-09 22:27:35 - INFO:\ttrain #10210 lr = 3.60e-05 loss = 0.020866 train = 0.992578 valid = 0.823111\n",
            "2022-01-09 22:28:03 - INFO:\ttrain #10220 lr = 3.60e-05 loss = 0.019237 train = 0.995508 valid = 0.821690\n",
            "2022-01-09 22:28:31 - INFO:\ttrain #10230 lr = 3.59e-05 loss = 0.021353 train = 0.992969 valid = 0.818440\n",
            "2022-01-09 22:28:59 - INFO:\ttrain #10240 lr = 3.59e-05 loss = 0.030389 train = 0.990820 valid = 0.828798\n",
            "2022-01-09 22:29:27 - INFO:\ttrain #10250 lr = 3.59e-05 loss = 0.020627 train = 0.992969 valid = 0.812957\n",
            "2022-01-09 22:29:54 - INFO:\ttrain #10260 lr = 3.58e-05 loss = 0.024086 train = 0.992578 valid = 0.824330\n",
            "2022-01-09 22:30:22 - INFO:\ttrain #10270 lr = 3.58e-05 loss = 0.025620 train = 0.991992 valid = 0.818846\n",
            "2022-01-09 22:30:50 - INFO:\ttrain #10280 lr = 3.58e-05 loss = 0.022088 train = 0.992773 valid = 0.816816\n",
            "2022-01-09 22:31:18 - INFO:\ttrain #10290 lr = 3.57e-05 loss = 0.015163 train = 0.995313 valid = 0.823721\n",
            "2022-01-09 22:31:46 - INFO:\ttrain #10300 lr = 3.57e-05 loss = 0.017848 train = 0.993945 valid = 0.815800\n",
            "2022-01-09 22:31:50 - INFO:\tSaved test = 0.816045\n",
            "2022-01-09 22:32:18 - INFO:\ttrain #10310 lr = 3.57e-05 loss = 0.019510 train = 0.992773 valid = 0.821284\n",
            "2022-01-09 22:32:46 - INFO:\ttrain #10320 lr = 3.56e-05 loss = 0.019047 train = 0.993359 valid = 0.817222\n",
            "2022-01-09 22:33:14 - INFO:\ttrain #10330 lr = 3.56e-05 loss = 0.014031 train = 0.995898 valid = 0.820674\n",
            "2022-01-09 22:33:41 - INFO:\ttrain #10340 lr = 3.56e-05 loss = 0.016671 train = 0.994531 valid = 0.823517\n",
            "2022-01-09 22:34:09 - INFO:\ttrain #10350 lr = 3.55e-05 loss = 0.016137 train = 0.994727 valid = 0.822502\n",
            "2022-01-09 22:34:37 - INFO:\ttrain #10360 lr = 3.55e-05 loss = 0.022206 train = 0.992969 valid = 0.824330\n",
            "2022-01-09 22:35:06 - INFO:\ttrain #10370 lr = 3.54e-05 loss = 0.024348 train = 0.992773 valid = 0.819253\n",
            "2022-01-09 22:35:34 - INFO:\ttrain #10380 lr = 3.54e-05 loss = 0.020793 train = 0.992773 valid = 0.820674\n",
            "2022-01-09 22:36:02 - INFO:\ttrain #10390 lr = 3.54e-05 loss = 0.023590 train = 0.990430 valid = 0.819456\n",
            "2022-01-09 22:36:30 - INFO:\ttrain #10400 lr = 3.53e-05 loss = 0.021745 train = 0.993164 valid = 0.826970\n",
            "2022-01-09 22:36:33 - INFO:\tSaved test = 0.812399\n",
            "2022-01-09 22:37:01 - INFO:\ttrain #10410 lr = 3.53e-05 loss = 0.022784 train = 0.993359 valid = 0.823924\n",
            "2022-01-09 22:37:29 - INFO:\ttrain #10420 lr = 3.53e-05 loss = 0.025341 train = 0.991992 valid = 0.824533\n",
            "2022-01-09 22:37:57 - INFO:\ttrain #10430 lr = 3.52e-05 loss = 0.021591 train = 0.991797 valid = 0.822908\n",
            "2022-01-09 22:38:25 - INFO:\ttrain #10440 lr = 3.52e-05 loss = 0.016473 train = 0.994531 valid = 0.817222\n",
            "2022-01-09 22:38:53 - INFO:\ttrain #10450 lr = 3.52e-05 loss = 0.013547 train = 0.995508 valid = 0.819456\n",
            "2022-01-09 22:39:21 - INFO:\ttrain #10460 lr = 3.51e-05 loss = 0.020951 train = 0.993164 valid = 0.828798\n",
            "2022-01-09 22:39:49 - INFO:\ttrain #10470 lr = 3.51e-05 loss = 0.022374 train = 0.992188 valid = 0.829407\n",
            "2022-01-09 22:40:16 - INFO:\ttrain #10480 lr = 3.51e-05 loss = 0.023318 train = 0.992773 valid = 0.820674\n",
            "2022-01-09 22:40:44 - INFO:\ttrain #10490 lr = 3.50e-05 loss = 0.024081 train = 0.991406 valid = 0.822502\n",
            "2022-01-09 22:41:12 - INFO:\ttrain #10500 lr = 3.50e-05 loss = 0.026740 train = 0.991211 valid = 0.821284\n",
            "2022-01-09 22:41:15 - INFO:\tSaved test = 0.807536\n",
            "2022-01-09 22:41:43 - INFO:\ttrain #10510 lr = 3.50e-05 loss = 0.023418 train = 0.992773 valid = 0.821690\n",
            "2022-01-09 22:42:12 - INFO:\ttrain #10520 lr = 3.49e-05 loss = 0.024337 train = 0.991602 valid = 0.818846\n",
            "2022-01-09 22:42:40 - INFO:\ttrain #10530 lr = 3.49e-05 loss = 0.018288 train = 0.995313 valid = 0.822705\n",
            "2022-01-09 22:43:08 - INFO:\ttrain #10540 lr = 3.49e-05 loss = 0.026606 train = 0.990820 valid = 0.816003\n",
            "2022-01-09 22:43:36 - INFO:\ttrain #10550 lr = 3.48e-05 loss = 0.026331 train = 0.991016 valid = 0.819659\n",
            "2022-01-09 22:44:05 - INFO:\ttrain #10560 lr = 3.48e-05 loss = 0.023498 train = 0.992383 valid = 0.814379\n",
            "2022-01-09 22:44:33 - INFO:\ttrain #10570 lr = 3.47e-05 loss = 0.024962 train = 0.991211 valid = 0.818034\n",
            "2022-01-09 22:45:01 - INFO:\ttrain #10580 lr = 3.47e-05 loss = 0.020484 train = 0.993555 valid = 0.821080\n",
            "2022-01-09 22:45:28 - INFO:\ttrain #10590 lr = 3.47e-05 loss = 0.017170 train = 0.993750 valid = 0.815800\n",
            "2022-01-09 22:45:56 - INFO:\ttrain #10600 lr = 3.46e-05 loss = 0.020230 train = 0.992383 valid = 0.820877\n",
            "2022-01-09 22:45:59 - INFO:\tSaved test = 0.814019\n",
            "2022-01-09 22:46:26 - INFO:\ttrain #10610 lr = 3.46e-05 loss = 0.021523 train = 0.991211 valid = 0.820065\n",
            "2022-01-09 22:46:54 - INFO:\ttrain #10620 lr = 3.46e-05 loss = 0.021664 train = 0.992578 valid = 0.822908\n",
            "2022-01-09 22:47:22 - INFO:\ttrain #10630 lr = 3.45e-05 loss = 0.023945 train = 0.991992 valid = 0.824736\n",
            "2022-01-09 22:47:49 - INFO:\ttrain #10640 lr = 3.45e-05 loss = 0.018945 train = 0.992773 valid = 0.822299\n",
            "2022-01-09 22:48:17 - INFO:\ttrain #10650 lr = 3.45e-05 loss = 0.022491 train = 0.992969 valid = 0.826158\n",
            "2022-01-09 22:48:45 - INFO:\ttrain #10660 lr = 3.44e-05 loss = 0.020690 train = 0.993555 valid = 0.820674\n",
            "2022-01-09 22:49:12 - INFO:\ttrain #10670 lr = 3.44e-05 loss = 0.021269 train = 0.992578 valid = 0.820471\n",
            "2022-01-09 22:49:40 - INFO:\ttrain #10680 lr = 3.44e-05 loss = 0.024656 train = 0.991406 valid = 0.819456\n",
            "2022-01-09 22:50:08 - INFO:\ttrain #10690 lr = 3.43e-05 loss = 0.019801 train = 0.993750 valid = 0.822705\n",
            "2022-01-09 22:50:36 - INFO:\ttrain #10700 lr = 3.43e-05 loss = 0.021857 train = 0.992188 valid = 0.818440\n",
            "2022-01-09 22:50:39 - INFO:\tSaved test = 0.805916\n",
            "2022-01-09 22:51:07 - INFO:\ttrain #10710 lr = 3.43e-05 loss = 0.016993 train = 0.994141 valid = 0.820268\n",
            "2022-01-09 22:51:35 - INFO:\ttrain #10720 lr = 3.42e-05 loss = 0.024494 train = 0.991992 valid = 0.821284\n",
            "2022-01-09 22:52:03 - INFO:\ttrain #10730 lr = 3.42e-05 loss = 0.017638 train = 0.995508 valid = 0.823924\n",
            "2022-01-09 22:52:30 - INFO:\ttrain #10740 lr = 3.42e-05 loss = 0.012923 train = 0.996094 valid = 0.825345\n",
            "2022-01-09 22:52:58 - INFO:\ttrain #10750 lr = 3.41e-05 loss = 0.016774 train = 0.994922 valid = 0.825955\n",
            "2022-01-09 22:53:26 - INFO:\ttrain #10760 lr = 3.41e-05 loss = 0.016702 train = 0.995313 valid = 0.823721\n",
            "2022-01-09 22:53:54 - INFO:\ttrain #10770 lr = 3.41e-05 loss = 0.020092 train = 0.992773 valid = 0.825955\n",
            "2022-01-09 22:54:21 - INFO:\ttrain #10780 lr = 3.40e-05 loss = 0.011800 train = 0.997266 valid = 0.830219\n",
            "2022-01-09 22:54:49 - INFO:\ttrain #10790 lr = 3.40e-05 loss = 0.016933 train = 0.994531 valid = 0.822705\n",
            "2022-01-09 22:55:17 - INFO:\ttrain #10800 lr = 3.40e-05 loss = 0.017246 train = 0.994922 valid = 0.827376\n",
            "2022-01-09 22:55:21 - INFO:\tSaved test = 0.819287\n",
            "2022-01-09 22:55:49 - INFO:\ttrain #10810 lr = 3.39e-05 loss = 0.017005 train = 0.993750 valid = 0.821690\n",
            "2022-01-09 22:56:16 - INFO:\ttrain #10820 lr = 3.39e-05 loss = 0.016202 train = 0.994336 valid = 0.827376\n",
            "2022-01-09 22:56:44 - INFO:\ttrain #10830 lr = 3.39e-05 loss = 0.016870 train = 0.994922 valid = 0.822096\n",
            "2022-01-09 22:57:11 - INFO:\ttrain #10840 lr = 3.38e-05 loss = 0.019077 train = 0.994336 valid = 0.820471\n",
            "2022-01-09 22:57:39 - INFO:\ttrain #10850 lr = 3.38e-05 loss = 0.022003 train = 0.992969 valid = 0.822705\n",
            "2022-01-09 22:58:07 - INFO:\ttrain #10860 lr = 3.38e-05 loss = 0.018353 train = 0.992969 valid = 0.825955\n",
            "2022-01-09 22:58:35 - INFO:\ttrain #10870 lr = 3.37e-05 loss = 0.018676 train = 0.992969 valid = 0.827782\n",
            "2022-01-09 22:59:02 - INFO:\ttrain #10880 lr = 3.37e-05 loss = 0.027848 train = 0.990039 valid = 0.824127\n",
            "2022-01-09 22:59:30 - INFO:\ttrain #10890 lr = 3.37e-05 loss = 0.023531 train = 0.991211 valid = 0.821487\n",
            "2022-01-09 22:59:58 - INFO:\ttrain #10900 lr = 3.36e-05 loss = 0.020581 train = 0.993359 valid = 0.812754\n",
            "2022-01-09 23:00:01 - INFO:\tSaved test = 0.803890\n",
            "2022-01-09 23:00:29 - INFO:\ttrain #10910 lr = 3.36e-05 loss = 0.017020 train = 0.995313 valid = 0.825548\n",
            "2022-01-09 23:00:57 - INFO:\ttrain #10920 lr = 3.36e-05 loss = 0.024515 train = 0.991797 valid = 0.826970\n",
            "2022-01-09 23:01:25 - INFO:\ttrain #10930 lr = 3.35e-05 loss = 0.018022 train = 0.994531 valid = 0.822705\n",
            "2022-01-09 23:01:53 - INFO:\ttrain #10940 lr = 3.35e-05 loss = 0.013472 train = 0.996094 valid = 0.826970\n",
            "2022-01-09 23:02:22 - INFO:\ttrain #10950 lr = 3.35e-05 loss = 0.013855 train = 0.995703 valid = 0.826158\n",
            "2022-01-09 23:02:49 - INFO:\ttrain #10960 lr = 3.34e-05 loss = 0.010815 train = 0.997266 valid = 0.831032\n",
            "2022-01-09 23:03:17 - INFO:\ttrain #10970 lr = 3.34e-05 loss = 0.012096 train = 0.996484 valid = 0.820877\n",
            "2022-01-09 23:03:45 - INFO:\ttrain #10980 lr = 3.34e-05 loss = 0.016204 train = 0.995703 valid = 0.819253\n",
            "2022-01-09 23:04:13 - INFO:\ttrain #10990 lr = 3.33e-05 loss = 0.014857 train = 0.995117 valid = 0.814582\n",
            "2022-01-09 23:04:40 - INFO:\ttrain #11000 lr = 3.33e-05 loss = 0.016869 train = 0.994727 valid = 0.820877\n",
            "2022-01-09 23:04:44 - INFO:\tSaved test = 0.818071\n",
            "2022-01-09 23:05:12 - INFO:\ttrain #11010 lr = 3.33e-05 loss = 0.018199 train = 0.993555 valid = 0.821284\n",
            "2022-01-09 23:05:39 - INFO:\ttrain #11020 lr = 3.32e-05 loss = 0.016608 train = 0.994336 valid = 0.821080\n",
            "2022-01-09 23:06:07 - INFO:\ttrain #11030 lr = 3.32e-05 loss = 0.019677 train = 0.992578 valid = 0.821690\n",
            "2022-01-09 23:06:35 - INFO:\ttrain #11040 lr = 3.32e-05 loss = 0.018300 train = 0.995117 valid = 0.821893\n",
            "2022-01-09 23:07:02 - INFO:\ttrain #11050 lr = 3.31e-05 loss = 0.015775 train = 0.995313 valid = 0.825751\n",
            "2022-01-09 23:07:30 - INFO:\ttrain #11060 lr = 3.31e-05 loss = 0.017949 train = 0.995117 valid = 0.826361\n",
            "2022-01-09 23:07:58 - INFO:\ttrain #11070 lr = 3.31e-05 loss = 0.018351 train = 0.993945 valid = 0.820877\n",
            "2022-01-09 23:08:26 - INFO:\ttrain #11080 lr = 3.30e-05 loss = 0.016684 train = 0.994922 valid = 0.825345\n",
            "2022-01-09 23:08:54 - INFO:\ttrain #11090 lr = 3.30e-05 loss = 0.020673 train = 0.991797 valid = 0.816206\n",
            "2022-01-09 23:09:21 - INFO:\ttrain #11100 lr = 3.30e-05 loss = 0.019438 train = 0.993750 valid = 0.824127\n",
            "2022-01-09 23:09:25 - INFO:\tSaved test = 0.812399\n",
            "2022-01-09 23:09:53 - INFO:\ttrain #11110 lr = 3.29e-05 loss = 0.013664 train = 0.996484 valid = 0.824533\n",
            "2022-01-09 23:10:21 - INFO:\ttrain #11120 lr = 3.29e-05 loss = 0.018183 train = 0.994336 valid = 0.817425\n",
            "2022-01-09 23:10:51 - INFO:\ttrain #11130 lr = 3.29e-05 loss = 0.010419 train = 0.996289 valid = 0.823721\n",
            "2022-01-09 23:11:19 - INFO:\ttrain #11140 lr = 3.28e-05 loss = 0.013946 train = 0.995898 valid = 0.825751\n",
            "2022-01-09 23:11:48 - INFO:\ttrain #11150 lr = 3.28e-05 loss = 0.019130 train = 0.992773 valid = 0.818237\n",
            "2022-01-09 23:12:16 - INFO:\ttrain #11160 lr = 3.28e-05 loss = 0.016318 train = 0.994531 valid = 0.828798\n",
            "2022-01-09 23:12:45 - INFO:\ttrain #11170 lr = 3.27e-05 loss = 0.017123 train = 0.994336 valid = 0.820268\n",
            "2022-01-09 23:13:13 - INFO:\ttrain #11180 lr = 3.27e-05 loss = 0.013868 train = 0.994922 valid = 0.825955\n",
            "2022-01-09 23:13:41 - INFO:\ttrain #11190 lr = 3.27e-05 loss = 0.016371 train = 0.994336 valid = 0.818237\n",
            "2022-01-09 23:14:10 - INFO:\ttrain #11200 lr = 3.26e-05 loss = 0.018567 train = 0.995508 valid = 0.822096\n",
            "2022-01-09 23:14:14 - INFO:\tSaved test = 0.818882\n",
            "2022-01-09 23:14:43 - INFO:\ttrain #11210 lr = 3.26e-05 loss = 0.017218 train = 0.994336 valid = 0.818846\n",
            "2022-01-09 23:15:11 - INFO:\ttrain #11220 lr = 3.26e-05 loss = 0.026063 train = 0.991211 valid = 0.821487\n",
            "2022-01-09 23:15:39 - INFO:\ttrain #11230 lr = 3.25e-05 loss = 0.014724 train = 0.995313 valid = 0.822299\n",
            "2022-01-09 23:16:08 - INFO:\ttrain #11240 lr = 3.25e-05 loss = 0.017166 train = 0.994531 valid = 0.828392\n",
            "2022-01-09 23:16:37 - INFO:\ttrain #11250 lr = 3.25e-05 loss = 0.016033 train = 0.993945 valid = 0.827376\n",
            "2022-01-09 23:17:05 - INFO:\ttrain #11260 lr = 3.24e-05 loss = 0.014668 train = 0.995313 valid = 0.820877\n",
            "2022-01-09 23:17:34 - INFO:\ttrain #11270 lr = 3.24e-05 loss = 0.018139 train = 0.994727 valid = 0.803615\n",
            "2022-01-09 23:18:02 - INFO:\ttrain #11280 lr = 3.24e-05 loss = 0.015178 train = 0.995703 valid = 0.830626\n",
            "2022-01-09 23:18:31 - INFO:\ttrain #11290 lr = 3.23e-05 loss = 0.017962 train = 0.993164 valid = 0.826361\n",
            "2022-01-09 23:18:59 - INFO:\ttrain #11300 lr = 3.23e-05 loss = 0.020975 train = 0.992188 valid = 0.828798\n",
            "2022-01-09 23:19:03 - INFO:\tSaved test = 0.817666\n",
            "2022-01-09 23:19:32 - INFO:\ttrain #11310 lr = 3.23e-05 loss = 0.016210 train = 0.995117 valid = 0.826361\n",
            "2022-01-09 23:20:01 - INFO:\ttrain #11320 lr = 3.22e-05 loss = 0.012857 train = 0.995703 valid = 0.826564\n",
            "2022-01-09 23:20:30 - INFO:\ttrain #11330 lr = 3.22e-05 loss = 0.015506 train = 0.994141 valid = 0.816409\n",
            "2022-01-09 23:20:58 - INFO:\ttrain #11340 lr = 3.22e-05 loss = 0.017440 train = 0.995508 valid = 0.820268\n",
            "2022-01-09 23:21:26 - INFO:\ttrain #11350 lr = 3.21e-05 loss = 0.014291 train = 0.995508 valid = 0.824736\n",
            "2022-01-09 23:21:54 - INFO:\ttrain #11360 lr = 3.21e-05 loss = 0.011229 train = 0.997852 valid = 0.826767\n",
            "2022-01-09 23:22:21 - INFO:\ttrain #11370 lr = 3.21e-05 loss = 0.011619 train = 0.997461 valid = 0.825548\n",
            "2022-01-09 23:22:49 - INFO:\ttrain #11380 lr = 3.20e-05 loss = 0.013627 train = 0.996484 valid = 0.824127\n",
            "2022-01-09 23:23:18 - INFO:\ttrain #11390 lr = 3.20e-05 loss = 0.014986 train = 0.995508 valid = 0.823111\n",
            "2022-01-09 23:23:47 - INFO:\ttrain #11400 lr = 3.20e-05 loss = 0.013238 train = 0.995898 valid = 0.817831\n",
            "2022-01-09 23:23:51 - INFO:\tSaved test = 0.811588\n",
            "2022-01-09 23:24:20 - INFO:\ttrain #11410 lr = 3.19e-05 loss = 0.014770 train = 0.995508 valid = 0.824330\n",
            "2022-01-09 23:24:48 - INFO:\ttrain #11420 lr = 3.19e-05 loss = 0.013393 train = 0.995703 valid = 0.822908\n",
            "2022-01-09 23:25:16 - INFO:\ttrain #11430 lr = 3.19e-05 loss = 0.028287 train = 0.991406 valid = 0.822096\n",
            "2022-01-09 23:25:45 - INFO:\ttrain #11440 lr = 3.19e-05 loss = 0.020544 train = 0.993945 valid = 0.823111\n",
            "2022-01-09 23:26:14 - INFO:\ttrain #11450 lr = 3.18e-05 loss = 0.018236 train = 0.994336 valid = 0.819862\n",
            "2022-01-09 23:26:43 - INFO:\ttrain #11460 lr = 3.18e-05 loss = 0.026835 train = 0.992188 valid = 0.819456\n",
            "2022-01-09 23:27:11 - INFO:\ttrain #11470 lr = 3.18e-05 loss = 0.017905 train = 0.995508 valid = 0.825345\n",
            "2022-01-09 23:27:40 - INFO:\ttrain #11480 lr = 3.17e-05 loss = 0.019757 train = 0.993164 valid = 0.823517\n",
            "2022-01-09 23:28:08 - INFO:\ttrain #11490 lr = 3.17e-05 loss = 0.015451 train = 0.995313 valid = 0.824736\n",
            "2022-01-09 23:28:36 - INFO:\ttrain #11500 lr = 3.17e-05 loss = 0.017450 train = 0.994531 valid = 0.818643\n",
            "2022-01-09 23:28:40 - INFO:\tSaved test = 0.809562\n",
            "2022-01-09 23:29:08 - INFO:\ttrain #11510 lr = 3.16e-05 loss = 0.014014 train = 0.995703 valid = 0.828595\n",
            "2022-01-09 23:29:37 - INFO:\ttrain #11520 lr = 3.16e-05 loss = 0.016517 train = 0.995117 valid = 0.820268\n",
            "2022-01-09 23:30:05 - INFO:\ttrain #11530 lr = 3.16e-05 loss = 0.015858 train = 0.994727 valid = 0.823314\n",
            "2022-01-09 23:30:34 - INFO:\ttrain #11540 lr = 3.15e-05 loss = 0.014450 train = 0.994922 valid = 0.822908\n",
            "2022-01-09 23:31:02 - INFO:\ttrain #11550 lr = 3.15e-05 loss = 0.014813 train = 0.994922 valid = 0.821893\n",
            "2022-01-09 23:31:31 - INFO:\ttrain #11560 lr = 3.15e-05 loss = 0.013976 train = 0.995313 valid = 0.821893\n",
            "2022-01-09 23:32:00 - INFO:\ttrain #11570 lr = 3.14e-05 loss = 0.014739 train = 0.994531 valid = 0.816816\n",
            "2022-01-09 23:32:28 - INFO:\ttrain #11580 lr = 3.14e-05 loss = 0.016113 train = 0.994336 valid = 0.826767\n",
            "2022-01-09 23:32:58 - INFO:\ttrain #11590 lr = 3.14e-05 loss = 0.017486 train = 0.993945 valid = 0.826361\n",
            "2022-01-09 23:33:26 - INFO:\ttrain #11600 lr = 3.13e-05 loss = 0.013372 train = 0.995703 valid = 0.822908\n",
            "2022-01-09 23:33:30 - INFO:\tSaved test = 0.823744\n",
            "2022-01-09 23:33:58 - INFO:\ttrain #11610 lr = 3.13e-05 loss = 0.014463 train = 0.996289 valid = 0.827985\n",
            "2022-01-09 23:34:25 - INFO:\ttrain #11620 lr = 3.13e-05 loss = 0.012081 train = 0.996289 valid = 0.823517\n",
            "2022-01-09 23:34:53 - INFO:\ttrain #11630 lr = 3.13e-05 loss = 0.018756 train = 0.994531 valid = 0.827985\n",
            "2022-01-09 23:35:21 - INFO:\ttrain #11640 lr = 3.12e-05 loss = 0.013209 train = 0.996484 valid = 0.826361\n",
            "2022-01-09 23:35:49 - INFO:\ttrain #11650 lr = 3.12e-05 loss = 0.015458 train = 0.994336 valid = 0.826361\n",
            "2022-01-09 23:36:16 - INFO:\ttrain #11660 lr = 3.12e-05 loss = 0.011899 train = 0.996484 valid = 0.826564\n",
            "2022-01-09 23:36:44 - INFO:\ttrain #11670 lr = 3.11e-05 loss = 0.014169 train = 0.995117 valid = 0.826361\n",
            "2022-01-09 23:37:11 - INFO:\ttrain #11680 lr = 3.11e-05 loss = 0.013490 train = 0.995703 valid = 0.824127\n",
            "2022-01-09 23:37:39 - INFO:\ttrain #11690 lr = 3.11e-05 loss = 0.011843 train = 0.996875 valid = 0.823111\n",
            "2022-01-09 23:38:06 - INFO:\ttrain #11700 lr = 3.10e-05 loss = 0.018797 train = 0.993555 valid = 0.824127\n",
            "2022-01-09 23:38:10 - INFO:\tSaved test = 0.811994\n",
            "2022-01-09 23:38:38 - INFO:\ttrain #11710 lr = 3.10e-05 loss = 0.012629 train = 0.995898 valid = 0.827985\n",
            "2022-01-09 23:39:06 - INFO:\ttrain #11720 lr = 3.10e-05 loss = 0.015580 train = 0.993945 valid = 0.826970\n",
            "2022-01-09 23:39:34 - INFO:\ttrain #11730 lr = 3.09e-05 loss = 0.013524 train = 0.996289 valid = 0.827173\n",
            "2022-01-09 23:40:02 - INFO:\ttrain #11740 lr = 3.09e-05 loss = 0.011925 train = 0.996289 valid = 0.833063 updated\n",
            "2022-01-09 23:40:29 - INFO:\ttrain #11750 lr = 3.09e-05 loss = 0.014766 train = 0.995508 valid = 0.824127\n",
            "2022-01-09 23:40:57 - INFO:\ttrain #11760 lr = 3.08e-05 loss = 0.016952 train = 0.995313 valid = 0.823924\n",
            "2022-01-09 23:41:25 - INFO:\ttrain #11770 lr = 3.08e-05 loss = 0.013397 train = 0.996484 valid = 0.822096\n",
            "2022-01-09 23:41:53 - INFO:\ttrain #11780 lr = 3.08e-05 loss = 0.017725 train = 0.995117 valid = 0.827782\n",
            "2022-01-09 23:42:21 - INFO:\ttrain #11790 lr = 3.08e-05 loss = 0.022905 train = 0.991992 valid = 0.823721\n",
            "2022-01-09 23:42:48 - INFO:\ttrain #11800 lr = 3.07e-05 loss = 0.017883 train = 0.994922 valid = 0.832453\n",
            "2022-01-09 23:42:52 - INFO:\tSaved test = 0.816856\n",
            "2022-01-09 23:43:20 - INFO:\ttrain #11810 lr = 3.07e-05 loss = 0.012433 train = 0.996484 valid = 0.817628\n",
            "2022-01-09 23:43:47 - INFO:\ttrain #11820 lr = 3.07e-05 loss = 0.017544 train = 0.993945 valid = 0.829001\n",
            "2022-01-09 23:44:15 - INFO:\ttrain #11830 lr = 3.06e-05 loss = 0.012087 train = 0.995508 valid = 0.830626\n",
            "2022-01-09 23:44:43 - INFO:\ttrain #11840 lr = 3.06e-05 loss = 0.013115 train = 0.994727 valid = 0.828392\n",
            "2022-01-09 23:45:11 - INFO:\ttrain #11850 lr = 3.06e-05 loss = 0.017382 train = 0.994727 valid = 0.823314\n",
            "2022-01-09 23:45:40 - INFO:\ttrain #11860 lr = 3.05e-05 loss = 0.012557 train = 0.995898 valid = 0.822908\n",
            "2022-01-09 23:46:08 - INFO:\ttrain #11870 lr = 3.05e-05 loss = 0.015592 train = 0.995117 valid = 0.824939\n",
            "2022-01-09 23:46:36 - INFO:\ttrain #11880 lr = 3.05e-05 loss = 0.015369 train = 0.996289 valid = 0.829407\n",
            "2022-01-09 23:47:03 - INFO:\ttrain #11890 lr = 3.05e-05 loss = 0.015948 train = 0.994141 valid = 0.828798\n",
            "2022-01-09 23:47:31 - INFO:\ttrain #11900 lr = 3.04e-05 loss = 0.016950 train = 0.993555 valid = 0.826767\n",
            "2022-01-09 23:47:35 - INFO:\tSaved test = 0.814425\n",
            "2022-01-09 23:48:02 - INFO:\ttrain #11910 lr = 3.04e-05 loss = 0.015989 train = 0.995313 valid = 0.828595\n",
            "2022-01-09 23:48:30 - INFO:\ttrain #11920 lr = 3.04e-05 loss = 0.016939 train = 0.994531 valid = 0.823517\n",
            "2022-01-09 23:48:57 - INFO:\ttrain #11930 lr = 3.03e-05 loss = 0.016600 train = 0.994141 valid = 0.826361\n",
            "2022-01-09 23:49:25 - INFO:\ttrain #11940 lr = 3.03e-05 loss = 0.026203 train = 0.991992 valid = 0.818846\n",
            "2022-01-09 23:49:53 - INFO:\ttrain #11950 lr = 3.03e-05 loss = 0.014646 train = 0.994922 valid = 0.822908\n",
            "2022-01-09 23:50:20 - INFO:\ttrain #11960 lr = 3.02e-05 loss = 0.014780 train = 0.995703 valid = 0.820877\n",
            "2022-01-09 23:50:48 - INFO:\ttrain #11970 lr = 3.02e-05 loss = 0.015227 train = 0.994727 valid = 0.826158\n",
            "2022-01-09 23:51:16 - INFO:\ttrain #11980 lr = 3.02e-05 loss = 0.012827 train = 0.996094 valid = 0.825142\n",
            "2022-01-09 23:51:44 - INFO:\ttrain #11990 lr = 3.01e-05 loss = 0.010008 train = 0.996875 valid = 0.825142\n",
            "2022-01-09 23:52:11 - INFO:\ttrain #12000 lr = 3.01e-05 loss = 0.010488 train = 0.997070 valid = 0.822096\n",
            "2022-01-09 23:52:15 - INFO:\tSaved test = 0.823744\n",
            "2022-01-09 23:52:42 - INFO:\ttrain #12010 lr = 3.01e-05 loss = 0.010005 train = 0.997266 valid = 0.823517\n",
            "2022-01-09 23:53:10 - INFO:\ttrain #12020 lr = 3.01e-05 loss = 0.013477 train = 0.995898 valid = 0.821690\n",
            "2022-01-09 23:53:38 - INFO:\ttrain #12030 lr = 3.00e-05 loss = 0.012392 train = 0.996484 valid = 0.825345\n",
            "2022-01-09 23:54:06 - INFO:\ttrain #12040 lr = 3.00e-05 loss = 0.011480 train = 0.996094 valid = 0.822299\n",
            "2022-01-09 23:54:34 - INFO:\ttrain #12050 lr = 3.00e-05 loss = 0.017134 train = 0.994727 valid = 0.820065\n",
            "2022-01-09 23:55:01 - INFO:\ttrain #12060 lr = 2.99e-05 loss = 0.010628 train = 0.996484 valid = 0.831032\n",
            "2022-01-09 23:55:29 - INFO:\ttrain #12070 lr = 2.99e-05 loss = 0.012385 train = 0.995898 valid = 0.828595\n",
            "2022-01-09 23:55:57 - INFO:\ttrain #12080 lr = 2.99e-05 loss = 0.009858 train = 0.996875 valid = 0.830626\n",
            "2022-01-09 23:56:25 - INFO:\ttrain #12090 lr = 2.98e-05 loss = 0.016944 train = 0.994141 valid = 0.830626\n",
            "2022-01-09 23:56:52 - INFO:\ttrain #12100 lr = 2.98e-05 loss = 0.012881 train = 0.995898 valid = 0.826361\n",
            "2022-01-09 23:56:56 - INFO:\tSaved test = 0.808752\n",
            "2022-01-09 23:57:24 - INFO:\ttrain #12110 lr = 2.98e-05 loss = 0.015097 train = 0.994727 valid = 0.824736\n",
            "2022-01-09 23:57:52 - INFO:\ttrain #12120 lr = 2.98e-05 loss = 0.017603 train = 0.994922 valid = 0.826564\n",
            "2022-01-09 23:58:19 - INFO:\ttrain #12130 lr = 2.97e-05 loss = 0.012860 train = 0.995313 valid = 0.827376\n",
            "2022-01-09 23:58:47 - INFO:\ttrain #12140 lr = 2.97e-05 loss = 0.013596 train = 0.995703 valid = 0.829407\n",
            "2022-01-09 23:59:14 - INFO:\ttrain #12150 lr = 2.97e-05 loss = 0.018791 train = 0.992969 valid = 0.827376\n",
            "2022-01-09 23:59:42 - INFO:\ttrain #12160 lr = 2.96e-05 loss = 0.014575 train = 0.996094 valid = 0.825751\n",
            "2022-01-10 00:00:10 - INFO:\ttrain #12170 lr = 2.96e-05 loss = 0.016342 train = 0.994141 valid = 0.827579\n",
            "2022-01-10 00:00:38 - INFO:\ttrain #12180 lr = 2.96e-05 loss = 0.016035 train = 0.994141 valid = 0.826564\n",
            "2022-01-10 00:01:06 - INFO:\ttrain #12190 lr = 2.96e-05 loss = 0.010780 train = 0.997070 valid = 0.828188\n",
            "2022-01-10 00:01:34 - INFO:\ttrain #12200 lr = 2.95e-05 loss = 0.010038 train = 0.996875 valid = 0.823517\n",
            "2022-01-10 00:01:38 - INFO:\tSaved test = 0.820908\n",
            "2022-01-10 00:02:05 - INFO:\ttrain #12210 lr = 2.95e-05 loss = 0.010935 train = 0.996094 valid = 0.816816\n",
            "2022-01-10 00:02:33 - INFO:\ttrain #12220 lr = 2.95e-05 loss = 0.012445 train = 0.996094 valid = 0.823721\n",
            "2022-01-10 00:03:00 - INFO:\ttrain #12230 lr = 2.94e-05 loss = 0.009417 train = 0.997656 valid = 0.822096\n",
            "2022-01-10 00:03:28 - INFO:\ttrain #12240 lr = 2.94e-05 loss = 0.012695 train = 0.996875 valid = 0.824330\n",
            "2022-01-10 00:03:55 - INFO:\ttrain #12250 lr = 2.94e-05 loss = 0.011844 train = 0.996484 valid = 0.828595\n",
            "2022-01-10 00:04:23 - INFO:\ttrain #12260 lr = 2.93e-05 loss = 0.013433 train = 0.995898 valid = 0.825548\n",
            "2022-01-10 00:04:51 - INFO:\ttrain #12270 lr = 2.93e-05 loss = 0.013873 train = 0.996484 valid = 0.822908\n",
            "2022-01-10 00:05:18 - INFO:\ttrain #12280 lr = 2.93e-05 loss = 0.014057 train = 0.995117 valid = 0.820268\n",
            "2022-01-10 00:05:47 - INFO:\ttrain #12290 lr = 2.93e-05 loss = 0.016497 train = 0.994141 valid = 0.824330\n",
            "2022-01-10 00:06:15 - INFO:\ttrain #12300 lr = 2.92e-05 loss = 0.018095 train = 0.994531 valid = 0.824330\n",
            "2022-01-10 00:06:18 - INFO:\tSaved test = 0.817666\n",
            "2022-01-10 00:06:46 - INFO:\ttrain #12310 lr = 2.92e-05 loss = 0.013787 train = 0.995313 valid = 0.820268\n",
            "2022-01-10 00:07:14 - INFO:\ttrain #12320 lr = 2.92e-05 loss = 0.013228 train = 0.997070 valid = 0.822908\n",
            "2022-01-10 00:07:41 - INFO:\ttrain #12330 lr = 2.91e-05 loss = 0.015096 train = 0.995117 valid = 0.819456\n",
            "2022-01-10 00:08:09 - INFO:\ttrain #12340 lr = 2.91e-05 loss = 0.011932 train = 0.996289 valid = 0.826158\n",
            "2022-01-10 00:08:37 - INFO:\ttrain #12350 lr = 2.91e-05 loss = 0.016920 train = 0.995313 valid = 0.820674\n",
            "2022-01-10 00:09:05 - INFO:\ttrain #12360 lr = 2.91e-05 loss = 0.014071 train = 0.994727 valid = 0.821690\n",
            "2022-01-10 00:09:33 - INFO:\ttrain #12370 lr = 2.90e-05 loss = 0.013544 train = 0.995508 valid = 0.824330\n",
            "2022-01-10 00:10:00 - INFO:\ttrain #12380 lr = 2.90e-05 loss = 0.010393 train = 0.997461 valid = 0.823314\n",
            "2022-01-10 00:10:28 - INFO:\ttrain #12390 lr = 2.90e-05 loss = 0.011488 train = 0.996484 valid = 0.823721\n",
            "2022-01-10 00:10:56 - INFO:\ttrain #12400 lr = 2.89e-05 loss = 0.016511 train = 0.994336 valid = 0.820674\n",
            "2022-01-10 00:11:00 - INFO:\tSaved test = 0.808752\n",
            "2022-01-10 00:11:27 - INFO:\ttrain #12410 lr = 2.89e-05 loss = 0.013839 train = 0.995703 valid = 0.817831\n",
            "2022-01-10 00:11:55 - INFO:\ttrain #12420 lr = 2.89e-05 loss = 0.011629 train = 0.996875 valid = 0.826970\n",
            "2022-01-10 00:12:23 - INFO:\ttrain #12430 lr = 2.88e-05 loss = 0.011214 train = 0.997266 valid = 0.820268\n",
            "2022-01-10 00:12:50 - INFO:\ttrain #12440 lr = 2.88e-05 loss = 0.014570 train = 0.994922 valid = 0.825548\n",
            "2022-01-10 00:13:18 - INFO:\ttrain #12450 lr = 2.88e-05 loss = 0.011221 train = 0.996094 valid = 0.823517\n",
            "2022-01-10 00:13:46 - INFO:\ttrain #12460 lr = 2.88e-05 loss = 0.016066 train = 0.994727 valid = 0.826564\n",
            "2022-01-10 00:14:14 - INFO:\ttrain #12470 lr = 2.87e-05 loss = 0.019335 train = 0.993164 valid = 0.819862\n",
            "2022-01-10 00:14:42 - INFO:\ttrain #12480 lr = 2.87e-05 loss = 0.013858 train = 0.995117 valid = 0.821080\n",
            "2022-01-10 00:15:10 - INFO:\ttrain #12490 lr = 2.87e-05 loss = 0.011968 train = 0.995898 valid = 0.821893\n",
            "2022-01-10 00:15:37 - INFO:\ttrain #12500 lr = 2.86e-05 loss = 0.012560 train = 0.996094 valid = 0.824736\n",
            "2022-01-10 00:15:40 - INFO:\tSaved test = 0.821313\n",
            "2022-01-10 00:16:08 - INFO:\ttrain #12510 lr = 2.86e-05 loss = 0.013289 train = 0.995898 valid = 0.829001\n",
            "2022-01-10 00:16:35 - INFO:\ttrain #12520 lr = 2.86e-05 loss = 0.014072 train = 0.995313 valid = 0.826564\n",
            "2022-01-10 00:17:02 - INFO:\ttrain #12530 lr = 2.86e-05 loss = 0.011537 train = 0.996875 valid = 0.824127\n",
            "2022-01-10 00:17:30 - INFO:\ttrain #12540 lr = 2.85e-05 loss = 0.009796 train = 0.996680 valid = 0.820471\n",
            "2022-01-10 00:17:57 - INFO:\ttrain #12550 lr = 2.85e-05 loss = 0.007074 train = 0.997852 valid = 0.827579\n",
            "2022-01-10 00:18:25 - INFO:\ttrain #12560 lr = 2.85e-05 loss = 0.009591 train = 0.996875 valid = 0.825955\n",
            "2022-01-10 00:18:53 - INFO:\ttrain #12570 lr = 2.84e-05 loss = 0.009096 train = 0.997656 valid = 0.823721\n",
            "2022-01-10 00:19:21 - INFO:\ttrain #12580 lr = 2.84e-05 loss = 0.014218 train = 0.994336 valid = 0.819253\n",
            "2022-01-10 00:19:49 - INFO:\ttrain #12590 lr = 2.84e-05 loss = 0.010227 train = 0.996875 valid = 0.822299\n",
            "2022-01-10 00:20:16 - INFO:\ttrain #12600 lr = 2.84e-05 loss = 0.009170 train = 0.997266 valid = 0.819456\n",
            "2022-01-10 00:20:20 - INFO:\tSaved test = 0.816451\n",
            "2022-01-10 00:20:48 - INFO:\ttrain #12610 lr = 2.83e-05 loss = 0.011534 train = 0.996484 valid = 0.817222\n",
            "2022-01-10 00:21:17 - INFO:\ttrain #12620 lr = 2.83e-05 loss = 0.012396 train = 0.995508 valid = 0.821080\n",
            "2022-01-10 00:21:46 - INFO:\ttrain #12630 lr = 2.83e-05 loss = 0.009471 train = 0.996680 valid = 0.825548\n",
            "2022-01-10 00:22:13 - INFO:\ttrain #12640 lr = 2.83e-05 loss = 0.010183 train = 0.996289 valid = 0.824939\n",
            "2022-01-10 00:22:41 - INFO:\ttrain #12650 lr = 2.82e-05 loss = 0.018984 train = 0.993945 valid = 0.821690\n",
            "2022-01-10 00:23:09 - INFO:\ttrain #12660 lr = 2.82e-05 loss = 0.017642 train = 0.994531 valid = 0.813972\n",
            "2022-01-10 00:23:37 - INFO:\ttrain #12670 lr = 2.82e-05 loss = 0.017873 train = 0.994336 valid = 0.816613\n",
            "2022-01-10 00:24:05 - INFO:\ttrain #12680 lr = 2.81e-05 loss = 0.012680 train = 0.996484 valid = 0.820471\n",
            "2022-01-10 00:24:33 - INFO:\ttrain #12690 lr = 2.81e-05 loss = 0.013307 train = 0.996094 valid = 0.826564\n",
            "2022-01-10 00:25:01 - INFO:\ttrain #12700 lr = 2.81e-05 loss = 0.016489 train = 0.994727 valid = 0.822299\n",
            "2022-01-10 00:25:04 - INFO:\tSaved test = 0.811183\n",
            "2022-01-10 00:25:32 - INFO:\ttrain #12710 lr = 2.81e-05 loss = 0.009760 train = 0.997852 valid = 0.824736\n",
            "2022-01-10 00:26:00 - INFO:\ttrain #12720 lr = 2.80e-05 loss = 0.010389 train = 0.997070 valid = 0.822502\n",
            "2022-01-10 00:26:27 - INFO:\ttrain #12730 lr = 2.80e-05 loss = 0.015570 train = 0.994531 valid = 0.826970\n",
            "2022-01-10 00:26:55 - INFO:\ttrain #12740 lr = 2.80e-05 loss = 0.010616 train = 0.996094 valid = 0.826970\n",
            "2022-01-10 00:27:23 - INFO:\ttrain #12750 lr = 2.79e-05 loss = 0.013547 train = 0.995898 valid = 0.821284\n",
            "2022-01-10 00:27:50 - INFO:\ttrain #12760 lr = 2.79e-05 loss = 0.009872 train = 0.997461 valid = 0.823314\n",
            "2022-01-10 00:28:18 - INFO:\ttrain #12770 lr = 2.79e-05 loss = 0.010042 train = 0.996289 valid = 0.826970\n",
            "2022-01-10 00:28:45 - INFO:\ttrain #12780 lr = 2.79e-05 loss = 0.011826 train = 0.996484 valid = 0.823314\n",
            "2022-01-10 00:29:12 - INFO:\ttrain #12790 lr = 2.78e-05 loss = 0.012125 train = 0.996094 valid = 0.822502\n",
            "2022-01-10 00:29:40 - INFO:\ttrain #12800 lr = 2.78e-05 loss = 0.009406 train = 0.996875 valid = 0.821487\n",
            "2022-01-10 00:29:43 - INFO:\tSaved test = 0.822934\n",
            "2022-01-10 00:30:11 - INFO:\ttrain #12810 lr = 2.78e-05 loss = 0.009402 train = 0.997266 valid = 0.826564\n",
            "2022-01-10 00:30:38 - INFO:\ttrain #12820 lr = 2.77e-05 loss = 0.008238 train = 0.997070 valid = 0.830219\n",
            "2022-01-10 00:31:06 - INFO:\ttrain #12830 lr = 2.77e-05 loss = 0.011127 train = 0.995703 valid = 0.822908\n",
            "2022-01-10 00:31:34 - INFO:\ttrain #12840 lr = 2.77e-05 loss = 0.009530 train = 0.997656 valid = 0.827782\n",
            "2022-01-10 00:32:02 - INFO:\ttrain #12850 lr = 2.77e-05 loss = 0.006073 train = 0.998633 valid = 0.827376\n",
            "2022-01-10 00:32:30 - INFO:\ttrain #12860 lr = 2.76e-05 loss = 0.015918 train = 0.994336 valid = 0.825751\n",
            "2022-01-10 00:32:57 - INFO:\ttrain #12870 lr = 2.76e-05 loss = 0.014801 train = 0.995508 valid = 0.826158\n",
            "2022-01-10 00:33:24 - INFO:\ttrain #12880 lr = 2.76e-05 loss = 0.016324 train = 0.994141 valid = 0.816816\n",
            "2022-01-10 00:33:52 - INFO:\ttrain #12890 lr = 2.76e-05 loss = 0.012851 train = 0.995898 valid = 0.821284\n",
            "2022-01-10 00:34:19 - INFO:\ttrain #12900 lr = 2.75e-05 loss = 0.011603 train = 0.996094 valid = 0.827376\n",
            "2022-01-10 00:34:22 - INFO:\tSaved test = 0.820097\n",
            "2022-01-10 00:34:50 - INFO:\ttrain #12910 lr = 2.75e-05 loss = 0.012785 train = 0.995898 valid = 0.827173\n",
            "2022-01-10 00:35:17 - INFO:\ttrain #12920 lr = 2.75e-05 loss = 0.010235 train = 0.997070 valid = 0.823111\n",
            "2022-01-10 00:35:44 - INFO:\ttrain #12930 lr = 2.74e-05 loss = 0.013832 train = 0.995508 valid = 0.820674\n",
            "2022-01-10 00:36:12 - INFO:\ttrain #12940 lr = 2.74e-05 loss = 0.010556 train = 0.996875 valid = 0.823517\n",
            "2022-01-10 00:36:39 - INFO:\ttrain #12950 lr = 2.74e-05 loss = 0.007173 train = 0.997656 valid = 0.826767\n",
            "2022-01-10 00:37:06 - INFO:\ttrain #12960 lr = 2.74e-05 loss = 0.009313 train = 0.997070 valid = 0.826158\n",
            "2022-01-10 00:37:34 - INFO:\ttrain #12970 lr = 2.73e-05 loss = 0.008398 train = 0.997852 valid = 0.816613\n",
            "2022-01-10 00:38:01 - INFO:\ttrain #12980 lr = 2.73e-05 loss = 0.011205 train = 0.996680 valid = 0.825548\n",
            "2022-01-10 00:38:29 - INFO:\ttrain #12990 lr = 2.73e-05 loss = 0.015052 train = 0.994336 valid = 0.828188\n",
            "2022-01-10 00:38:57 - INFO:\ttrain #13000 lr = 2.73e-05 loss = 0.011789 train = 0.996680 valid = 0.828392\n",
            "2022-01-10 00:39:00 - INFO:\tSaved test = 0.810373\n",
            "2022-01-10 00:39:28 - INFO:\ttrain #13010 lr = 2.72e-05 loss = 0.011445 train = 0.996875 valid = 0.828188\n",
            "2022-01-10 00:39:55 - INFO:\ttrain #13020 lr = 2.72e-05 loss = 0.009833 train = 0.997070 valid = 0.826564\n",
            "2022-01-10 00:40:23 - INFO:\ttrain #13030 lr = 2.72e-05 loss = 0.008785 train = 0.997266 valid = 0.832859\n",
            "2022-01-10 00:40:51 - INFO:\ttrain #13040 lr = 2.71e-05 loss = 0.012712 train = 0.994531 valid = 0.816206\n",
            "2022-01-10 00:41:19 - INFO:\ttrain #13050 lr = 2.71e-05 loss = 0.009826 train = 0.996680 valid = 0.830219\n",
            "2022-01-10 00:41:47 - INFO:\ttrain #13060 lr = 2.71e-05 loss = 0.009334 train = 0.998047 valid = 0.830219\n",
            "2022-01-10 00:42:15 - INFO:\ttrain #13070 lr = 2.71e-05 loss = 0.006306 train = 0.999219 valid = 0.831438\n",
            "2022-01-10 00:42:43 - INFO:\ttrain #13080 lr = 2.70e-05 loss = 0.015954 train = 0.994336 valid = 0.821690\n",
            "2022-01-10 00:43:11 - INFO:\ttrain #13090 lr = 2.70e-05 loss = 0.008292 train = 0.997852 valid = 0.824736\n",
            "2022-01-10 00:43:38 - INFO:\ttrain #13100 lr = 2.70e-05 loss = 0.009231 train = 0.997266 valid = 0.828798\n",
            "2022-01-10 00:43:42 - INFO:\tSaved test = 0.815640\n",
            "2022-01-10 00:44:09 - INFO:\ttrain #13110 lr = 2.70e-05 loss = 0.008880 train = 0.997461 valid = 0.823111\n",
            "2022-01-10 00:44:37 - INFO:\ttrain #13120 lr = 2.69e-05 loss = 0.016022 train = 0.993750 valid = 0.815597\n",
            "2022-01-10 00:45:04 - INFO:\ttrain #13130 lr = 2.69e-05 loss = 0.014022 train = 0.994727 valid = 0.821893\n",
            "2022-01-10 00:45:31 - INFO:\ttrain #13140 lr = 2.69e-05 loss = 0.013281 train = 0.995117 valid = 0.822502\n",
            "2022-01-10 00:45:59 - INFO:\ttrain #13150 lr = 2.68e-05 loss = 0.010741 train = 0.996289 valid = 0.824939\n",
            "2022-01-10 00:46:26 - INFO:\ttrain #13160 lr = 2.68e-05 loss = 0.008019 train = 0.998047 valid = 0.824736\n",
            "2022-01-10 00:46:53 - INFO:\ttrain #13170 lr = 2.68e-05 loss = 0.014077 train = 0.994922 valid = 0.825142\n",
            "2022-01-10 00:47:21 - INFO:\ttrain #13180 lr = 2.68e-05 loss = 0.012321 train = 0.995508 valid = 0.825345\n",
            "2022-01-10 00:47:48 - INFO:\ttrain #13190 lr = 2.67e-05 loss = 0.005774 train = 0.998828 valid = 0.831235\n",
            "2022-01-10 00:48:15 - INFO:\ttrain #13200 lr = 2.67e-05 loss = 0.009303 train = 0.997461 valid = 0.825548\n",
            "2022-01-10 00:48:19 - INFO:\tSaved test = 0.820502\n",
            "2022-01-10 00:48:46 - INFO:\ttrain #13210 lr = 2.67e-05 loss = 0.009462 train = 0.997461 valid = 0.826564\n",
            "2022-01-10 00:49:14 - INFO:\ttrain #13220 lr = 2.67e-05 loss = 0.008242 train = 0.997070 valid = 0.825751\n",
            "2022-01-10 00:49:41 - INFO:\ttrain #13230 lr = 2.66e-05 loss = 0.007776 train = 0.997852 valid = 0.825142\n",
            "2022-01-10 00:50:08 - INFO:\ttrain #13240 lr = 2.66e-05 loss = 0.009959 train = 0.997461 valid = 0.820065\n",
            "2022-01-10 00:50:36 - INFO:\ttrain #13250 lr = 2.66e-05 loss = 0.019062 train = 0.992969 valid = 0.817831\n",
            "2022-01-10 00:51:03 - INFO:\ttrain #13260 lr = 2.66e-05 loss = 0.015300 train = 0.995508 valid = 0.819050\n",
            "2022-01-10 00:51:30 - INFO:\ttrain #13270 lr = 2.65e-05 loss = 0.013711 train = 0.994727 valid = 0.810317\n",
            "2022-01-10 00:51:58 - INFO:\ttrain #13280 lr = 2.65e-05 loss = 0.023798 train = 0.993164 valid = 0.816003\n",
            "2022-01-10 00:52:25 - INFO:\ttrain #13290 lr = 2.65e-05 loss = 0.016753 train = 0.994141 valid = 0.821487\n",
            "2022-01-10 00:52:52 - INFO:\ttrain #13300 lr = 2.64e-05 loss = 0.008023 train = 0.997852 valid = 0.821487\n",
            "2022-01-10 00:52:56 - INFO:\tSaved test = 0.816451\n",
            "2022-01-10 00:53:23 - INFO:\ttrain #13310 lr = 2.64e-05 loss = 0.009719 train = 0.997656 valid = 0.826361\n",
            "2022-01-10 00:53:50 - INFO:\ttrain #13320 lr = 2.64e-05 loss = 0.007556 train = 0.997656 valid = 0.829001\n",
            "2022-01-10 00:54:18 - INFO:\ttrain #13330 lr = 2.64e-05 loss = 0.008128 train = 0.997070 valid = 0.824736\n",
            "2022-01-10 00:54:45 - INFO:\ttrain #13340 lr = 2.63e-05 loss = 0.009442 train = 0.996680 valid = 0.828392\n",
            "2022-01-10 00:55:12 - INFO:\ttrain #13350 lr = 2.63e-05 loss = 0.009495 train = 0.997656 valid = 0.824939\n",
            "2022-01-10 00:55:39 - INFO:\ttrain #13360 lr = 2.63e-05 loss = 0.009323 train = 0.997266 valid = 0.824533\n",
            "2022-01-10 00:56:07 - INFO:\ttrain #13370 lr = 2.63e-05 loss = 0.007350 train = 0.997656 valid = 0.820877\n",
            "2022-01-10 00:56:34 - INFO:\ttrain #13380 lr = 2.62e-05 loss = 0.009415 train = 0.997461 valid = 0.824533\n",
            "2022-01-10 00:57:01 - INFO:\ttrain #13390 lr = 2.62e-05 loss = 0.012894 train = 0.995898 valid = 0.824939\n",
            "2022-01-10 00:57:29 - INFO:\ttrain #13400 lr = 2.62e-05 loss = 0.013233 train = 0.995508 valid = 0.821080\n",
            "2022-01-10 00:57:32 - INFO:\tSaved test = 0.817666\n",
            "2022-01-10 00:57:59 - INFO:\ttrain #13410 lr = 2.62e-05 loss = 0.007471 train = 0.997852 valid = 0.825142\n",
            "2022-01-10 00:58:27 - INFO:\ttrain #13420 lr = 2.61e-05 loss = 0.007683 train = 0.997852 valid = 0.826158\n",
            "2022-01-10 00:58:54 - INFO:\ttrain #13430 lr = 2.61e-05 loss = 0.008934 train = 0.997266 valid = 0.820065\n",
            "2022-01-10 00:59:21 - INFO:\ttrain #13440 lr = 2.61e-05 loss = 0.011110 train = 0.995508 valid = 0.824127\n",
            "2022-01-10 00:59:49 - INFO:\ttrain #13450 lr = 2.61e-05 loss = 0.011663 train = 0.996289 valid = 0.825345\n",
            "2022-01-10 01:00:16 - INFO:\ttrain #13460 lr = 2.60e-05 loss = 0.008693 train = 0.998047 valid = 0.822908\n",
            "2022-01-10 01:00:43 - INFO:\ttrain #13470 lr = 2.60e-05 loss = 0.007772 train = 0.998047 valid = 0.828798\n",
            "2022-01-10 01:01:11 - INFO:\ttrain #13480 lr = 2.60e-05 loss = 0.007521 train = 0.998242 valid = 0.824939\n",
            "2022-01-10 01:01:38 - INFO:\ttrain #13490 lr = 2.59e-05 loss = 0.011438 train = 0.996875 valid = 0.823111\n",
            "2022-01-10 01:02:05 - INFO:\ttrain #13500 lr = 2.59e-05 loss = 0.011628 train = 0.996289 valid = 0.828188\n",
            "2022-01-10 01:02:09 - INFO:\tSaved test = 0.816451\n",
            "2022-01-10 01:02:36 - INFO:\ttrain #13510 lr = 2.59e-05 loss = 0.009850 train = 0.996484 valid = 0.823721\n",
            "2022-01-10 01:03:04 - INFO:\ttrain #13520 lr = 2.59e-05 loss = 0.012664 train = 0.996484 valid = 0.823924\n",
            "2022-01-10 01:03:31 - INFO:\ttrain #13530 lr = 2.58e-05 loss = 0.007666 train = 0.998047 valid = 0.824533\n",
            "2022-01-10 01:03:58 - INFO:\ttrain #13540 lr = 2.58e-05 loss = 0.007674 train = 0.997656 valid = 0.819456\n",
            "2022-01-10 01:04:25 - INFO:\ttrain #13550 lr = 2.58e-05 loss = 0.012300 train = 0.995898 valid = 0.822299\n",
            "2022-01-10 01:04:53 - INFO:\ttrain #13560 lr = 2.58e-05 loss = 0.013941 train = 0.996680 valid = 0.822705\n",
            "2022-01-10 01:05:20 - INFO:\ttrain #13570 lr = 2.57e-05 loss = 0.009636 train = 0.996484 valid = 0.823517\n",
            "2022-01-10 01:05:47 - INFO:\ttrain #13580 lr = 2.57e-05 loss = 0.007413 train = 0.998047 valid = 0.823721\n",
            "2022-01-10 01:06:15 - INFO:\ttrain #13590 lr = 2.57e-05 loss = 0.007902 train = 0.997852 valid = 0.823111\n",
            "2022-01-10 01:06:42 - INFO:\ttrain #13600 lr = 2.57e-05 loss = 0.006111 train = 0.998633 valid = 0.825548\n",
            "2022-01-10 01:06:46 - INFO:\tSaved test = 0.817261\n",
            "2022-01-10 01:07:13 - INFO:\ttrain #13610 lr = 2.56e-05 loss = 0.007435 train = 0.996094 valid = 0.825751\n",
            "2022-01-10 01:07:40 - INFO:\ttrain #13620 lr = 2.56e-05 loss = 0.014520 train = 0.994336 valid = 0.818643\n",
            "2022-01-10 01:08:07 - INFO:\ttrain #13630 lr = 2.56e-05 loss = 0.013307 train = 0.995703 valid = 0.817019\n",
            "2022-01-10 01:08:35 - INFO:\ttrain #13640 lr = 2.56e-05 loss = 0.011292 train = 0.996484 valid = 0.816206\n",
            "2022-01-10 01:09:02 - INFO:\ttrain #13650 lr = 2.55e-05 loss = 0.008661 train = 0.997266 valid = 0.816613\n",
            "2022-01-10 01:09:29 - INFO:\ttrain #13660 lr = 2.55e-05 loss = 0.009460 train = 0.997266 valid = 0.819862\n",
            "2022-01-10 01:09:57 - INFO:\ttrain #13670 lr = 2.55e-05 loss = 0.008868 train = 0.997070 valid = 0.822299\n",
            "2022-01-10 01:10:24 - INFO:\ttrain #13680 lr = 2.55e-05 loss = 0.009370 train = 0.997266 valid = 0.820268\n",
            "2022-01-10 01:10:51 - INFO:\ttrain #13690 lr = 2.54e-05 loss = 0.010308 train = 0.997852 valid = 0.827173\n",
            "2022-01-10 01:11:19 - INFO:\ttrain #13700 lr = 2.54e-05 loss = 0.009113 train = 0.998242 valid = 0.823314\n",
            "2022-01-10 01:11:22 - INFO:\tSaved test = 0.810373\n",
            "2022-01-10 01:11:49 - INFO:\ttrain #13710 lr = 2.54e-05 loss = 0.011705 train = 0.996289 valid = 0.823314\n",
            "2022-01-10 01:12:17 - INFO:\ttrain #13720 lr = 2.54e-05 loss = 0.008975 train = 0.996680 valid = 0.819456\n",
            "2022-01-10 01:12:44 - INFO:\ttrain #13730 lr = 2.53e-05 loss = 0.008617 train = 0.997070 valid = 0.830016\n",
            "2022-01-10 01:13:11 - INFO:\ttrain #13740 lr = 2.53e-05 loss = 0.007741 train = 0.998047 valid = 0.829204\n",
            "2022-01-10 01:13:39 - INFO:\ttrain #13750 lr = 2.53e-05 loss = 0.010530 train = 0.996875 valid = 0.824736\n",
            "2022-01-10 01:14:06 - INFO:\ttrain #13760 lr = 2.53e-05 loss = 0.012048 train = 0.996484 valid = 0.824330\n",
            "2022-01-10 01:14:33 - INFO:\ttrain #13770 lr = 2.52e-05 loss = 0.011448 train = 0.995117 valid = 0.819862\n",
            "2022-01-10 01:15:00 - INFO:\ttrain #13780 lr = 2.52e-05 loss = 0.011481 train = 0.997070 valid = 0.819659\n",
            "2022-01-10 01:15:28 - INFO:\ttrain #13790 lr = 2.52e-05 loss = 0.008079 train = 0.997266 valid = 0.820674\n",
            "2022-01-10 01:15:55 - INFO:\ttrain #13800 lr = 2.52e-05 loss = 0.005205 train = 0.998828 valid = 0.822299\n",
            "2022-01-10 01:15:59 - INFO:\tSaved test = 0.818476\n",
            "2022-01-10 01:16:26 - INFO:\ttrain #13810 lr = 2.51e-05 loss = 0.005450 train = 0.998633 valid = 0.824939\n",
            "2022-01-10 01:16:53 - INFO:\ttrain #13820 lr = 2.51e-05 loss = 0.013700 train = 0.995703 valid = 0.824533\n",
            "2022-01-10 01:17:20 - INFO:\ttrain #13830 lr = 2.51e-05 loss = 0.008223 train = 0.997461 valid = 0.821284\n",
            "2022-01-10 01:17:48 - INFO:\ttrain #13840 lr = 2.51e-05 loss = 0.006918 train = 0.997852 valid = 0.824939\n",
            "2022-01-10 01:18:15 - INFO:\ttrain #13850 lr = 2.50e-05 loss = 0.005479 train = 0.998633 valid = 0.824736\n",
            "2022-01-10 01:18:42 - INFO:\ttrain #13860 lr = 2.50e-05 loss = 0.006226 train = 0.998242 valid = 0.827376\n",
            "2022-01-10 01:19:10 - INFO:\ttrain #13870 lr = 2.50e-05 loss = 0.013923 train = 0.995313 valid = 0.827579\n",
            "2022-01-10 01:19:37 - INFO:\ttrain #13880 lr = 2.50e-05 loss = 0.015571 train = 0.994531 valid = 0.823111\n",
            "2022-01-10 01:20:04 - INFO:\ttrain #13890 lr = 2.49e-05 loss = 0.010772 train = 0.996680 valid = 0.824939\n",
            "2022-01-10 01:20:31 - INFO:\ttrain #13900 lr = 2.49e-05 loss = 0.011614 train = 0.995898 valid = 0.823517\n",
            "2022-01-10 01:20:35 - INFO:\tSaved test = 0.812804\n",
            "2022-01-10 01:21:02 - INFO:\ttrain #13910 lr = 2.49e-05 loss = 0.010679 train = 0.996875 valid = 0.823111\n",
            "2022-01-10 01:21:29 - INFO:\ttrain #13920 lr = 2.49e-05 loss = 0.012370 train = 0.995703 valid = 0.824736\n",
            "2022-01-10 01:21:57 - INFO:\ttrain #13930 lr = 2.48e-05 loss = 0.009899 train = 0.996094 valid = 0.826158\n",
            "2022-01-10 01:22:24 - INFO:\ttrain #13940 lr = 2.48e-05 loss = 0.007761 train = 0.997852 valid = 0.822299\n",
            "2022-01-10 01:22:51 - INFO:\ttrain #13950 lr = 2.48e-05 loss = 0.012924 train = 0.995313 valid = 0.817831\n",
            "2022-01-10 01:23:18 - INFO:\ttrain #13960 lr = 2.48e-05 loss = 0.012404 train = 0.997070 valid = 0.821487\n",
            "2022-01-10 01:23:46 - INFO:\ttrain #13970 lr = 2.47e-05 loss = 0.011010 train = 0.996289 valid = 0.824127\n",
            "2022-01-10 01:24:13 - INFO:\ttrain #13980 lr = 2.47e-05 loss = 0.007794 train = 0.997461 valid = 0.824330\n",
            "2022-01-10 01:24:40 - INFO:\ttrain #13990 lr = 2.47e-05 loss = 0.006371 train = 0.998828 valid = 0.825142\n",
            "2022-01-10 01:25:08 - INFO:\ttrain #14000 lr = 2.47e-05 loss = 0.009106 train = 0.997266 valid = 0.822705\n",
            "2022-01-10 01:25:11 - INFO:\tSaved test = 0.815640\n",
            "2022-01-10 01:25:38 - INFO:\ttrain #14010 lr = 2.46e-05 loss = 0.014226 train = 0.995703 valid = 0.823111\n",
            "2022-01-10 01:26:06 - INFO:\ttrain #14020 lr = 2.46e-05 loss = 0.013029 train = 0.995898 valid = 0.825548\n",
            "2022-01-10 01:26:33 - INFO:\ttrain #14030 lr = 2.46e-05 loss = 0.011306 train = 0.996680 valid = 0.822096\n",
            "2022-01-10 01:27:00 - INFO:\ttrain #14040 lr = 2.46e-05 loss = 0.008575 train = 0.997461 valid = 0.824736\n",
            "2022-01-10 01:27:28 - INFO:\ttrain #14050 lr = 2.45e-05 loss = 0.009763 train = 0.996289 valid = 0.823924\n",
            "2022-01-10 01:27:55 - INFO:\ttrain #14060 lr = 2.45e-05 loss = 0.009261 train = 0.997070 valid = 0.822096\n",
            "2022-01-10 01:28:22 - INFO:\ttrain #14070 lr = 2.45e-05 loss = 0.007614 train = 0.996875 valid = 0.825751\n",
            "2022-01-10 01:28:50 - INFO:\ttrain #14080 lr = 2.45e-05 loss = 0.006659 train = 0.998437 valid = 0.830016\n",
            "2022-01-10 01:29:17 - INFO:\ttrain #14090 lr = 2.44e-05 loss = 0.008837 train = 0.997266 valid = 0.831235\n",
            "2022-01-10 01:29:44 - INFO:\ttrain #14100 lr = 2.44e-05 loss = 0.005341 train = 0.998437 valid = 0.825142\n",
            "2022-01-10 01:29:48 - INFO:\tSaved test = 0.819287\n",
            "2022-01-10 01:30:15 - INFO:\ttrain #14110 lr = 2.44e-05 loss = 0.006431 train = 0.998047 valid = 0.832250\n",
            "2022-01-10 01:30:42 - INFO:\ttrain #14120 lr = 2.44e-05 loss = 0.005360 train = 0.998633 valid = 0.827376\n",
            "2022-01-10 01:31:09 - INFO:\ttrain #14130 lr = 2.43e-05 loss = 0.006438 train = 0.997656 valid = 0.830219\n",
            "2022-01-10 01:31:37 - INFO:\ttrain #14140 lr = 2.43e-05 loss = 0.007286 train = 0.998437 valid = 0.831032\n",
            "2022-01-10 01:32:04 - INFO:\ttrain #14150 lr = 2.43e-05 loss = 0.006638 train = 0.997266 valid = 0.830626\n",
            "2022-01-10 01:32:31 - INFO:\ttrain #14160 lr = 2.43e-05 loss = 0.006090 train = 0.997461 valid = 0.826767\n",
            "2022-01-10 01:32:59 - INFO:\ttrain #14170 lr = 2.42e-05 loss = 0.004898 train = 0.998633 valid = 0.819862\n",
            "2022-01-10 01:33:26 - INFO:\ttrain #14180 lr = 2.42e-05 loss = 0.016318 train = 0.995117 valid = 0.816206\n",
            "2022-01-10 01:33:53 - INFO:\ttrain #14190 lr = 2.42e-05 loss = 0.018617 train = 0.994141 valid = 0.812551\n",
            "2022-01-10 01:34:21 - INFO:\ttrain #14200 lr = 2.42e-05 loss = 0.010395 train = 0.995898 valid = 0.821080\n",
            "2022-01-10 01:34:24 - INFO:\tSaved test = 0.814830\n",
            "2022-01-10 01:34:51 - INFO:\ttrain #14210 lr = 2.41e-05 loss = 0.010774 train = 0.996289 valid = 0.824939\n",
            "2022-01-10 01:35:19 - INFO:\ttrain #14220 lr = 2.41e-05 loss = 0.009661 train = 0.996680 valid = 0.820471\n",
            "2022-01-10 01:35:46 - INFO:\ttrain #14230 lr = 2.41e-05 loss = 0.007456 train = 0.997266 valid = 0.826158\n",
            "2022-01-10 01:36:13 - INFO:\ttrain #14240 lr = 2.41e-05 loss = 0.007678 train = 0.997461 valid = 0.826361\n",
            "2022-01-10 01:36:41 - INFO:\ttrain #14250 lr = 2.40e-05 loss = 0.010861 train = 0.996484 valid = 0.824330\n",
            "2022-01-10 01:37:08 - INFO:\ttrain #14260 lr = 2.40e-05 loss = 0.007892 train = 0.998047 valid = 0.824736\n",
            "2022-01-10 01:37:35 - INFO:\ttrain #14270 lr = 2.40e-05 loss = 0.005282 train = 0.999023 valid = 0.824330\n",
            "2022-01-10 01:38:03 - INFO:\ttrain #14280 lr = 2.40e-05 loss = 0.005939 train = 0.998242 valid = 0.827579\n",
            "2022-01-10 01:38:31 - INFO:\ttrain #14290 lr = 2.40e-05 loss = 0.009999 train = 0.997266 valid = 0.823314\n",
            "2022-01-10 01:38:58 - INFO:\ttrain #14300 lr = 2.39e-05 loss = 0.010850 train = 0.996289 valid = 0.827579\n",
            "2022-01-10 01:39:02 - INFO:\tSaved test = 0.816045\n",
            "2022-01-10 01:39:29 - INFO:\ttrain #14310 lr = 2.39e-05 loss = 0.008109 train = 0.997852 valid = 0.826361\n",
            "2022-01-10 01:39:56 - INFO:\ttrain #14320 lr = 2.39e-05 loss = 0.006694 train = 0.998047 valid = 0.826564\n",
            "2022-01-10 01:40:24 - INFO:\ttrain #14330 lr = 2.39e-05 loss = 0.009396 train = 0.996484 valid = 0.827376\n",
            "2022-01-10 01:40:52 - INFO:\ttrain #14340 lr = 2.38e-05 loss = 0.006011 train = 0.998242 valid = 0.824736\n",
            "2022-01-10 01:41:19 - INFO:\ttrain #14350 lr = 2.38e-05 loss = 0.008583 train = 0.997070 valid = 0.823517\n",
            "2022-01-10 01:41:47 - INFO:\ttrain #14360 lr = 2.38e-05 loss = 0.006406 train = 0.998047 valid = 0.827173\n",
            "2022-01-10 01:42:14 - INFO:\ttrain #14370 lr = 2.38e-05 loss = 0.006920 train = 0.998437 valid = 0.819050\n",
            "2022-01-10 01:42:42 - INFO:\ttrain #14380 lr = 2.37e-05 loss = 0.009840 train = 0.997461 valid = 0.821080\n",
            "2022-01-10 01:43:09 - INFO:\ttrain #14390 lr = 2.37e-05 loss = 0.005684 train = 0.999219 valid = 0.822502\n",
            "2022-01-10 01:43:36 - INFO:\ttrain #14400 lr = 2.37e-05 loss = 0.006405 train = 0.998047 valid = 0.828595\n",
            "2022-01-10 01:43:40 - INFO:\tSaved test = 0.813209\n",
            "2022-01-10 01:44:08 - INFO:\ttrain #14410 lr = 2.37e-05 loss = 0.007764 train = 0.997656 valid = 0.825345\n",
            "2022-01-10 01:44:35 - INFO:\ttrain #14420 lr = 2.36e-05 loss = 0.008338 train = 0.998047 valid = 0.818643\n",
            "2022-01-10 01:45:04 - INFO:\ttrain #14430 lr = 2.36e-05 loss = 0.007517 train = 0.998047 valid = 0.824330\n",
            "2022-01-10 01:45:32 - INFO:\ttrain #14440 lr = 2.36e-05 loss = 0.008087 train = 0.998242 valid = 0.829610\n",
            "2022-01-10 01:46:01 - INFO:\ttrain #14450 lr = 2.36e-05 loss = 0.009029 train = 0.996484 valid = 0.826564\n",
            "2022-01-10 01:46:29 - INFO:\ttrain #14460 lr = 2.35e-05 loss = 0.012685 train = 0.995508 valid = 0.826970\n",
            "2022-01-10 01:46:57 - INFO:\ttrain #14470 lr = 2.35e-05 loss = 0.007375 train = 0.997461 valid = 0.829813\n",
            "2022-01-10 01:47:26 - INFO:\ttrain #14480 lr = 2.35e-05 loss = 0.006939 train = 0.997852 valid = 0.825345\n",
            "2022-01-10 01:47:54 - INFO:\ttrain #14490 lr = 2.35e-05 loss = 0.006748 train = 0.998047 valid = 0.824330\n",
            "2022-01-10 01:48:23 - INFO:\ttrain #14500 lr = 2.35e-05 loss = 0.006888 train = 0.997656 valid = 0.825345\n",
            "2022-01-10 01:48:27 - INFO:\tSaved test = 0.813614\n",
            "2022-01-10 01:48:55 - INFO:\ttrain #14510 lr = 2.34e-05 loss = 0.008677 train = 0.997656 valid = 0.825751\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-21-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-20-87a43fac0421>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(more_epoch, valid_result_threshold)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m                 \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0miperm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mget_trans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_trans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Colab\\PointCloud\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmem\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maugment\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextra_labels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextra_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maugment\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train Result Archive**"
      ],
      "metadata": {
        "id": "S1OecUx3PFs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert False, \"protected\""
      ],
      "metadata": {
        "id": "kSmPAb_APjQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# affine, 1024 point2embed\n",
        "train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K9ZTaYhTfgu2",
        "outputId": "42244632-c0b4-4b77-eb64-5e0d6a5e5805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-08 00:41:20 - INFO:\ttrain epoch = 1 ~ 100000 threshold = 1.0\n",
            "2022-01-08 00:41:24 - DEBUG:\ttrain #1 lr = 1.00e-04 loss = 3.589709 train = 0.083984 \n",
            "2022-01-08 00:41:25 - DEBUG:\ttrain #2 lr = 1.00e-04 loss = 3.339514 train = 0.156250 \n",
            "2022-01-08 00:41:27 - DEBUG:\ttrain #3 lr = 1.00e-04 loss = 3.044279 train = 0.218750 \n",
            "2022-01-08 00:41:28 - DEBUG:\ttrain #4 lr = 1.00e-04 loss = 2.893158 train = 0.246094 \n",
            "2022-01-08 00:41:29 - DEBUG:\ttrain #5 lr = 1.00e-04 loss = 2.842332 train = 0.248047 \n",
            "2022-01-08 00:41:54 - INFO:\ttrain #20 lr = 9.98e-05 loss = 2.523985 train = 0.339062 valid = 0.340983 updated\n",
            "2022-01-08 00:42:25 - INFO:\ttrain #40 lr = 9.96e-05 loss = 2.005709 train = 0.458691 valid = 0.379976 updated\n",
            "2022-01-08 00:42:58 - INFO:\ttrain #60 lr = 9.94e-05 loss = 1.711581 train = 0.526563 valid = 0.491267 updated\n",
            "2022-01-08 00:43:30 - INFO:\ttrain #80 lr = 9.92e-05 loss = 1.545243 train = 0.563770 valid = 0.515841 updated\n",
            "2022-01-08 00:44:01 - INFO:\ttrain #100 lr = 9.90e-05 loss = 1.405138 train = 0.598242 valid = 0.555240 updated\n",
            "2022-01-08 00:44:04 - INFO:\tSaved test = 0.535656\n",
            "2022-01-08 00:44:35 - INFO:\ttrain #120 lr = 9.88e-05 loss = 1.329405 train = 0.616211 valid = 0.567831 updated\n",
            "2022-01-08 00:45:05 - INFO:\ttrain #140 lr = 9.86e-05 loss = 1.236238 train = 0.641504 valid = 0.569050 updated\n",
            "2022-01-08 00:45:35 - INFO:\ttrain #160 lr = 9.84e-05 loss = 1.172531 train = 0.657715 valid = 0.634850 updated\n",
            "2022-01-08 00:46:05 - INFO:\ttrain #180 lr = 9.82e-05 loss = 1.113998 train = 0.672461 valid = 0.627335\n",
            "2022-01-08 00:46:35 - INFO:\ttrain #200 lr = 9.80e-05 loss = 1.055430 train = 0.686035 valid = 0.662673 updated\n",
            "2022-01-08 00:46:37 - INFO:\tSaved test = 0.640194\n",
            "2022-01-08 00:47:07 - INFO:\ttrain #220 lr = 9.78e-05 loss = 1.021045 train = 0.696094 valid = 0.634850\n",
            "2022-01-08 00:47:37 - INFO:\ttrain #240 lr = 9.76e-05 loss = 0.980060 train = 0.704590 valid = 0.665516 updated\n",
            "2022-01-08 00:48:06 - INFO:\ttrain #260 lr = 9.74e-05 loss = 0.956049 train = 0.713965 valid = 0.661251\n",
            "2022-01-08 00:48:36 - INFO:\ttrain #280 lr = 9.72e-05 loss = 0.943585 train = 0.714746 valid = 0.642973\n",
            "2022-01-08 00:49:06 - INFO:\ttrain #300 lr = 9.70e-05 loss = 0.867650 train = 0.740723 valid = 0.690292 updated\n",
            "2022-01-08 00:49:09 - INFO:\tSaved test = 0.676256\n",
            "2022-01-08 00:49:38 - INFO:\ttrain #320 lr = 9.69e-05 loss = 0.870391 train = 0.739453 valid = 0.677295\n",
            "2022-01-08 00:50:08 - INFO:\ttrain #340 lr = 9.67e-05 loss = 0.853267 train = 0.742090 valid = 0.689074\n",
            "2022-01-08 00:50:38 - INFO:\ttrain #360 lr = 9.65e-05 loss = 0.802078 train = 0.752051 valid = 0.700853 updated\n",
            "2022-01-08 00:51:08 - INFO:\ttrain #380 lr = 9.63e-05 loss = 0.791183 train = 0.759668 valid = 0.705321 updated\n",
            "2022-01-08 00:51:38 - INFO:\ttrain #400 lr = 9.61e-05 loss = 0.750471 train = 0.763965 valid = 0.703087\n",
            "2022-01-08 00:51:40 - INFO:\tSaved test = 0.682739\n",
            "2022-01-08 00:52:10 - INFO:\ttrain #420 lr = 9.59e-05 loss = 0.754256 train = 0.770215 valid = 0.697400\n",
            "2022-01-08 00:52:40 - INFO:\ttrain #440 lr = 9.57e-05 loss = 0.711153 train = 0.782520 valid = 0.722786 updated\n",
            "2022-01-08 00:53:10 - INFO:\ttrain #460 lr = 9.55e-05 loss = 0.731068 train = 0.772070 valid = 0.705727\n",
            "2022-01-08 00:53:40 - INFO:\ttrain #480 lr = 9.53e-05 loss = 0.706908 train = 0.780273 valid = 0.720552\n",
            "2022-01-08 00:54:10 - INFO:\ttrain #500 lr = 9.51e-05 loss = 0.684451 train = 0.785742 valid = 0.713241\n",
            "2022-01-08 00:54:12 - INFO:\tSaved test = 0.711507\n",
            "2022-01-08 00:54:42 - INFO:\ttrain #520 lr = 9.49e-05 loss = 0.658093 train = 0.789355 valid = 0.722177\n",
            "2022-01-08 00:55:12 - INFO:\ttrain #540 lr = 9.47e-05 loss = 0.672648 train = 0.788184 valid = 0.699025\n",
            "2022-01-08 00:55:42 - INFO:\ttrain #560 lr = 9.46e-05 loss = 0.652046 train = 0.794336 valid = 0.724411 updated\n",
            "2022-01-08 00:56:12 - INFO:\ttrain #580 lr = 9.44e-05 loss = 0.617083 train = 0.807227 valid = 0.722177\n",
            "2022-01-08 00:56:42 - INFO:\ttrain #600 lr = 9.42e-05 loss = 0.602855 train = 0.809082 valid = 0.747969 updated\n",
            "2022-01-08 00:56:44 - INFO:\tSaved test = 0.736224\n",
            "2022-01-08 00:57:14 - INFO:\ttrain #620 lr = 9.40e-05 loss = 0.599018 train = 0.807422 valid = 0.734362\n",
            "2022-01-08 00:57:44 - INFO:\ttrain #640 lr = 9.38e-05 loss = 0.584555 train = 0.816211 valid = 0.730301\n",
            "2022-01-08 00:58:14 - INFO:\ttrain #660 lr = 9.36e-05 loss = 0.572901 train = 0.817676 valid = 0.762794 updated\n",
            "2022-01-08 00:58:44 - INFO:\ttrain #680 lr = 9.34e-05 loss = 0.579982 train = 0.816016 valid = 0.724614\n",
            "2022-01-08 00:59:13 - INFO:\ttrain #700 lr = 9.32e-05 loss = 0.554131 train = 0.824414 valid = 0.731925\n",
            "2022-01-08 00:59:16 - INFO:\tSaved test = 0.728930\n",
            "2022-01-08 00:59:46 - INFO:\ttrain #720 lr = 9.31e-05 loss = 0.552867 train = 0.825488 valid = 0.754671\n",
            "2022-01-08 01:00:15 - INFO:\ttrain #740 lr = 9.29e-05 loss = 0.541395 train = 0.828613 valid = 0.726442\n",
            "2022-01-08 01:00:45 - INFO:\ttrain #760 lr = 9.27e-05 loss = 0.564250 train = 0.819922 valid = 0.739033\n",
            "2022-01-08 01:01:15 - INFO:\ttrain #780 lr = 9.25e-05 loss = 0.504116 train = 0.835449 valid = 0.753046\n",
            "2022-01-08 01:01:45 - INFO:\ttrain #800 lr = 9.23e-05 loss = 0.511303 train = 0.831738 valid = 0.727660\n",
            "2022-01-08 01:01:47 - INFO:\tSaved test = 0.736224\n",
            "2022-01-08 01:02:17 - INFO:\ttrain #820 lr = 9.21e-05 loss = 0.491244 train = 0.841699 valid = 0.741064\n",
            "2022-01-08 01:02:47 - INFO:\ttrain #840 lr = 9.19e-05 loss = 0.498912 train = 0.841406 valid = 0.747360\n",
            "2022-01-08 01:03:17 - INFO:\ttrain #860 lr = 9.18e-05 loss = 0.487885 train = 0.843750 valid = 0.766044 updated\n",
            "2022-01-08 01:03:47 - INFO:\ttrain #880 lr = 9.16e-05 loss = 0.469610 train = 0.846680 valid = 0.749188\n",
            "2022-01-08 01:04:17 - INFO:\ttrain #900 lr = 9.14e-05 loss = 0.465935 train = 0.846973 valid = 0.759139\n",
            "2022-01-08 01:04:19 - INFO:\tSaved test = 0.758914\n",
            "2022-01-08 01:04:51 - INFO:\ttrain #920 lr = 9.12e-05 loss = 0.443766 train = 0.856445 valid = 0.771121 updated\n",
            "2022-01-08 01:05:23 - INFO:\ttrain #940 lr = 9.10e-05 loss = 0.433177 train = 0.858887 valid = 0.767465\n",
            "2022-01-08 01:05:55 - INFO:\ttrain #960 lr = 9.08e-05 loss = 0.422007 train = 0.860449 valid = 0.768887\n",
            "2022-01-08 01:06:27 - INFO:\ttrain #980 lr = 9.07e-05 loss = 0.439349 train = 0.854492 valid = 0.763607\n",
            "2022-01-08 01:06:58 - INFO:\ttrain #1000 lr = 9.05e-05 loss = 0.450342 train = 0.853516 valid = 0.767465\n",
            "2022-01-08 01:07:01 - INFO:\tSaved test = 0.769044\n",
            "2022-01-08 01:07:33 - INFO:\ttrain #1020 lr = 9.03e-05 loss = 0.428327 train = 0.860059 valid = 0.749188\n",
            "2022-01-08 01:08:05 - INFO:\ttrain #1040 lr = 9.01e-05 loss = 0.415821 train = 0.862402 valid = 0.762998\n",
            "2022-01-08 01:08:37 - INFO:\ttrain #1060 lr = 8.99e-05 loss = 0.429341 train = 0.858984 valid = 0.769699\n",
            "2022-01-08 01:09:09 - INFO:\ttrain #1080 lr = 8.98e-05 loss = 0.401210 train = 0.870801 valid = 0.779854 updated\n",
            "2022-01-08 01:09:41 - INFO:\ttrain #1100 lr = 8.96e-05 loss = 0.398938 train = 0.869238 valid = 0.739439\n",
            "2022-01-08 01:09:44 - INFO:\tSaved test = 0.726904\n",
            "2022-01-08 01:10:15 - INFO:\ttrain #1120 lr = 8.94e-05 loss = 0.395849 train = 0.872754 valid = 0.770918\n",
            "2022-01-08 01:10:48 - INFO:\ttrain #1140 lr = 8.92e-05 loss = 0.372467 train = 0.874023 valid = 0.760967\n",
            "2022-01-08 01:11:20 - INFO:\ttrain #1160 lr = 8.90e-05 loss = 0.361776 train = 0.880664 valid = 0.768887\n",
            "2022-01-08 01:11:51 - INFO:\ttrain #1180 lr = 8.89e-05 loss = 0.365525 train = 0.877246 valid = 0.764419\n",
            "2022-01-08 01:12:23 - INFO:\ttrain #1200 lr = 8.87e-05 loss = 0.381009 train = 0.872656 valid = 0.758123\n",
            "2022-01-08 01:12:26 - INFO:\tSaved test = 0.756483\n",
            "2022-01-08 01:12:57 - INFO:\ttrain #1220 lr = 8.85e-05 loss = 0.371461 train = 0.879687 valid = 0.766856\n",
            "2022-01-08 01:13:28 - INFO:\ttrain #1240 lr = 8.83e-05 loss = 0.357214 train = 0.882910 valid = 0.761982\n",
            "2022-01-08 01:14:00 - INFO:\ttrain #1260 lr = 8.82e-05 loss = 0.342190 train = 0.889062 valid = 0.778635\n",
            "2022-01-08 01:14:32 - INFO:\ttrain #1280 lr = 8.80e-05 loss = 0.343585 train = 0.884570 valid = 0.767465\n",
            "2022-01-08 01:15:03 - INFO:\ttrain #1300 lr = 8.78e-05 loss = 0.330002 train = 0.891211 valid = 0.775183\n",
            "2022-01-08 01:15:05 - INFO:\tSaved test = 0.758914\n",
            "2022-01-08 01:15:35 - INFO:\ttrain #1320 lr = 8.76e-05 loss = 0.333770 train = 0.889258 valid = 0.754874\n",
            "2022-01-08 01:16:05 - INFO:\ttrain #1340 lr = 8.75e-05 loss = 0.322151 train = 0.889355 valid = 0.771933\n",
            "2022-01-08 01:16:36 - INFO:\ttrain #1360 lr = 8.73e-05 loss = 0.315412 train = 0.894238 valid = 0.774980\n",
            "2022-01-08 01:17:08 - INFO:\ttrain #1380 lr = 8.71e-05 loss = 0.319755 train = 0.895117 valid = 0.772340\n",
            "2022-01-08 01:17:40 - INFO:\ttrain #1400 lr = 8.69e-05 loss = 0.312107 train = 0.898242 valid = 0.758733\n",
            "2022-01-08 01:17:42 - INFO:\tSaved test = 0.730956\n",
            "2022-01-08 01:18:15 - INFO:\ttrain #1420 lr = 8.68e-05 loss = 0.316708 train = 0.894531 valid = 0.783509 updated\n",
            "2022-01-08 01:18:46 - INFO:\ttrain #1440 lr = 8.66e-05 loss = 0.320568 train = 0.894922 valid = 0.777011\n",
            "2022-01-08 01:19:18 - INFO:\ttrain #1460 lr = 8.64e-05 loss = 0.301153 train = 0.897461 valid = 0.778838\n",
            "2022-01-08 01:19:50 - INFO:\ttrain #1480 lr = 8.62e-05 loss = 0.282581 train = 0.906543 valid = 0.778838\n",
            "2022-01-08 01:20:21 - INFO:\ttrain #1500 lr = 8.61e-05 loss = 0.293449 train = 0.902637 valid = 0.769699\n",
            "2022-01-08 01:20:23 - INFO:\tSaved test = 0.760130\n",
            "2022-01-08 01:20:55 - INFO:\ttrain #1520 lr = 8.59e-05 loss = 0.300593 train = 0.900098 valid = 0.758733\n",
            "2022-01-08 01:21:27 - INFO:\ttrain #1540 lr = 8.57e-05 loss = 0.297396 train = 0.903223 valid = 0.758123\n",
            "2022-01-08 01:22:00 - INFO:\ttrain #1560 lr = 8.56e-05 loss = 0.296859 train = 0.899902 valid = 0.792851 updated\n",
            "2022-01-08 01:22:32 - INFO:\ttrain #1580 lr = 8.54e-05 loss = 0.281659 train = 0.904102 valid = 0.771527\n",
            "2022-01-08 01:23:04 - INFO:\ttrain #1600 lr = 8.52e-05 loss = 0.266306 train = 0.910254 valid = 0.779854\n",
            "2022-01-08 01:23:06 - INFO:\tSaved test = 0.774311\n",
            "2022-01-08 01:23:38 - INFO:\ttrain #1620 lr = 8.50e-05 loss = 0.261783 train = 0.908496 valid = 0.771121\n",
            "2022-01-08 01:24:10 - INFO:\ttrain #1640 lr = 8.49e-05 loss = 0.278619 train = 0.907031 valid = 0.788587\n",
            "2022-01-08 01:24:42 - INFO:\ttrain #1660 lr = 8.47e-05 loss = 0.273248 train = 0.908301 valid = 0.777011\n",
            "2022-01-08 01:25:14 - INFO:\ttrain #1680 lr = 8.45e-05 loss = 0.252309 train = 0.916797 valid = 0.776401\n",
            "2022-01-08 01:25:46 - INFO:\ttrain #1700 lr = 8.44e-05 loss = 0.250586 train = 0.914551 valid = 0.773152\n",
            "2022-01-08 01:25:48 - INFO:\tSaved test = 0.760535\n",
            "2022-01-08 01:26:20 - INFO:\ttrain #1720 lr = 8.42e-05 loss = 0.254324 train = 0.917383 valid = 0.772746\n",
            "2022-01-08 01:26:52 - INFO:\ttrain #1740 lr = 8.40e-05 loss = 0.272427 train = 0.906348 valid = 0.787977\n",
            "2022-01-08 01:27:24 - INFO:\ttrain #1760 lr = 8.39e-05 loss = 0.251228 train = 0.916211 valid = 0.795288 updated\n",
            "2022-01-08 01:27:56 - INFO:\ttrain #1780 lr = 8.37e-05 loss = 0.229008 train = 0.924023 valid = 0.771121\n",
            "2022-01-08 01:28:28 - INFO:\ttrain #1800 lr = 8.35e-05 loss = 0.255328 train = 0.915430 valid = 0.796101 updated\n",
            "2022-01-08 01:28:31 - INFO:\tSaved test = 0.792545\n",
            "2022-01-08 01:29:03 - INFO:\ttrain #1820 lr = 8.34e-05 loss = 0.239235 train = 0.917871 valid = 0.787977\n",
            "2022-01-08 01:29:35 - INFO:\ttrain #1840 lr = 8.32e-05 loss = 0.249553 train = 0.917676 valid = 0.786353\n",
            "2022-01-08 01:30:07 - INFO:\ttrain #1860 lr = 8.30e-05 loss = 0.253765 train = 0.915039 valid = 0.782088\n",
            "2022-01-08 01:30:38 - INFO:\ttrain #1880 lr = 8.29e-05 loss = 0.233678 train = 0.921484 valid = 0.769903\n",
            "2022-01-08 01:31:10 - INFO:\ttrain #1900 lr = 8.27e-05 loss = 0.223654 train = 0.924414 valid = 0.780057\n",
            "2022-01-08 01:31:13 - INFO:\tSaved test = 0.770665\n",
            "2022-01-08 01:31:45 - INFO:\ttrain #1920 lr = 8.25e-05 loss = 0.225319 train = 0.924121 valid = 0.781275\n",
            "2022-01-08 01:32:17 - INFO:\ttrain #1940 lr = 8.24e-05 loss = 0.237136 train = 0.921387 valid = 0.787977\n",
            "2022-01-08 01:32:49 - INFO:\ttrain #1960 lr = 8.22e-05 loss = 0.219795 train = 0.928809 valid = 0.777011\n",
            "2022-01-08 01:33:21 - INFO:\ttrain #1980 lr = 8.20e-05 loss = 0.221910 train = 0.924609 valid = 0.784728\n",
            "2022-01-08 01:33:53 - INFO:\ttrain #2000 lr = 8.19e-05 loss = 0.213621 train = 0.928809 valid = 0.793867\n",
            "2022-01-08 01:33:55 - INFO:\tSaved test = 0.772690\n",
            "2022-01-08 01:34:27 - INFO:\ttrain #2020 lr = 8.17e-05 loss = 0.211955 train = 0.928418 valid = 0.783509\n",
            "2022-01-08 01:34:59 - INFO:\ttrain #2040 lr = 8.15e-05 loss = 0.215445 train = 0.927246 valid = 0.786962\n",
            "2022-01-08 01:35:31 - INFO:\ttrain #2060 lr = 8.14e-05 loss = 0.224887 train = 0.923633 valid = 0.777620\n",
            "2022-01-08 01:36:02 - INFO:\ttrain #2080 lr = 8.12e-05 loss = 0.211998 train = 0.930957 valid = 0.794476\n",
            "2022-01-08 01:36:34 - INFO:\ttrain #2100 lr = 8.11e-05 loss = 0.212661 train = 0.928418 valid = 0.789196\n",
            "2022-01-08 01:36:36 - INFO:\tSaved test = 0.779579\n",
            "2022-01-08 01:37:08 - INFO:\ttrain #2120 lr = 8.09e-05 loss = 0.210695 train = 0.930469 valid = 0.784322\n",
            "2022-01-08 01:37:40 - INFO:\ttrain #2140 lr = 8.07e-05 loss = 0.215323 train = 0.926074 valid = 0.782494\n",
            "2022-01-08 01:38:12 - INFO:\ttrain #2160 lr = 8.06e-05 loss = 0.199493 train = 0.932129 valid = 0.772340\n",
            "2022-01-08 01:38:44 - INFO:\ttrain #2180 lr = 8.04e-05 loss = 0.200742 train = 0.932715 valid = 0.786149\n",
            "2022-01-08 01:39:16 - INFO:\ttrain #2200 lr = 8.03e-05 loss = 0.204792 train = 0.929883 valid = 0.799147 updated\n",
            "2022-01-08 01:39:18 - INFO:\tSaved test = 0.792950\n",
            "2022-01-08 01:39:50 - INFO:\ttrain #2220 lr = 8.01e-05 loss = 0.197658 train = 0.934082 valid = 0.781885\n",
            "2022-01-08 01:40:22 - INFO:\ttrain #2240 lr = 7.99e-05 loss = 0.193805 train = 0.935156 valid = 0.794882\n",
            "2022-01-08 01:40:54 - INFO:\ttrain #2260 lr = 7.98e-05 loss = 0.184475 train = 0.939551 valid = 0.791633\n",
            "2022-01-08 01:41:26 - INFO:\ttrain #2280 lr = 7.96e-05 loss = 0.167758 train = 0.943945 valid = 0.799959 updated\n",
            "2022-01-08 01:41:58 - INFO:\ttrain #2300 lr = 7.95e-05 loss = 0.189878 train = 0.934375 valid = 0.784119\n",
            "2022-01-08 01:42:01 - INFO:\tSaved test = 0.783630\n",
            "2022-01-08 01:42:33 - INFO:\ttrain #2320 lr = 7.93e-05 loss = 0.176238 train = 0.939355 valid = 0.794476\n",
            "2022-01-08 01:43:05 - INFO:\ttrain #2340 lr = 7.91e-05 loss = 0.186806 train = 0.937891 valid = 0.783509\n",
            "2022-01-08 01:43:37 - INFO:\ttrain #2360 lr = 7.90e-05 loss = 0.176443 train = 0.943457 valid = 0.788180\n",
            "2022-01-08 01:44:08 - INFO:\ttrain #2380 lr = 7.88e-05 loss = 0.189029 train = 0.935352 valid = 0.791227\n",
            "2022-01-08 01:44:40 - INFO:\ttrain #2400 lr = 7.87e-05 loss = 0.171209 train = 0.942480 valid = 0.804021 updated\n",
            "2022-01-08 01:44:43 - INFO:\tSaved test = 0.784846\n",
            "2022-01-08 01:45:15 - INFO:\ttrain #2420 lr = 7.85e-05 loss = 0.177325 train = 0.939746 valid = 0.796913\n",
            "2022-01-08 01:45:47 - INFO:\ttrain #2440 lr = 7.83e-05 loss = 0.173368 train = 0.941211 valid = 0.794273\n",
            "2022-01-08 01:46:19 - INFO:\ttrain #2460 lr = 7.82e-05 loss = 0.184307 train = 0.938672 valid = 0.775792\n",
            "2022-01-08 01:46:50 - INFO:\ttrain #2480 lr = 7.80e-05 loss = 0.181466 train = 0.939355 valid = 0.793867\n",
            "2022-01-08 01:47:22 - INFO:\ttrain #2500 lr = 7.79e-05 loss = 0.176992 train = 0.937598 valid = 0.790617\n",
            "2022-01-08 01:47:25 - INFO:\tSaved test = 0.773096\n",
            "2022-01-08 01:47:57 - INFO:\ttrain #2520 lr = 7.77e-05 loss = 0.163773 train = 0.944629 valid = 0.784931\n",
            "2022-01-08 01:48:29 - INFO:\ttrain #2540 lr = 7.76e-05 loss = 0.168361 train = 0.944043 valid = 0.793054\n",
            "2022-01-08 01:49:01 - INFO:\ttrain #2560 lr = 7.74e-05 loss = 0.167424 train = 0.944238 valid = 0.794476\n",
            "2022-01-08 01:49:32 - INFO:\ttrain #2580 lr = 7.73e-05 loss = 0.156241 train = 0.946387 valid = 0.795288\n",
            "2022-01-08 01:50:04 - INFO:\ttrain #2600 lr = 7.71e-05 loss = 0.163550 train = 0.946094 valid = 0.781478\n",
            "2022-01-08 01:50:07 - INFO:\tSaved test = 0.777958\n",
            "2022-01-08 01:50:39 - INFO:\ttrain #2620 lr = 7.70e-05 loss = 0.161360 train = 0.944531 valid = 0.788790\n",
            "2022-01-08 01:51:11 - INFO:\ttrain #2640 lr = 7.68e-05 loss = 0.156683 train = 0.944434 valid = 0.802193\n",
            "2022-01-08 01:51:43 - INFO:\ttrain #2660 lr = 7.66e-05 loss = 0.161873 train = 0.944727 valid = 0.809098 updated\n",
            "2022-01-08 01:52:15 - INFO:\ttrain #2680 lr = 7.65e-05 loss = 0.148090 train = 0.950488 valid = 0.802803\n",
            "2022-01-08 01:52:46 - INFO:\ttrain #2700 lr = 7.63e-05 loss = 0.163478 train = 0.943457 valid = 0.788790\n",
            "2022-01-08 01:52:49 - INFO:\tSaved test = 0.786467\n",
            "2022-01-08 01:53:21 - INFO:\ttrain #2720 lr = 7.62e-05 loss = 0.154070 train = 0.947754 valid = 0.794476\n",
            "2022-01-08 01:53:53 - INFO:\ttrain #2740 lr = 7.60e-05 loss = 0.161479 train = 0.943652 valid = 0.801178\n",
            "2022-01-08 01:54:25 - INFO:\ttrain #2760 lr = 7.59e-05 loss = 0.163882 train = 0.943457 valid = 0.790008\n",
            "2022-01-08 01:54:57 - INFO:\ttrain #2780 lr = 7.57e-05 loss = 0.159848 train = 0.945117 valid = 0.799350\n",
            "2022-01-08 01:55:28 - INFO:\ttrain #2800 lr = 7.56e-05 loss = 0.143635 train = 0.951465 valid = 0.805849\n",
            "2022-01-08 01:55:30 - INFO:\tSaved test = 0.794165\n",
            "2022-01-08 01:56:02 - INFO:\ttrain #2820 lr = 7.54e-05 loss = 0.151677 train = 0.949707 valid = 0.803209\n",
            "2022-01-08 01:56:32 - INFO:\ttrain #2840 lr = 7.53e-05 loss = 0.146655 train = 0.947656 valid = 0.803006\n",
            "2022-01-08 01:57:04 - INFO:\ttrain #2860 lr = 7.51e-05 loss = 0.138421 train = 0.953711 valid = 0.800366\n",
            "2022-01-08 01:57:35 - INFO:\ttrain #2880 lr = 7.50e-05 loss = 0.160457 train = 0.945117 valid = 0.803412\n",
            "2022-01-08 01:58:06 - INFO:\ttrain #2900 lr = 7.48e-05 loss = 0.152633 train = 0.949609 valid = 0.789196\n",
            "2022-01-08 01:58:08 - INFO:\tSaved test = 0.787682\n",
            "2022-01-08 01:58:39 - INFO:\ttrain #2920 lr = 7.47e-05 loss = 0.141674 train = 0.950977 valid = 0.801381\n",
            "2022-01-08 01:59:11 - INFO:\ttrain #2940 lr = 7.45e-05 loss = 0.143347 train = 0.952930 valid = 0.788383\n",
            "2022-01-08 01:59:42 - INFO:\ttrain #2960 lr = 7.44e-05 loss = 0.147425 train = 0.950488 valid = 0.784728\n",
            "2022-01-08 02:00:13 - INFO:\ttrain #2980 lr = 7.42e-05 loss = 0.140076 train = 0.953125 valid = 0.803615\n",
            "2022-01-08 02:00:43 - INFO:\ttrain #3000 lr = 7.41e-05 loss = 0.135121 train = 0.954688 valid = 0.790820\n",
            "2022-01-08 02:00:46 - INFO:\tSaved test = 0.783225\n",
            "2022-01-08 02:01:17 - INFO:\ttrain #3020 lr = 7.39e-05 loss = 0.135362 train = 0.955273 valid = 0.795085\n",
            "2022-01-08 02:01:48 - INFO:\ttrain #3040 lr = 7.38e-05 loss = 0.131889 train = 0.954785 valid = 0.795898\n",
            "2022-01-08 02:02:19 - INFO:\ttrain #3060 lr = 7.36e-05 loss = 0.137554 train = 0.953418 valid = 0.794882\n",
            "2022-01-08 02:02:50 - INFO:\ttrain #3080 lr = 7.35e-05 loss = 0.128399 train = 0.956543 valid = 0.794273\n",
            "2022-01-08 02:03:21 - INFO:\ttrain #3100 lr = 7.33e-05 loss = 0.144701 train = 0.950488 valid = 0.803818\n",
            "2022-01-08 02:03:23 - INFO:\tSaved test = 0.792545\n",
            "2022-01-08 02:03:54 - INFO:\ttrain #3120 lr = 7.32e-05 loss = 0.138563 train = 0.951660 valid = 0.806661\n",
            "2022-01-08 02:04:25 - INFO:\ttrain #3140 lr = 7.31e-05 loss = 0.133939 train = 0.954590 valid = 0.791430\n",
            "2022-01-08 02:04:56 - INFO:\ttrain #3160 lr = 7.29e-05 loss = 0.139447 train = 0.952051 valid = 0.799959\n",
            "2022-01-08 02:05:26 - INFO:\ttrain #3180 lr = 7.28e-05 loss = 0.129282 train = 0.954590 valid = 0.790211\n",
            "2022-01-08 02:05:57 - INFO:\ttrain #3200 lr = 7.26e-05 loss = 0.124342 train = 0.957617 valid = 0.799350\n",
            "2022-01-08 02:06:00 - INFO:\tSaved test = 0.790519\n",
            "2022-01-08 02:06:30 - INFO:\ttrain #3220 lr = 7.25e-05 loss = 0.131828 train = 0.955469 valid = 0.806864\n",
            "2022-01-08 02:07:02 - INFO:\ttrain #3240 lr = 7.23e-05 loss = 0.126928 train = 0.956934 valid = 0.798132\n",
            "2022-01-08 02:07:33 - INFO:\ttrain #3260 lr = 7.22e-05 loss = 0.128696 train = 0.953125 valid = 0.809911 updated\n",
            "2022-01-08 02:08:04 - INFO:\ttrain #3280 lr = 7.20e-05 loss = 0.127320 train = 0.956152 valid = 0.792851\n",
            "2022-01-08 02:08:35 - INFO:\ttrain #3300 lr = 7.19e-05 loss = 0.122540 train = 0.960352 valid = 0.804021\n",
            "2022-01-08 02:08:37 - INFO:\tSaved test = 0.793760\n",
            "2022-01-08 02:09:09 - INFO:\ttrain #3320 lr = 7.17e-05 loss = 0.114252 train = 0.961230 valid = 0.807474\n",
            "2022-01-08 02:09:40 - INFO:\ttrain #3340 lr = 7.16e-05 loss = 0.134006 train = 0.951660 valid = 0.804224\n",
            "2022-01-08 02:10:11 - INFO:\ttrain #3360 lr = 7.15e-05 loss = 0.118358 train = 0.958301 valid = 0.806458\n",
            "2022-01-08 02:10:42 - INFO:\ttrain #3380 lr = 7.13e-05 loss = 0.122199 train = 0.958691 valid = 0.801990\n",
            "2022-01-08 02:11:13 - INFO:\ttrain #3400 lr = 7.12e-05 loss = 0.127003 train = 0.957617 valid = 0.811738 updated\n",
            "2022-01-08 02:11:16 - INFO:\tSaved test = 0.797002\n",
            "2022-01-08 02:11:47 - INFO:\ttrain #3420 lr = 7.10e-05 loss = 0.120296 train = 0.960449 valid = 0.794882\n",
            "2022-01-08 02:12:18 - INFO:\ttrain #3440 lr = 7.09e-05 loss = 0.120714 train = 0.960449 valid = 0.799350\n",
            "2022-01-08 02:12:49 - INFO:\ttrain #3460 lr = 7.08e-05 loss = 0.119962 train = 0.957129 valid = 0.791227\n",
            "2022-01-08 02:13:20 - INFO:\ttrain #3480 lr = 7.06e-05 loss = 0.116543 train = 0.958105 valid = 0.801178\n",
            "2022-01-08 02:13:51 - INFO:\ttrain #3500 lr = 7.05e-05 loss = 0.122173 train = 0.957227 valid = 0.793054\n",
            "2022-01-08 02:13:54 - INFO:\tSaved test = 0.779579\n",
            "2022-01-08 02:14:25 - INFO:\ttrain #3520 lr = 7.03e-05 loss = 0.116788 train = 0.959473 valid = 0.806255\n",
            "2022-01-08 02:14:56 - INFO:\ttrain #3540 lr = 7.02e-05 loss = 0.127508 train = 0.956445 valid = 0.803006\n",
            "2022-01-08 02:15:27 - INFO:\ttrain #3560 lr = 7.00e-05 loss = 0.124930 train = 0.956348 valid = 0.811535\n",
            "2022-01-08 02:15:58 - INFO:\ttrain #3580 lr = 6.99e-05 loss = 0.117404 train = 0.959277 valid = 0.799756\n",
            "2022-01-08 02:16:30 - INFO:\ttrain #3600 lr = 6.98e-05 loss = 0.107798 train = 0.963672 valid = 0.810723\n",
            "2022-01-08 02:16:32 - INFO:\tSaved test = 0.810373\n",
            "2022-01-08 02:17:03 - INFO:\ttrain #3620 lr = 6.96e-05 loss = 0.106332 train = 0.966113 valid = 0.813972 updated\n",
            "2022-01-08 02:17:35 - INFO:\ttrain #3640 lr = 6.95e-05 loss = 0.104717 train = 0.964844 valid = 0.805443\n",
            "2022-01-08 02:18:06 - INFO:\ttrain #3660 lr = 6.93e-05 loss = 0.106214 train = 0.963672 valid = 0.804224\n",
            "2022-01-08 02:18:37 - INFO:\ttrain #3680 lr = 6.92e-05 loss = 0.107625 train = 0.962305 valid = 0.803615\n",
            "2022-01-08 02:19:08 - INFO:\ttrain #3700 lr = 6.91e-05 loss = 0.109333 train = 0.965527 valid = 0.811535\n",
            "2022-01-08 02:19:10 - INFO:\tSaved test = 0.797407\n",
            "2022-01-08 02:19:41 - INFO:\ttrain #3720 lr = 6.89e-05 loss = 0.108753 train = 0.963574 valid = 0.805443\n",
            "2022-01-08 02:20:12 - INFO:\ttrain #3740 lr = 6.88e-05 loss = 0.101652 train = 0.964258 valid = 0.807677\n",
            "2022-01-08 02:20:44 - INFO:\ttrain #3760 lr = 6.87e-05 loss = 0.110302 train = 0.962500 valid = 0.806864\n",
            "2022-01-08 02:21:14 - INFO:\ttrain #3780 lr = 6.85e-05 loss = 0.106671 train = 0.964551 valid = 0.805443\n",
            "2022-01-08 02:21:46 - INFO:\ttrain #3800 lr = 6.84e-05 loss = 0.113605 train = 0.961523 valid = 0.814379 updated\n",
            "2022-01-08 02:21:48 - INFO:\tSaved test = 0.796191\n",
            "2022-01-08 02:22:19 - INFO:\ttrain #3820 lr = 6.82e-05 loss = 0.105152 train = 0.964648 valid = 0.802600\n",
            "2022-01-08 02:22:50 - INFO:\ttrain #3840 lr = 6.81e-05 loss = 0.119382 train = 0.959375 valid = 0.798741\n",
            "2022-01-08 02:23:21 - INFO:\ttrain #3860 lr = 6.80e-05 loss = 0.098326 train = 0.969434 valid = 0.807880\n",
            "2022-01-08 02:23:53 - INFO:\ttrain #3880 lr = 6.78e-05 loss = 0.103463 train = 0.964648 valid = 0.806458\n",
            "2022-01-08 02:24:24 - INFO:\ttrain #3900 lr = 6.77e-05 loss = 0.100623 train = 0.964551 valid = 0.794679\n",
            "2022-01-08 02:24:26 - INFO:\tSaved test = 0.788898\n",
            "2022-01-08 02:24:57 - INFO:\ttrain #3920 lr = 6.76e-05 loss = 0.103426 train = 0.963672 valid = 0.803615\n",
            "2022-01-08 02:25:28 - INFO:\ttrain #3940 lr = 6.74e-05 loss = 0.102644 train = 0.963965 valid = 0.803412\n",
            "2022-01-08 02:25:59 - INFO:\ttrain #3960 lr = 6.73e-05 loss = 0.111235 train = 0.961328 valid = 0.799756\n",
            "2022-01-08 02:26:31 - INFO:\ttrain #3980 lr = 6.72e-05 loss = 0.110688 train = 0.961328 valid = 0.813160\n",
            "2022-01-08 02:27:02 - INFO:\ttrain #4000 lr = 6.70e-05 loss = 0.097500 train = 0.967383 valid = 0.798944\n",
            "2022-01-08 02:27:04 - INFO:\tSaved test = 0.795786\n",
            "2022-01-08 02:27:35 - INFO:\ttrain #4020 lr = 6.69e-05 loss = 0.096058 train = 0.967187 valid = 0.809301\n",
            "2022-01-08 02:28:06 - INFO:\ttrain #4040 lr = 6.68e-05 loss = 0.100670 train = 0.965820 valid = 0.807474\n",
            "2022-01-08 02:28:38 - INFO:\ttrain #4060 lr = 6.66e-05 loss = 0.103451 train = 0.964355 valid = 0.806864\n",
            "2022-01-08 02:29:09 - INFO:\ttrain #4080 lr = 6.65e-05 loss = 0.090880 train = 0.969043 valid = 0.803818\n",
            "2022-01-08 02:29:40 - INFO:\ttrain #4100 lr = 6.64e-05 loss = 0.096424 train = 0.966113 valid = 0.800975\n",
            "2022-01-08 02:29:42 - INFO:\tSaved test = 0.795786\n",
            "2022-01-08 02:30:14 - INFO:\ttrain #4120 lr = 6.62e-05 loss = 0.098505 train = 0.966016 valid = 0.795695\n",
            "2022-01-08 02:30:45 - INFO:\ttrain #4140 lr = 6.61e-05 loss = 0.101349 train = 0.964941 valid = 0.816003 updated\n",
            "2022-01-08 02:31:16 - INFO:\ttrain #4160 lr = 6.60e-05 loss = 0.098924 train = 0.966504 valid = 0.792648\n",
            "2022-01-08 02:31:47 - INFO:\ttrain #4180 lr = 6.58e-05 loss = 0.091980 train = 0.969043 valid = 0.803412\n",
            "2022-01-08 02:32:18 - INFO:\ttrain #4200 lr = 6.57e-05 loss = 0.086543 train = 0.971582 valid = 0.806255\n",
            "2022-01-08 02:32:21 - INFO:\tSaved test = 0.796191\n",
            "2022-01-08 02:32:52 - INFO:\ttrain #4220 lr = 6.56e-05 loss = 0.090777 train = 0.970020 valid = 0.824939 updated\n",
            "2022-01-08 02:33:23 - INFO:\ttrain #4240 lr = 6.54e-05 loss = 0.087693 train = 0.969531 valid = 0.796913\n",
            "2022-01-08 02:33:54 - INFO:\ttrain #4260 lr = 6.53e-05 loss = 0.092798 train = 0.966699 valid = 0.803818\n",
            "2022-01-08 02:34:25 - INFO:\ttrain #4280 lr = 6.52e-05 loss = 0.080588 train = 0.973926 valid = 0.800366\n",
            "2022-01-08 02:34:56 - INFO:\ttrain #4300 lr = 6.50e-05 loss = 0.086298 train = 0.968555 valid = 0.805849\n",
            "2022-01-08 02:34:59 - INFO:\tSaved test = 0.802674\n",
            "2022-01-08 02:35:30 - INFO:\ttrain #4320 lr = 6.49e-05 loss = 0.084242 train = 0.971387 valid = 0.806052\n",
            "2022-01-08 02:36:01 - INFO:\ttrain #4340 lr = 6.48e-05 loss = 0.092548 train = 0.969141 valid = 0.803412\n",
            "2022-01-08 02:36:32 - INFO:\ttrain #4360 lr = 6.47e-05 loss = 0.094287 train = 0.969238 valid = 0.801787\n",
            "2022-01-08 02:37:04 - INFO:\ttrain #4380 lr = 6.45e-05 loss = 0.086712 train = 0.970410 valid = 0.802600\n",
            "2022-01-08 02:37:35 - INFO:\ttrain #4400 lr = 6.44e-05 loss = 0.087560 train = 0.968945 valid = 0.813972\n",
            "2022-01-08 02:37:37 - INFO:\tSaved test = 0.805511\n",
            "2022-01-08 02:38:09 - INFO:\ttrain #4420 lr = 6.43e-05 loss = 0.090953 train = 0.969043 valid = 0.801990\n",
            "2022-01-08 02:38:40 - INFO:\ttrain #4440 lr = 6.41e-05 loss = 0.089876 train = 0.969531 valid = 0.804021\n",
            "2022-01-08 02:39:11 - INFO:\ttrain #4460 lr = 6.40e-05 loss = 0.089891 train = 0.968164 valid = 0.808895\n",
            "2022-01-08 02:39:42 - INFO:\ttrain #4480 lr = 6.39e-05 loss = 0.085369 train = 0.970215 valid = 0.811332\n",
            "2022-01-08 02:40:13 - INFO:\ttrain #4500 lr = 6.38e-05 loss = 0.085354 train = 0.970898 valid = 0.809301\n",
            "2022-01-08 02:40:16 - INFO:\tSaved test = 0.812804\n",
            "2022-01-08 02:40:47 - INFO:\ttrain #4520 lr = 6.36e-05 loss = 0.092751 train = 0.968945 valid = 0.810317\n",
            "2022-01-08 02:41:18 - INFO:\ttrain #4540 lr = 6.35e-05 loss = 0.079838 train = 0.972266 valid = 0.810317\n",
            "2022-01-08 02:41:49 - INFO:\ttrain #4560 lr = 6.34e-05 loss = 0.085283 train = 0.970703 valid = 0.802396\n",
            "2022-01-08 02:42:21 - INFO:\ttrain #4580 lr = 6.33e-05 loss = 0.085565 train = 0.970508 valid = 0.807271\n",
            "2022-01-08 02:42:52 - INFO:\ttrain #4600 lr = 6.31e-05 loss = 0.091917 train = 0.968457 valid = 0.808489\n",
            "2022-01-08 02:42:54 - INFO:\tSaved test = 0.803485\n",
            "2022-01-08 02:43:25 - INFO:\ttrain #4620 lr = 6.30e-05 loss = 0.086726 train = 0.967578 valid = 0.816613\n",
            "2022-01-08 02:43:56 - INFO:\ttrain #4640 lr = 6.29e-05 loss = 0.081392 train = 0.972656 valid = 0.805037\n",
            "2022-01-08 02:44:27 - INFO:\ttrain #4660 lr = 6.27e-05 loss = 0.081970 train = 0.970898 valid = 0.807677\n",
            "2022-01-08 02:44:58 - INFO:\ttrain #4680 lr = 6.26e-05 loss = 0.084609 train = 0.971289 valid = 0.811942\n",
            "2022-01-08 02:45:29 - INFO:\ttrain #4700 lr = 6.25e-05 loss = 0.079078 train = 0.972852 valid = 0.817222\n",
            "2022-01-08 02:45:31 - INFO:\tSaved test = 0.805105\n",
            "2022-01-08 02:46:02 - INFO:\ttrain #4720 lr = 6.24e-05 loss = 0.083440 train = 0.970410 valid = 0.813160\n",
            "2022-01-08 02:46:34 - INFO:\ttrain #4740 lr = 6.22e-05 loss = 0.086053 train = 0.968652 valid = 0.806255\n",
            "2022-01-08 02:47:05 - INFO:\ttrain #4760 lr = 6.21e-05 loss = 0.084752 train = 0.970605 valid = 0.794070\n",
            "2022-01-08 02:47:36 - INFO:\ttrain #4780 lr = 6.20e-05 loss = 0.086606 train = 0.971387 valid = 0.816409\n",
            "2022-01-08 02:48:07 - INFO:\ttrain #4800 lr = 6.19e-05 loss = 0.076799 train = 0.973926 valid = 0.812145\n",
            "2022-01-08 02:48:09 - INFO:\tSaved test = 0.800243\n",
            "2022-01-08 02:48:40 - INFO:\ttrain #4820 lr = 6.18e-05 loss = 0.081032 train = 0.973047 valid = 0.817222\n",
            "2022-01-08 02:49:12 - INFO:\ttrain #4840 lr = 6.16e-05 loss = 0.081399 train = 0.971777 valid = 0.811738\n",
            "2022-01-08 02:49:43 - INFO:\ttrain #4860 lr = 6.15e-05 loss = 0.079793 train = 0.973437 valid = 0.804833\n",
            "2022-01-08 02:50:14 - INFO:\ttrain #4880 lr = 6.14e-05 loss = 0.080653 train = 0.971680 valid = 0.809708\n",
            "2022-01-08 02:50:45 - INFO:\ttrain #4900 lr = 6.13e-05 loss = 0.073425 train = 0.975000 valid = 0.804224\n",
            "2022-01-08 02:50:48 - INFO:\tSaved test = 0.794976\n",
            "2022-01-08 02:51:19 - INFO:\ttrain #4920 lr = 6.11e-05 loss = 0.085172 train = 0.970703 valid = 0.810114\n",
            "2022-01-08 02:51:50 - INFO:\ttrain #4940 lr = 6.10e-05 loss = 0.078099 train = 0.973340 valid = 0.796507\n",
            "2022-01-08 02:52:21 - INFO:\ttrain #4960 lr = 6.09e-05 loss = 0.080081 train = 0.970410 valid = 0.804224\n",
            "2022-01-08 02:52:52 - INFO:\ttrain #4980 lr = 6.08e-05 loss = 0.081292 train = 0.971191 valid = 0.808286\n",
            "2022-01-08 02:53:23 - INFO:\ttrain #5000 lr = 6.07e-05 loss = 0.074496 train = 0.972754 valid = 0.820065\n",
            "2022-01-08 02:53:25 - INFO:\tSaved test = 0.808752\n",
            "2022-01-08 02:53:57 - INFO:\ttrain #5020 lr = 6.05e-05 loss = 0.075341 train = 0.975879 valid = 0.802396\n",
            "2022-01-08 02:54:28 - INFO:\ttrain #5040 lr = 6.04e-05 loss = 0.084385 train = 0.969824 valid = 0.802803\n",
            "2022-01-08 02:54:59 - INFO:\ttrain #5060 lr = 6.03e-05 loss = 0.076456 train = 0.974805 valid = 0.812754\n",
            "2022-01-08 02:55:30 - INFO:\ttrain #5080 lr = 6.02e-05 loss = 0.067335 train = 0.977637 valid = 0.808692\n",
            "2022-01-08 02:56:01 - INFO:\ttrain #5100 lr = 6.00e-05 loss = 0.073394 train = 0.973535 valid = 0.803615\n",
            "2022-01-08 02:56:03 - INFO:\tSaved test = 0.800648\n",
            "2022-01-08 02:56:35 - INFO:\ttrain #5120 lr = 5.99e-05 loss = 0.074602 train = 0.975391 valid = 0.809708\n",
            "2022-01-08 02:57:06 - INFO:\ttrain #5140 lr = 5.98e-05 loss = 0.066827 train = 0.977441 valid = 0.810520\n",
            "2022-01-08 02:57:37 - INFO:\ttrain #5160 lr = 5.97e-05 loss = 0.068412 train = 0.975586 valid = 0.816003\n",
            "2022-01-08 02:58:08 - INFO:\ttrain #5180 lr = 5.96e-05 loss = 0.072601 train = 0.974902 valid = 0.810317\n",
            "2022-01-08 02:58:39 - INFO:\ttrain #5200 lr = 5.95e-05 loss = 0.071771 train = 0.975684 valid = 0.813769\n",
            "2022-01-08 02:58:41 - INFO:\tSaved test = 0.800243\n",
            "2022-01-08 02:59:13 - INFO:\ttrain #5220 lr = 5.93e-05 loss = 0.072221 train = 0.975879 valid = 0.810520\n",
            "2022-01-08 02:59:44 - INFO:\ttrain #5240 lr = 5.92e-05 loss = 0.074652 train = 0.973730 valid = 0.801787\n",
            "2022-01-08 03:00:15 - INFO:\ttrain #5260 lr = 5.91e-05 loss = 0.073052 train = 0.974219 valid = 0.813769\n",
            "2022-01-08 03:00:46 - INFO:\ttrain #5280 lr = 5.90e-05 loss = 0.069541 train = 0.975879 valid = 0.805849\n",
            "2022-01-08 03:01:17 - INFO:\ttrain #5300 lr = 5.89e-05 loss = 0.071285 train = 0.975781 valid = 0.815191\n",
            "2022-01-08 03:01:19 - INFO:\tSaved test = 0.807131\n",
            "2022-01-08 03:01:51 - INFO:\ttrain #5320 lr = 5.87e-05 loss = 0.075009 train = 0.974219 valid = 0.809708\n",
            "2022-01-08 03:02:22 - INFO:\ttrain #5340 lr = 5.86e-05 loss = 0.065266 train = 0.978516 valid = 0.817019\n",
            "2022-01-08 03:02:53 - INFO:\ttrain #5360 lr = 5.85e-05 loss = 0.073191 train = 0.976465 valid = 0.805849\n",
            "2022-01-08 03:03:24 - INFO:\ttrain #5380 lr = 5.84e-05 loss = 0.067987 train = 0.977051 valid = 0.807474\n",
            "2022-01-08 03:03:56 - INFO:\ttrain #5400 lr = 5.83e-05 loss = 0.070650 train = 0.975293 valid = 0.813769\n",
            "2022-01-08 03:03:58 - INFO:\tSaved test = 0.790924\n",
            "2022-01-08 03:04:29 - INFO:\ttrain #5420 lr = 5.82e-05 loss = 0.061482 train = 0.978418 valid = 0.811332\n",
            "2022-01-08 03:05:00 - INFO:\ttrain #5440 lr = 5.80e-05 loss = 0.069497 train = 0.974902 valid = 0.812957\n",
            "2022-01-08 03:05:30 - INFO:\ttrain #5460 lr = 5.79e-05 loss = 0.066946 train = 0.976172 valid = 0.816409\n",
            "2022-01-08 03:06:02 - INFO:\ttrain #5480 lr = 5.78e-05 loss = 0.061240 train = 0.978906 valid = 0.811129\n",
            "2022-01-08 03:06:33 - INFO:\ttrain #5500 lr = 5.77e-05 loss = 0.065936 train = 0.977051 valid = 0.808286\n",
            "2022-01-08 03:06:35 - INFO:\tSaved test = 0.806321\n",
            "2022-01-08 03:07:06 - INFO:\ttrain #5520 lr = 5.76e-05 loss = 0.069623 train = 0.976367 valid = 0.810317\n",
            "2022-01-08 03:07:37 - INFO:\ttrain #5540 lr = 5.75e-05 loss = 0.067088 train = 0.976855 valid = 0.805849\n",
            "2022-01-08 03:08:08 - INFO:\ttrain #5560 lr = 5.73e-05 loss = 0.067357 train = 0.977539 valid = 0.804427\n",
            "2022-01-08 03:08:39 - INFO:\ttrain #5580 lr = 5.72e-05 loss = 0.060628 train = 0.980566 valid = 0.813566\n",
            "2022-01-08 03:09:10 - INFO:\ttrain #5600 lr = 5.71e-05 loss = 0.068403 train = 0.976270 valid = 0.812145\n",
            "2022-01-08 03:09:12 - INFO:\tSaved test = 0.803485\n",
            "2022-01-08 03:09:43 - INFO:\ttrain #5620 lr = 5.70e-05 loss = 0.066613 train = 0.977637 valid = 0.816409\n",
            "2022-01-08 03:10:15 - INFO:\ttrain #5640 lr = 5.69e-05 loss = 0.062112 train = 0.979980 valid = 0.810520\n",
            "2022-01-08 03:10:46 - INFO:\ttrain #5660 lr = 5.68e-05 loss = 0.060808 train = 0.979004 valid = 0.808286\n",
            "2022-01-08 03:11:17 - INFO:\ttrain #5680 lr = 5.67e-05 loss = 0.069150 train = 0.975293 valid = 0.811332\n",
            "2022-01-08 03:11:48 - INFO:\ttrain #5700 lr = 5.66e-05 loss = 0.064548 train = 0.977734 valid = 0.815191\n",
            "2022-01-08 03:11:51 - INFO:\tSaved test = 0.815640\n",
            "2022-01-08 03:12:22 - INFO:\ttrain #5720 lr = 5.64e-05 loss = 0.065978 train = 0.977637 valid = 0.809098\n",
            "2022-01-08 03:12:53 - INFO:\ttrain #5740 lr = 5.63e-05 loss = 0.062439 train = 0.978711 valid = 0.813566\n",
            "2022-01-08 03:13:24 - INFO:\ttrain #5760 lr = 5.62e-05 loss = 0.058637 train = 0.980176 valid = 0.800569\n",
            "2022-01-08 03:13:55 - INFO:\ttrain #5780 lr = 5.61e-05 loss = 0.064999 train = 0.976953 valid = 0.809708\n",
            "2022-01-08 03:14:26 - INFO:\ttrain #5800 lr = 5.60e-05 loss = 0.062624 train = 0.977246 valid = 0.806255\n",
            "2022-01-08 03:14:28 - INFO:\tSaved test = 0.809968\n",
            "2022-01-08 03:14:59 - INFO:\ttrain #5820 lr = 5.59e-05 loss = 0.067611 train = 0.977246 valid = 0.807880\n",
            "2022-01-08 03:15:30 - INFO:\ttrain #5840 lr = 5.58e-05 loss = 0.071318 train = 0.974902 valid = 0.814785\n",
            "2022-01-08 03:16:02 - INFO:\ttrain #5860 lr = 5.57e-05 loss = 0.062099 train = 0.978613 valid = 0.806052\n",
            "2022-01-08 03:16:33 - INFO:\ttrain #5880 lr = 5.55e-05 loss = 0.056503 train = 0.979102 valid = 0.812551\n",
            "2022-01-08 03:17:04 - INFO:\ttrain #5900 lr = 5.54e-05 loss = 0.060643 train = 0.979785 valid = 0.804021\n",
            "2022-01-08 03:17:06 - INFO:\tSaved test = 0.804295\n",
            "2022-01-08 03:17:37 - INFO:\ttrain #5920 lr = 5.53e-05 loss = 0.063158 train = 0.979102 valid = 0.810317\n",
            "2022-01-08 03:18:09 - INFO:\ttrain #5940 lr = 5.52e-05 loss = 0.061081 train = 0.978711 valid = 0.810114\n",
            "2022-01-08 03:18:40 - INFO:\ttrain #5960 lr = 5.51e-05 loss = 0.060682 train = 0.979785 valid = 0.816206\n",
            "2022-01-08 03:19:11 - INFO:\ttrain #5980 lr = 5.50e-05 loss = 0.054328 train = 0.982324 valid = 0.822096\n",
            "2022-01-08 03:19:42 - INFO:\ttrain #6000 lr = 5.49e-05 loss = 0.057637 train = 0.980762 valid = 0.814988\n",
            "2022-01-08 03:19:44 - INFO:\tSaved test = 0.805105\n",
            "2022-01-08 03:20:15 - INFO:\ttrain #6020 lr = 5.48e-05 loss = 0.057996 train = 0.979297 valid = 0.816409\n",
            "2022-01-08 03:20:46 - INFO:\ttrain #6040 lr = 5.47e-05 loss = 0.063261 train = 0.976074 valid = 0.810723\n",
            "2022-01-08 03:21:17 - INFO:\ttrain #6060 lr = 5.46e-05 loss = 0.056962 train = 0.980664 valid = 0.817019\n",
            "2022-01-08 03:21:49 - INFO:\ttrain #6080 lr = 5.44e-05 loss = 0.062157 train = 0.979980 valid = 0.811942\n",
            "2022-01-08 03:22:20 - INFO:\ttrain #6100 lr = 5.43e-05 loss = 0.052947 train = 0.981055 valid = 0.817831\n",
            "2022-01-08 03:22:22 - INFO:\tSaved test = 0.806726\n",
            "2022-01-08 03:22:53 - INFO:\ttrain #6120 lr = 5.42e-05 loss = 0.059661 train = 0.979199 valid = 0.799756\n",
            "2022-01-08 03:23:24 - INFO:\ttrain #6140 lr = 5.41e-05 loss = 0.058526 train = 0.979785 valid = 0.811332\n",
            "2022-01-08 03:23:55 - INFO:\ttrain #6160 lr = 5.40e-05 loss = 0.054562 train = 0.980762 valid = 0.813160\n",
            "2022-01-08 03:24:26 - INFO:\ttrain #6180 lr = 5.39e-05 loss = 0.061264 train = 0.978906 valid = 0.810317\n",
            "2022-01-08 03:24:58 - INFO:\ttrain #6200 lr = 5.38e-05 loss = 0.058737 train = 0.978809 valid = 0.811942\n",
            "2022-01-08 03:25:00 - INFO:\tSaved test = 0.801459\n",
            "2022-01-08 03:25:31 - INFO:\ttrain #6220 lr = 5.37e-05 loss = 0.058089 train = 0.979395 valid = 0.811129\n",
            "2022-01-08 03:26:02 - INFO:\ttrain #6240 lr = 5.36e-05 loss = 0.052206 train = 0.981055 valid = 0.817222\n",
            "2022-01-08 03:26:33 - INFO:\ttrain #6260 lr = 5.35e-05 loss = 0.058033 train = 0.981641 valid = 0.813160\n",
            "2022-01-08 03:27:04 - INFO:\ttrain #6280 lr = 5.34e-05 loss = 0.056902 train = 0.979785 valid = 0.811129\n",
            "2022-01-08 03:27:36 - INFO:\ttrain #6300 lr = 5.33e-05 loss = 0.051908 train = 0.982227 valid = 0.819659\n",
            "2022-01-08 03:27:38 - INFO:\tSaved test = 0.798622\n",
            "2022-01-08 03:28:09 - INFO:\ttrain #6320 lr = 5.32e-05 loss = 0.053377 train = 0.980664 valid = 0.817425\n",
            "2022-01-08 03:28:40 - INFO:\ttrain #6340 lr = 5.30e-05 loss = 0.048966 train = 0.983301 valid = 0.817019\n",
            "2022-01-08 03:29:11 - INFO:\ttrain #6360 lr = 5.29e-05 loss = 0.056614 train = 0.980176 valid = 0.811332\n",
            "2022-01-08 03:29:42 - INFO:\ttrain #6380 lr = 5.28e-05 loss = 0.058250 train = 0.979297 valid = 0.822502\n",
            "2022-01-08 03:30:13 - INFO:\ttrain #6400 lr = 5.27e-05 loss = 0.052797 train = 0.982422 valid = 0.816613\n",
            "2022-01-08 03:30:15 - INFO:\tSaved test = 0.813209\n",
            "2022-01-08 03:30:46 - INFO:\ttrain #6420 lr = 5.26e-05 loss = 0.049873 train = 0.983203 valid = 0.809098\n",
            "2022-01-08 03:31:18 - INFO:\ttrain #6440 lr = 5.25e-05 loss = 0.051146 train = 0.983105 valid = 0.820674\n",
            "2022-01-08 03:31:49 - INFO:\ttrain #6460 lr = 5.24e-05 loss = 0.059668 train = 0.979883 valid = 0.805849\n",
            "2022-01-08 03:32:20 - INFO:\ttrain #6480 lr = 5.23e-05 loss = 0.051476 train = 0.983203 valid = 0.808692\n",
            "2022-01-08 03:32:51 - INFO:\ttrain #6500 lr = 5.22e-05 loss = 0.051126 train = 0.983008 valid = 0.810723\n",
            "2022-01-08 03:32:53 - INFO:\tSaved test = 0.802269\n",
            "2022-01-08 03:33:25 - INFO:\ttrain #6520 lr = 5.21e-05 loss = 0.053512 train = 0.981152 valid = 0.819862\n",
            "2022-01-08 03:33:56 - INFO:\ttrain #6540 lr = 5.20e-05 loss = 0.056911 train = 0.980566 valid = 0.813363\n",
            "2022-01-08 03:34:27 - INFO:\ttrain #6560 lr = 5.19e-05 loss = 0.047459 train = 0.984082 valid = 0.806661\n",
            "2022-01-08 03:34:58 - INFO:\ttrain #6580 lr = 5.18e-05 loss = 0.052341 train = 0.981934 valid = 0.814582\n",
            "2022-01-08 03:35:29 - INFO:\ttrain #6600 lr = 5.17e-05 loss = 0.044681 train = 0.985254 valid = 0.813769\n",
            "2022-01-08 03:35:31 - INFO:\tSaved test = 0.809968\n",
            "2022-01-08 03:36:03 - INFO:\ttrain #6620 lr = 5.16e-05 loss = 0.054051 train = 0.981738 valid = 0.810520\n",
            "2022-01-08 03:36:34 - INFO:\ttrain #6640 lr = 5.15e-05 loss = 0.049663 train = 0.981934 valid = 0.815191\n",
            "2022-01-08 03:37:05 - INFO:\ttrain #6660 lr = 5.14e-05 loss = 0.048315 train = 0.982422 valid = 0.814175\n",
            "2022-01-08 03:37:36 - INFO:\ttrain #6680 lr = 5.13e-05 loss = 0.053421 train = 0.981543 valid = 0.815394\n",
            "2022-01-08 03:38:07 - INFO:\ttrain #6700 lr = 5.12e-05 loss = 0.049937 train = 0.982715 valid = 0.815191\n",
            "2022-01-08 03:38:09 - INFO:\tSaved test = 0.804295\n",
            "2022-01-08 03:38:41 - INFO:\ttrain #6720 lr = 5.11e-05 loss = 0.051092 train = 0.983203 valid = 0.805240\n",
            "2022-01-08 03:39:12 - INFO:\ttrain #6740 lr = 5.10e-05 loss = 0.050869 train = 0.982422 valid = 0.812957\n",
            "2022-01-08 03:39:43 - INFO:\ttrain #6760 lr = 5.09e-05 loss = 0.039698 train = 0.986230 valid = 0.814175\n",
            "2022-01-08 03:40:14 - INFO:\ttrain #6780 lr = 5.08e-05 loss = 0.055692 train = 0.979883 valid = 0.816613\n",
            "2022-01-08 03:40:45 - INFO:\ttrain #6800 lr = 5.07e-05 loss = 0.048027 train = 0.983887 valid = 0.814175\n",
            "2022-01-08 03:40:48 - INFO:\tSaved test = 0.798622\n",
            "2022-01-08 03:41:19 - INFO:\ttrain #6820 lr = 5.06e-05 loss = 0.049575 train = 0.983887 valid = 0.819050\n",
            "2022-01-08 03:41:50 - INFO:\ttrain #6840 lr = 5.05e-05 loss = 0.049482 train = 0.982812 valid = 0.809301\n",
            "2022-01-08 03:42:21 - INFO:\ttrain #6860 lr = 5.04e-05 loss = 0.051074 train = 0.982715 valid = 0.810520\n",
            "2022-01-08 03:42:53 - INFO:\ttrain #6880 lr = 5.03e-05 loss = 0.041616 train = 0.985156 valid = 0.819659\n",
            "2022-01-08 03:43:24 - INFO:\ttrain #6900 lr = 5.02e-05 loss = 0.045678 train = 0.985156 valid = 0.824330\n",
            "2022-01-08 03:43:26 - INFO:\tSaved test = 0.804700\n",
            "2022-01-08 03:43:57 - INFO:\ttrain #6920 lr = 5.01e-05 loss = 0.050120 train = 0.982031 valid = 0.815800\n",
            "2022-01-08 03:44:28 - INFO:\ttrain #6940 lr = 5.00e-05 loss = 0.050400 train = 0.981738 valid = 0.819659\n",
            "2022-01-08 03:44:59 - INFO:\ttrain #6960 lr = 4.99e-05 loss = 0.053109 train = 0.981055 valid = 0.800569\n",
            "2022-01-08 03:45:30 - INFO:\ttrain #6980 lr = 4.98e-05 loss = 0.047373 train = 0.984277 valid = 0.813160\n",
            "2022-01-08 03:46:02 - INFO:\ttrain #7000 lr = 4.97e-05 loss = 0.047391 train = 0.982715 valid = 0.809911\n",
            "2022-01-08 03:46:04 - INFO:\tSaved test = 0.807131\n",
            "2022-01-08 03:46:35 - INFO:\ttrain #7020 lr = 4.96e-05 loss = 0.042838 train = 0.984668 valid = 0.806052\n",
            "2022-01-08 03:47:06 - INFO:\ttrain #7040 lr = 4.95e-05 loss = 0.045117 train = 0.984082 valid = 0.805443\n",
            "2022-01-08 03:47:37 - INFO:\ttrain #7060 lr = 4.94e-05 loss = 0.041292 train = 0.986230 valid = 0.809708\n",
            "2022-01-08 03:48:09 - INFO:\ttrain #7080 lr = 4.93e-05 loss = 0.042332 train = 0.985938 valid = 0.813769\n",
            "2022-01-08 03:48:39 - INFO:\ttrain #7100 lr = 4.92e-05 loss = 0.050905 train = 0.982617 valid = 0.813160\n",
            "2022-01-08 03:48:42 - INFO:\tSaved test = 0.809968\n",
            "2022-01-08 03:49:13 - INFO:\ttrain #7120 lr = 4.91e-05 loss = 0.048426 train = 0.983984 valid = 0.815800\n",
            "2022-01-08 03:49:44 - INFO:\ttrain #7140 lr = 4.90e-05 loss = 0.044624 train = 0.984375 valid = 0.820268\n",
            "2022-01-08 03:50:15 - INFO:\ttrain #7160 lr = 4.89e-05 loss = 0.050057 train = 0.982129 valid = 0.816409\n",
            "2022-01-08 03:50:46 - INFO:\ttrain #7180 lr = 4.88e-05 loss = 0.051967 train = 0.981934 valid = 0.816816\n",
            "2022-01-08 03:51:18 - INFO:\ttrain #7200 lr = 4.87e-05 loss = 0.042169 train = 0.986133 valid = 0.821487\n",
            "2022-01-08 03:51:20 - INFO:\tSaved test = 0.813209\n",
            "2022-01-08 03:51:51 - INFO:\ttrain #7220 lr = 4.86e-05 loss = 0.050996 train = 0.982715 valid = 0.806458\n",
            "2022-01-08 03:52:22 - INFO:\ttrain #7240 lr = 4.85e-05 loss = 0.042464 train = 0.986426 valid = 0.801381\n",
            "2022-01-08 03:52:53 - INFO:\ttrain #7260 lr = 4.84e-05 loss = 0.040031 train = 0.987793 valid = 0.817628\n",
            "2022-01-08 03:53:24 - INFO:\ttrain #7280 lr = 4.83e-05 loss = 0.041909 train = 0.986426 valid = 0.811942\n",
            "2022-01-08 03:53:56 - INFO:\ttrain #7300 lr = 4.82e-05 loss = 0.042233 train = 0.985938 valid = 0.821690\n",
            "2022-01-08 03:53:58 - INFO:\tSaved test = 0.807942\n",
            "2022-01-08 03:54:29 - INFO:\ttrain #7320 lr = 4.81e-05 loss = 0.039211 train = 0.987012 valid = 0.813769\n",
            "2022-01-08 03:55:00 - INFO:\ttrain #7340 lr = 4.80e-05 loss = 0.041074 train = 0.986035 valid = 0.821080\n",
            "2022-01-08 03:55:31 - INFO:\ttrain #7360 lr = 4.79e-05 loss = 0.045429 train = 0.983496 valid = 0.811942\n",
            "2022-01-08 03:56:03 - INFO:\ttrain #7380 lr = 4.78e-05 loss = 0.039039 train = 0.986328 valid = 0.814785\n",
            "2022-01-08 03:56:34 - INFO:\ttrain #7400 lr = 4.77e-05 loss = 0.045076 train = 0.984570 valid = 0.819253\n",
            "2022-01-08 03:56:36 - INFO:\tSaved test = 0.806321\n",
            "2022-01-08 03:57:07 - INFO:\ttrain #7420 lr = 4.76e-05 loss = 0.046917 train = 0.982422 valid = 0.816003\n",
            "2022-01-08 03:57:38 - INFO:\ttrain #7440 lr = 4.75e-05 loss = 0.040866 train = 0.986816 valid = 0.822096\n",
            "2022-01-08 03:58:10 - INFO:\ttrain #7460 lr = 4.74e-05 loss = 0.044390 train = 0.984473 valid = 0.813769\n",
            "2022-01-08 03:58:41 - INFO:\ttrain #7480 lr = 4.73e-05 loss = 0.039261 train = 0.984961 valid = 0.815191\n",
            "2022-01-08 03:59:12 - INFO:\ttrain #7500 lr = 4.72e-05 loss = 0.038172 train = 0.986621 valid = 0.812754\n",
            "2022-01-08 03:59:14 - INFO:\tSaved test = 0.812399\n",
            "2022-01-08 03:59:45 - INFO:\ttrain #7520 lr = 4.71e-05 loss = 0.045997 train = 0.984863 valid = 0.813769\n",
            "2022-01-08 04:00:17 - INFO:\ttrain #7540 lr = 4.70e-05 loss = 0.038727 train = 0.987012 valid = 0.807677\n",
            "2022-01-08 04:00:48 - INFO:\ttrain #7560 lr = 4.70e-05 loss = 0.038354 train = 0.987012 valid = 0.821284\n",
            "2022-01-08 04:01:19 - INFO:\ttrain #7580 lr = 4.69e-05 loss = 0.043730 train = 0.984082 valid = 0.825142 updated\n",
            "2022-01-08 04:01:49 - INFO:\ttrain #7600 lr = 4.68e-05 loss = 0.034658 train = 0.988965 valid = 0.821080\n",
            "2022-01-08 04:01:51 - INFO:\tSaved test = 0.815640\n",
            "2022-01-08 04:02:22 - INFO:\ttrain #7620 lr = 4.67e-05 loss = 0.044436 train = 0.984375 valid = 0.816409\n",
            "2022-01-08 04:02:53 - INFO:\ttrain #7640 lr = 4.66e-05 loss = 0.039872 train = 0.985938 valid = 0.818237\n",
            "2022-01-08 04:03:24 - INFO:\ttrain #7660 lr = 4.65e-05 loss = 0.037732 train = 0.986914 valid = 0.817831\n",
            "2022-01-08 04:03:56 - INFO:\ttrain #7680 lr = 4.64e-05 loss = 0.041836 train = 0.985840 valid = 0.819050\n",
            "2022-01-08 04:04:27 - INFO:\ttrain #7700 lr = 4.63e-05 loss = 0.032667 train = 0.989355 valid = 0.818440\n",
            "2022-01-08 04:04:29 - INFO:\tSaved test = 0.816045\n",
            "2022-01-08 04:05:00 - INFO:\ttrain #7720 lr = 4.62e-05 loss = 0.036268 train = 0.987207 valid = 0.815597\n",
            "2022-01-08 04:05:32 - INFO:\ttrain #7740 lr = 4.61e-05 loss = 0.036935 train = 0.986719 valid = 0.808692\n",
            "2022-01-08 04:06:03 - INFO:\ttrain #7760 lr = 4.60e-05 loss = 0.035974 train = 0.988184 valid = 0.819253\n",
            "2022-01-08 04:06:34 - INFO:\ttrain #7780 lr = 4.59e-05 loss = 0.041799 train = 0.985156 valid = 0.816206\n",
            "2022-01-08 04:07:05 - INFO:\ttrain #7800 lr = 4.58e-05 loss = 0.044792 train = 0.985059 valid = 0.815597\n",
            "2022-01-08 04:07:07 - INFO:\tSaved test = 0.805105\n",
            "2022-01-08 04:07:38 - INFO:\ttrain #7820 lr = 4.57e-05 loss = 0.042089 train = 0.984668 valid = 0.811535\n",
            "2022-01-08 04:08:09 - INFO:\ttrain #7840 lr = 4.57e-05 loss = 0.039259 train = 0.987402 valid = 0.814988\n",
            "2022-01-08 04:08:40 - INFO:\ttrain #7860 lr = 4.56e-05 loss = 0.037821 train = 0.986133 valid = 0.814988\n",
            "2022-01-08 04:09:11 - INFO:\ttrain #7880 lr = 4.55e-05 loss = 0.039887 train = 0.985938 valid = 0.819050\n",
            "2022-01-08 04:09:42 - INFO:\ttrain #7900 lr = 4.54e-05 loss = 0.046434 train = 0.984375 valid = 0.807271\n",
            "2022-01-08 04:09:44 - INFO:\tSaved test = 0.796596\n",
            "2022-01-08 04:10:15 - INFO:\ttrain #7920 lr = 4.53e-05 loss = 0.035893 train = 0.987207 valid = 0.825548 updated\n",
            "2022-01-08 04:10:46 - INFO:\ttrain #7940 lr = 4.52e-05 loss = 0.032136 train = 0.990039 valid = 0.818846\n",
            "2022-01-08 04:11:17 - INFO:\ttrain #7960 lr = 4.51e-05 loss = 0.035767 train = 0.987598 valid = 0.819862\n",
            "2022-01-08 04:11:49 - INFO:\ttrain #7980 lr = 4.50e-05 loss = 0.038547 train = 0.985840 valid = 0.815394\n",
            "2022-01-08 04:12:20 - INFO:\ttrain #8000 lr = 4.49e-05 loss = 0.037949 train = 0.986914 valid = 0.812551\n",
            "2022-01-08 04:12:22 - INFO:\tSaved test = 0.808752\n",
            "2022-01-08 04:12:53 - INFO:\ttrain #8020 lr = 4.48e-05 loss = 0.033635 train = 0.989258 valid = 0.824330\n",
            "2022-01-08 04:13:24 - INFO:\ttrain #8040 lr = 4.48e-05 loss = 0.029854 train = 0.990137 valid = 0.810520\n",
            "2022-01-08 04:13:55 - INFO:\ttrain #8060 lr = 4.47e-05 loss = 0.035041 train = 0.987305 valid = 0.809911\n",
            "2022-01-08 04:14:26 - INFO:\ttrain #8080 lr = 4.46e-05 loss = 0.029352 train = 0.991309 valid = 0.822299\n",
            "2022-01-08 04:14:57 - INFO:\ttrain #8100 lr = 4.45e-05 loss = 0.036981 train = 0.987207 valid = 0.811332\n",
            "2022-01-08 04:15:00 - INFO:\tSaved test = 0.798622\n",
            "2022-01-08 04:15:31 - INFO:\ttrain #8120 lr = 4.44e-05 loss = 0.041127 train = 0.985645 valid = 0.821284\n",
            "2022-01-08 04:16:02 - INFO:\ttrain #8140 lr = 4.43e-05 loss = 0.030429 train = 0.989941 valid = 0.820268\n",
            "2022-01-08 04:16:34 - INFO:\ttrain #8160 lr = 4.42e-05 loss = 0.033852 train = 0.987891 valid = 0.817019\n",
            "2022-01-08 04:17:05 - INFO:\ttrain #8180 lr = 4.41e-05 loss = 0.034414 train = 0.987793 valid = 0.818643\n",
            "2022-01-08 04:17:36 - INFO:\ttrain #8200 lr = 4.40e-05 loss = 0.033277 train = 0.989258 valid = 0.816816\n",
            "2022-01-08 04:17:38 - INFO:\tSaved test = 0.800243\n",
            "2022-01-08 04:18:09 - INFO:\ttrain #8220 lr = 4.40e-05 loss = 0.037563 train = 0.987012 valid = 0.806052\n",
            "2022-01-08 04:18:40 - INFO:\ttrain #8240 lr = 4.39e-05 loss = 0.041586 train = 0.986816 valid = 0.810723\n",
            "2022-01-08 04:19:11 - INFO:\ttrain #8260 lr = 4.38e-05 loss = 0.037501 train = 0.987598 valid = 0.812145\n",
            "2022-01-08 04:19:42 - INFO:\ttrain #8280 lr = 4.37e-05 loss = 0.033536 train = 0.988379 valid = 0.822299\n",
            "2022-01-08 04:20:13 - INFO:\ttrain #8300 lr = 4.36e-05 loss = 0.028923 train = 0.990430 valid = 0.824939\n",
            "2022-01-08 04:20:16 - INFO:\tSaved test = 0.810778\n",
            "2022-01-08 04:20:47 - INFO:\ttrain #8320 lr = 4.35e-05 loss = 0.029584 train = 0.989746 valid = 0.824736\n",
            "2022-01-08 04:21:18 - INFO:\ttrain #8340 lr = 4.34e-05 loss = 0.034501 train = 0.987402 valid = 0.819659\n",
            "2022-01-08 04:21:50 - INFO:\ttrain #8360 lr = 4.33e-05 loss = 0.033213 train = 0.989551 valid = 0.823721\n",
            "2022-01-08 04:22:21 - INFO:\ttrain #8380 lr = 4.33e-05 loss = 0.032876 train = 0.988477 valid = 0.823924\n",
            "2022-01-08 04:22:52 - INFO:\ttrain #8400 lr = 4.32e-05 loss = 0.033606 train = 0.987695 valid = 0.808489\n",
            "2022-01-08 04:22:54 - INFO:\tSaved test = 0.807536\n",
            "2022-01-08 04:23:25 - INFO:\ttrain #8420 lr = 4.31e-05 loss = 0.033226 train = 0.988574 valid = 0.819659\n",
            "2022-01-08 04:23:57 - INFO:\ttrain #8440 lr = 4.30e-05 loss = 0.030907 train = 0.988281 valid = 0.820065\n",
            "2022-01-08 04:24:28 - INFO:\ttrain #8460 lr = 4.29e-05 loss = 0.028628 train = 0.991211 valid = 0.825955 updated\n",
            "2022-01-08 04:24:59 - INFO:\ttrain #8480 lr = 4.28e-05 loss = 0.031448 train = 0.988965 valid = 0.820877\n",
            "2022-01-08 04:25:30 - INFO:\ttrain #8500 lr = 4.27e-05 loss = 0.031845 train = 0.988770 valid = 0.815191\n",
            "2022-01-08 04:25:33 - INFO:\tSaved test = 0.803890\n",
            "2022-01-08 04:26:04 - INFO:\ttrain #8520 lr = 4.27e-05 loss = 0.033638 train = 0.988086 valid = 0.813160\n",
            "2022-01-08 04:26:35 - INFO:\ttrain #8540 lr = 4.26e-05 loss = 0.031895 train = 0.988965 valid = 0.808895\n",
            "2022-01-08 04:27:06 - INFO:\ttrain #8560 lr = 4.25e-05 loss = 0.028918 train = 0.990332 valid = 0.813972\n",
            "2022-01-08 04:27:37 - INFO:\ttrain #8580 lr = 4.24e-05 loss = 0.038482 train = 0.986621 valid = 0.817831\n",
            "2022-01-08 04:28:08 - INFO:\ttrain #8600 lr = 4.23e-05 loss = 0.031258 train = 0.990234 valid = 0.822299\n",
            "2022-01-08 04:28:10 - INFO:\tSaved test = 0.812399\n",
            "2022-01-08 04:28:42 - INFO:\ttrain #8620 lr = 4.22e-05 loss = 0.036239 train = 0.987695 valid = 0.819862\n",
            "2022-01-08 04:29:13 - INFO:\ttrain #8640 lr = 4.21e-05 loss = 0.028175 train = 0.990625 valid = 0.818237\n",
            "2022-01-08 04:29:44 - INFO:\ttrain #8660 lr = 4.21e-05 loss = 0.032765 train = 0.988086 valid = 0.816613\n",
            "2022-01-08 04:30:15 - INFO:\ttrain #8680 lr = 4.20e-05 loss = 0.030572 train = 0.989648 valid = 0.812551\n",
            "2022-01-08 04:30:46 - INFO:\ttrain #8700 lr = 4.19e-05 loss = 0.039901 train = 0.987207 valid = 0.810520\n",
            "2022-01-08 04:30:49 - INFO:\tSaved test = 0.805916\n",
            "2022-01-08 04:31:20 - INFO:\ttrain #8720 lr = 4.18e-05 loss = 0.037636 train = 0.987500 valid = 0.810317\n",
            "2022-01-08 04:31:51 - INFO:\ttrain #8740 lr = 4.17e-05 loss = 0.028891 train = 0.990527 valid = 0.820877\n",
            "2022-01-08 04:32:22 - INFO:\ttrain #8760 lr = 4.16e-05 loss = 0.028404 train = 0.991113 valid = 0.813972\n",
            "2022-01-08 04:32:53 - INFO:\ttrain #8780 lr = 4.16e-05 loss = 0.029177 train = 0.989941 valid = 0.818440\n",
            "2022-01-08 04:33:24 - INFO:\ttrain #8800 lr = 4.15e-05 loss = 0.030158 train = 0.989648 valid = 0.818846\n",
            "2022-01-08 04:33:27 - INFO:\tSaved test = 0.806726\n",
            "2022-01-08 04:33:58 - INFO:\ttrain #8820 lr = 4.14e-05 loss = 0.029492 train = 0.989844 valid = 0.813160\n",
            "2022-01-08 04:34:29 - INFO:\ttrain #8840 lr = 4.13e-05 loss = 0.029120 train = 0.990137 valid = 0.808286\n",
            "2022-01-08 04:35:00 - INFO:\ttrain #8860 lr = 4.12e-05 loss = 0.025629 train = 0.991504 valid = 0.809504\n",
            "2022-01-08 04:35:31 - INFO:\ttrain #8880 lr = 4.11e-05 loss = 0.035204 train = 0.987988 valid = 0.815800\n",
            "2022-01-08 04:36:02 - INFO:\ttrain #8900 lr = 4.11e-05 loss = 0.031428 train = 0.989551 valid = 0.816206\n",
            "2022-01-08 04:36:05 - INFO:\tSaved test = 0.811588\n",
            "2022-01-08 04:36:36 - INFO:\ttrain #8920 lr = 4.10e-05 loss = 0.027587 train = 0.990527 valid = 0.821487\n",
            "2022-01-08 04:37:07 - INFO:\ttrain #8940 lr = 4.09e-05 loss = 0.026035 train = 0.991211 valid = 0.814785\n",
            "2022-01-08 04:37:38 - INFO:\ttrain #8960 lr = 4.08e-05 loss = 0.028994 train = 0.990332 valid = 0.819253\n",
            "2022-01-08 04:38:09 - INFO:\ttrain #8980 lr = 4.07e-05 loss = 0.031986 train = 0.988086 valid = 0.816816\n",
            "2022-01-08 04:38:41 - INFO:\ttrain #9000 lr = 4.07e-05 loss = 0.027481 train = 0.990234 valid = 0.823517\n",
            "2022-01-08 04:38:43 - INFO:\tSaved test = 0.811588\n",
            "2022-01-08 04:39:14 - INFO:\ttrain #9020 lr = 4.06e-05 loss = 0.025866 train = 0.991406 valid = 0.814175\n",
            "2022-01-08 04:39:45 - INFO:\ttrain #9040 lr = 4.05e-05 loss = 0.026024 train = 0.991016 valid = 0.812551\n",
            "2022-01-08 04:40:16 - INFO:\ttrain #9060 lr = 4.04e-05 loss = 0.028922 train = 0.990430 valid = 0.819862\n",
            "2022-01-08 04:40:48 - INFO:\ttrain #9080 lr = 4.03e-05 loss = 0.027338 train = 0.991602 valid = 0.816003\n",
            "2022-01-08 04:41:19 - INFO:\ttrain #9100 lr = 4.03e-05 loss = 0.030293 train = 0.989844 valid = 0.821284\n",
            "2022-01-08 04:41:21 - INFO:\tSaved test = 0.806726\n",
            "2022-01-08 04:41:52 - INFO:\ttrain #9120 lr = 4.02e-05 loss = 0.021912 train = 0.992480 valid = 0.821284\n",
            "2022-01-08 04:42:24 - INFO:\ttrain #9140 lr = 4.01e-05 loss = 0.029081 train = 0.989355 valid = 0.813160\n",
            "2022-01-08 04:42:55 - INFO:\ttrain #9160 lr = 4.00e-05 loss = 0.033706 train = 0.988184 valid = 0.820065\n",
            "2022-01-08 04:43:26 - INFO:\ttrain #9180 lr = 3.99e-05 loss = 0.031448 train = 0.989941 valid = 0.812145\n",
            "2022-01-08 04:43:57 - INFO:\ttrain #9200 lr = 3.99e-05 loss = 0.029426 train = 0.990527 valid = 0.825142\n",
            "2022-01-08 04:44:00 - INFO:\tSaved test = 0.807942\n",
            "2022-01-08 04:44:31 - INFO:\ttrain #9220 lr = 3.98e-05 loss = 0.025488 train = 0.990430 valid = 0.820877\n",
            "2022-01-08 04:45:02 - INFO:\ttrain #9240 lr = 3.97e-05 loss = 0.026187 train = 0.992090 valid = 0.821893\n",
            "2022-01-08 04:45:33 - INFO:\ttrain #9260 lr = 3.96e-05 loss = 0.028557 train = 0.990625 valid = 0.815800\n",
            "2022-01-08 04:46:04 - INFO:\ttrain #9280 lr = 3.95e-05 loss = 0.026772 train = 0.990430 valid = 0.820471\n",
            "2022-01-08 04:46:36 - INFO:\ttrain #9300 lr = 3.95e-05 loss = 0.028077 train = 0.990332 valid = 0.819862\n",
            "2022-01-08 04:46:38 - INFO:\tSaved test = 0.805916\n",
            "2022-01-08 04:47:09 - INFO:\ttrain #9320 lr = 3.94e-05 loss = 0.028421 train = 0.989551 valid = 0.823314\n",
            "2022-01-08 04:47:39 - INFO:\ttrain #9340 lr = 3.93e-05 loss = 0.025071 train = 0.992285 valid = 0.824736\n",
            "2022-01-08 04:48:11 - INFO:\ttrain #9360 lr = 3.92e-05 loss = 0.030575 train = 0.991602 valid = 0.818440\n",
            "2022-01-08 04:48:42 - INFO:\ttrain #9380 lr = 3.91e-05 loss = 0.028183 train = 0.990430 valid = 0.822502\n",
            "2022-01-08 04:49:13 - INFO:\ttrain #9400 lr = 3.91e-05 loss = 0.024122 train = 0.991309 valid = 0.823721\n",
            "2022-01-08 04:49:15 - INFO:\tSaved test = 0.811994\n",
            "2022-01-08 04:49:46 - INFO:\ttrain #9420 lr = 3.90e-05 loss = 0.024335 train = 0.991699 valid = 0.815394\n",
            "2022-01-08 04:50:18 - INFO:\ttrain #9440 lr = 3.89e-05 loss = 0.031273 train = 0.988770 valid = 0.815191\n",
            "2022-01-08 04:50:49 - INFO:\ttrain #9460 lr = 3.88e-05 loss = 0.025816 train = 0.991699 valid = 0.814988\n",
            "2022-01-08 04:51:20 - INFO:\ttrain #9480 lr = 3.87e-05 loss = 0.029796 train = 0.989160 valid = 0.822299\n",
            "2022-01-08 04:51:50 - INFO:\ttrain #9500 lr = 3.87e-05 loss = 0.024703 train = 0.992773 valid = 0.817628\n",
            "2022-01-08 04:51:52 - INFO:\tSaved test = 0.801459\n",
            "2022-01-08 04:52:23 - INFO:\ttrain #9520 lr = 3.86e-05 loss = 0.025499 train = 0.992188 valid = 0.817222\n",
            "2022-01-08 04:52:55 - INFO:\ttrain #9540 lr = 3.85e-05 loss = 0.022920 train = 0.992871 valid = 0.819050\n",
            "2022-01-08 04:53:26 - INFO:\ttrain #9560 lr = 3.84e-05 loss = 0.025827 train = 0.991406 valid = 0.815800\n",
            "2022-01-08 04:53:57 - INFO:\ttrain #9580 lr = 3.84e-05 loss = 0.024752 train = 0.991797 valid = 0.819456\n",
            "2022-01-08 04:54:28 - INFO:\ttrain #9600 lr = 3.83e-05 loss = 0.028077 train = 0.990625 valid = 0.814988\n",
            "2022-01-08 04:54:30 - INFO:\tSaved test = 0.797407\n",
            "2022-01-08 04:55:01 - INFO:\ttrain #9620 lr = 3.82e-05 loss = 0.021238 train = 0.994824 valid = 0.817831\n",
            "2022-01-08 04:55:32 - INFO:\ttrain #9640 lr = 3.81e-05 loss = 0.029028 train = 0.990625 valid = 0.819050\n",
            "2022-01-08 04:56:03 - INFO:\ttrain #9660 lr = 3.81e-05 loss = 0.026493 train = 0.989941 valid = 0.821080\n",
            "2022-01-08 04:56:34 - INFO:\ttrain #9680 lr = 3.80e-05 loss = 0.022187 train = 0.992188 valid = 0.818034\n",
            "2022-01-08 04:57:06 - INFO:\ttrain #9700 lr = 3.79e-05 loss = 0.025556 train = 0.991113 valid = 0.819253\n",
            "2022-01-08 04:57:08 - INFO:\tSaved test = 0.808347\n",
            "2022-01-08 04:57:39 - INFO:\ttrain #9720 lr = 3.78e-05 loss = 0.030779 train = 0.989258 valid = 0.823314\n",
            "2022-01-08 04:58:10 - INFO:\ttrain #9740 lr = 3.78e-05 loss = 0.024032 train = 0.992480 valid = 0.819862\n",
            "2022-01-08 04:58:41 - INFO:\ttrain #9760 lr = 3.77e-05 loss = 0.024062 train = 0.991699 valid = 0.822705\n",
            "2022-01-08 04:59:12 - INFO:\ttrain #9780 lr = 3.76e-05 loss = 0.019603 train = 0.994434 valid = 0.825345\n",
            "2022-01-08 04:59:44 - INFO:\ttrain #9800 lr = 3.75e-05 loss = 0.029711 train = 0.989551 valid = 0.819050\n",
            "2022-01-08 04:59:46 - INFO:\tSaved test = 0.803890\n",
            "2022-01-08 05:00:17 - INFO:\ttrain #9820 lr = 3.75e-05 loss = 0.027063 train = 0.990820 valid = 0.820471\n",
            "2022-01-08 05:00:48 - INFO:\ttrain #9840 lr = 3.74e-05 loss = 0.023219 train = 0.992969 valid = 0.821690\n",
            "2022-01-08 05:01:19 - INFO:\ttrain #9860 lr = 3.73e-05 loss = 0.020394 train = 0.993555 valid = 0.819659\n",
            "2022-01-08 05:01:50 - INFO:\ttrain #9880 lr = 3.72e-05 loss = 0.024272 train = 0.991504 valid = 0.821080\n",
            "2022-01-08 05:02:21 - INFO:\ttrain #9900 lr = 3.72e-05 loss = 0.022610 train = 0.992188 valid = 0.822908\n",
            "2022-01-08 05:02:23 - INFO:\tSaved test = 0.815640\n",
            "2022-01-08 05:02:54 - INFO:\ttrain #9920 lr = 3.71e-05 loss = 0.024447 train = 0.991992 valid = 0.816613\n",
            "2022-01-08 05:03:25 - INFO:\ttrain #9940 lr = 3.70e-05 loss = 0.020974 train = 0.992773 valid = 0.825955\n",
            "2022-01-08 05:03:56 - INFO:\ttrain #9960 lr = 3.69e-05 loss = 0.020104 train = 0.993652 valid = 0.825955\n",
            "2022-01-08 05:04:27 - INFO:\ttrain #9980 lr = 3.69e-05 loss = 0.022590 train = 0.991602 valid = 0.825548\n",
            "2022-01-08 05:04:58 - INFO:\ttrain #10000 lr = 3.68e-05 loss = 0.021007 train = 0.992578 valid = 0.823517\n",
            "2022-01-08 05:05:01 - INFO:\tSaved test = 0.805916\n",
            "2022-01-08 05:05:32 - INFO:\ttrain #10020 lr = 3.67e-05 loss = 0.022915 train = 0.992090 valid = 0.827985 updated\n",
            "2022-01-08 05:06:03 - INFO:\ttrain #10040 lr = 3.66e-05 loss = 0.019946 train = 0.993945 valid = 0.820268\n",
            "2022-01-08 05:06:34 - INFO:\ttrain #10060 lr = 3.66e-05 loss = 0.030055 train = 0.989160 valid = 0.820877\n",
            "2022-01-08 05:07:05 - INFO:\ttrain #10080 lr = 3.65e-05 loss = 0.025311 train = 0.991211 valid = 0.823111\n",
            "2022-01-08 05:07:36 - INFO:\ttrain #10100 lr = 3.64e-05 loss = 0.021144 train = 0.992480 valid = 0.822299\n",
            "2022-01-08 05:07:39 - INFO:\tSaved test = 0.816451\n",
            "2022-01-08 05:08:10 - INFO:\ttrain #10120 lr = 3.63e-05 loss = 0.023175 train = 0.991895 valid = 0.822705\n",
            "2022-01-08 05:08:41 - INFO:\ttrain #10140 lr = 3.63e-05 loss = 0.024130 train = 0.991797 valid = 0.828798 updated\n",
            "2022-01-08 05:09:12 - INFO:\ttrain #10160 lr = 3.62e-05 loss = 0.018746 train = 0.993945 valid = 0.821080\n",
            "2022-01-08 05:09:43 - INFO:\ttrain #10180 lr = 3.61e-05 loss = 0.018545 train = 0.993359 valid = 0.826970\n",
            "2022-01-08 05:10:15 - INFO:\ttrain #10200 lr = 3.61e-05 loss = 0.021378 train = 0.992773 valid = 0.819862\n",
            "2022-01-08 05:10:17 - INFO:\tSaved test = 0.811994\n",
            "2022-01-08 05:10:48 - INFO:\ttrain #10220 lr = 3.60e-05 loss = 0.014740 train = 0.995117 valid = 0.827579\n",
            "2022-01-08 05:11:19 - INFO:\ttrain #10240 lr = 3.59e-05 loss = 0.020453 train = 0.992480 valid = 0.814988\n",
            "2022-01-08 05:11:51 - INFO:\ttrain #10260 lr = 3.58e-05 loss = 0.023607 train = 0.991699 valid = 0.817425\n",
            "2022-01-08 05:12:22 - INFO:\ttrain #10280 lr = 3.58e-05 loss = 0.018320 train = 0.993457 valid = 0.824533\n",
            "2022-01-08 05:12:53 - INFO:\ttrain #10300 lr = 3.57e-05 loss = 0.017889 train = 0.994141 valid = 0.820674\n",
            "2022-01-08 05:12:55 - INFO:\tSaved test = 0.809562\n",
            "2022-01-08 05:13:26 - INFO:\ttrain #10320 lr = 3.56e-05 loss = 0.022356 train = 0.992871 valid = 0.827376\n",
            "2022-01-08 05:13:58 - INFO:\ttrain #10340 lr = 3.56e-05 loss = 0.025898 train = 0.991602 valid = 0.816409\n",
            "2022-01-08 05:14:29 - INFO:\ttrain #10360 lr = 3.55e-05 loss = 0.019213 train = 0.993262 valid = 0.817831\n",
            "2022-01-08 05:15:00 - INFO:\ttrain #10380 lr = 3.54e-05 loss = 0.022104 train = 0.992773 valid = 0.826158\n",
            "2022-01-08 05:15:31 - INFO:\ttrain #10400 lr = 3.53e-05 loss = 0.016319 train = 0.995020 valid = 0.819862\n",
            "2022-01-08 05:15:33 - INFO:\tSaved test = 0.807942\n",
            "2022-01-08 05:16:05 - INFO:\ttrain #10420 lr = 3.53e-05 loss = 0.021228 train = 0.992480 valid = 0.813769\n",
            "2022-01-08 05:16:36 - INFO:\ttrain #10440 lr = 3.52e-05 loss = 0.022365 train = 0.992773 valid = 0.815394\n",
            "2022-01-08 05:17:07 - INFO:\ttrain #10460 lr = 3.51e-05 loss = 0.020506 train = 0.993164 valid = 0.821284\n",
            "2022-01-08 05:17:38 - INFO:\ttrain #10480 lr = 3.51e-05 loss = 0.022347 train = 0.992383 valid = 0.820674\n",
            "2022-01-08 05:18:10 - INFO:\ttrain #10500 lr = 3.50e-05 loss = 0.022618 train = 0.992676 valid = 0.820471\n",
            "2022-01-08 05:18:12 - INFO:\tSaved test = 0.809562\n",
            "2022-01-08 05:18:43 - INFO:\ttrain #10520 lr = 3.49e-05 loss = 0.017697 train = 0.993945 valid = 0.812754\n",
            "2022-01-08 05:19:14 - INFO:\ttrain #10540 lr = 3.49e-05 loss = 0.024338 train = 0.992188 valid = 0.821284\n",
            "2022-01-08 05:19:46 - INFO:\ttrain #10560 lr = 3.48e-05 loss = 0.025535 train = 0.991992 valid = 0.820065\n",
            "2022-01-08 05:20:17 - INFO:\ttrain #10580 lr = 3.47e-05 loss = 0.022014 train = 0.992188 valid = 0.821487\n",
            "2022-01-08 05:20:48 - INFO:\ttrain #10600 lr = 3.46e-05 loss = 0.021341 train = 0.991895 valid = 0.820471\n",
            "2022-01-08 05:20:50 - INFO:\tSaved test = 0.805916\n",
            "2022-01-08 05:21:22 - INFO:\ttrain #10620 lr = 3.46e-05 loss = 0.018738 train = 0.993652 valid = 0.822502\n",
            "2022-01-08 05:21:52 - INFO:\ttrain #10640 lr = 3.45e-05 loss = 0.019284 train = 0.994238 valid = 0.824330\n",
            "2022-01-08 05:22:24 - INFO:\ttrain #10660 lr = 3.44e-05 loss = 0.019511 train = 0.993848 valid = 0.819050\n",
            "2022-01-08 05:22:55 - INFO:\ttrain #10680 lr = 3.44e-05 loss = 0.021124 train = 0.993457 valid = 0.817425\n",
            "2022-01-08 05:23:26 - INFO:\ttrain #10700 lr = 3.43e-05 loss = 0.018910 train = 0.994043 valid = 0.824127\n",
            "2022-01-08 05:23:28 - INFO:\tSaved test = 0.808752\n",
            "2022-01-08 05:24:00 - INFO:\ttrain #10720 lr = 3.42e-05 loss = 0.020979 train = 0.993750 valid = 0.819659\n",
            "2022-01-08 05:24:31 - INFO:\ttrain #10740 lr = 3.42e-05 loss = 0.020671 train = 0.993750 valid = 0.819050\n",
            "2022-01-08 05:25:02 - INFO:\ttrain #10760 lr = 3.41e-05 loss = 0.019286 train = 0.994141 valid = 0.820268\n",
            "2022-01-08 05:25:33 - INFO:\ttrain #10780 lr = 3.40e-05 loss = 0.017621 train = 0.994531 valid = 0.817628\n",
            "2022-01-08 05:26:04 - INFO:\ttrain #10800 lr = 3.40e-05 loss = 0.022390 train = 0.993066 valid = 0.819862\n",
            "2022-01-08 05:26:07 - INFO:\tSaved test = 0.809562\n",
            "2022-01-08 05:26:38 - INFO:\ttrain #10820 lr = 3.39e-05 loss = 0.017184 train = 0.993750 valid = 0.827985\n",
            "2022-01-08 05:27:09 - INFO:\ttrain #10840 lr = 3.38e-05 loss = 0.023267 train = 0.991797 valid = 0.820674\n",
            "2022-01-08 05:27:40 - INFO:\ttrain #10860 lr = 3.38e-05 loss = 0.014636 train = 0.994922 valid = 0.823924\n",
            "2022-01-08 05:28:11 - INFO:\ttrain #10880 lr = 3.37e-05 loss = 0.016506 train = 0.994141 valid = 0.824330\n",
            "2022-01-08 05:28:42 - INFO:\ttrain #10900 lr = 3.36e-05 loss = 0.017094 train = 0.994336 valid = 0.823517\n",
            "2022-01-08 05:28:45 - INFO:\tSaved test = 0.809157\n",
            "2022-01-08 05:29:16 - INFO:\ttrain #10920 lr = 3.36e-05 loss = 0.020165 train = 0.993945 valid = 0.822908\n",
            "2022-01-08 05:29:47 - INFO:\ttrain #10940 lr = 3.35e-05 loss = 0.019442 train = 0.993750 valid = 0.829001 updated\n",
            "2022-01-08 05:30:18 - INFO:\ttrain #10960 lr = 3.34e-05 loss = 0.021131 train = 0.992676 valid = 0.826970\n",
            "2022-01-08 05:30:50 - INFO:\ttrain #10980 lr = 3.34e-05 loss = 0.020616 train = 0.994043 valid = 0.823924\n",
            "2022-01-08 05:31:20 - INFO:\ttrain #11000 lr = 3.33e-05 loss = 0.015150 train = 0.995410 valid = 0.824939\n",
            "2022-01-08 05:31:23 - INFO:\tSaved test = 0.802269\n",
            "2022-01-08 05:31:54 - INFO:\ttrain #11020 lr = 3.32e-05 loss = 0.012406 train = 0.996582 valid = 0.820268\n",
            "2022-01-08 05:32:25 - INFO:\ttrain #11040 lr = 3.32e-05 loss = 0.016657 train = 0.994043 valid = 0.824736\n",
            "2022-01-08 05:32:56 - INFO:\ttrain #11060 lr = 3.31e-05 loss = 0.017127 train = 0.994824 valid = 0.820674\n",
            "2022-01-08 05:33:28 - INFO:\ttrain #11080 lr = 3.30e-05 loss = 0.017529 train = 0.993945 valid = 0.818440\n",
            "2022-01-08 05:33:59 - INFO:\ttrain #11100 lr = 3.30e-05 loss = 0.019892 train = 0.993359 valid = 0.825751\n",
            "2022-01-08 05:34:01 - INFO:\tSaved test = 0.802269\n",
            "2022-01-08 05:34:32 - INFO:\ttrain #11120 lr = 3.29e-05 loss = 0.018170 train = 0.994336 valid = 0.820674\n",
            "2022-01-08 05:35:03 - INFO:\ttrain #11140 lr = 3.28e-05 loss = 0.016180 train = 0.993945 valid = 0.820065\n",
            "2022-01-08 05:35:35 - INFO:\ttrain #11160 lr = 3.28e-05 loss = 0.014123 train = 0.995117 valid = 0.822705\n",
            "2022-01-08 05:36:06 - INFO:\ttrain #11180 lr = 3.27e-05 loss = 0.017405 train = 0.994629 valid = 0.819456\n",
            "2022-01-08 05:36:37 - INFO:\ttrain #11200 lr = 3.26e-05 loss = 0.014177 train = 0.995605 valid = 0.818237\n",
            "2022-01-08 05:36:39 - INFO:\tSaved test = 0.806321\n",
            "2022-01-08 05:37:11 - INFO:\ttrain #11220 lr = 3.26e-05 loss = 0.016051 train = 0.994336 valid = 0.813972\n",
            "2022-01-08 05:37:42 - INFO:\ttrain #11240 lr = 3.25e-05 loss = 0.017508 train = 0.994922 valid = 0.825548\n",
            "2022-01-08 05:38:13 - INFO:\ttrain #11260 lr = 3.24e-05 loss = 0.013420 train = 0.995410 valid = 0.823924\n",
            "2022-01-08 05:38:44 - INFO:\ttrain #11280 lr = 3.24e-05 loss = 0.014049 train = 0.995898 valid = 0.820674\n",
            "2022-01-08 05:39:15 - INFO:\ttrain #11300 lr = 3.23e-05 loss = 0.015701 train = 0.995313 valid = 0.817831\n",
            "2022-01-08 05:39:17 - INFO:\tSaved test = 0.797812\n",
            "2022-01-08 05:39:49 - INFO:\ttrain #11320 lr = 3.22e-05 loss = 0.024468 train = 0.992090 valid = 0.827579\n",
            "2022-01-08 05:40:20 - INFO:\ttrain #11340 lr = 3.22e-05 loss = 0.017135 train = 0.994727 valid = 0.826361\n",
            "2022-01-08 05:40:51 - INFO:\ttrain #11360 lr = 3.21e-05 loss = 0.018513 train = 0.993652 valid = 0.823924\n",
            "2022-01-08 05:41:22 - INFO:\ttrain #11380 lr = 3.20e-05 loss = 0.016380 train = 0.994238 valid = 0.827985\n",
            "2022-01-08 05:41:53 - INFO:\ttrain #11400 lr = 3.20e-05 loss = 0.021603 train = 0.992285 valid = 0.821487\n",
            "2022-01-08 05:41:56 - INFO:\tSaved test = 0.799433\n",
            "2022-01-08 05:42:27 - INFO:\ttrain #11420 lr = 3.19e-05 loss = 0.017768 train = 0.993848 valid = 0.826970\n",
            "2022-01-08 05:42:58 - INFO:\ttrain #11440 lr = 3.19e-05 loss = 0.016350 train = 0.994531 valid = 0.821080\n",
            "2022-01-08 05:43:29 - INFO:\ttrain #11460 lr = 3.18e-05 loss = 0.016493 train = 0.994727 valid = 0.818846\n",
            "2022-01-08 05:44:00 - INFO:\ttrain #11480 lr = 3.17e-05 loss = 0.012545 train = 0.996387 valid = 0.825548\n",
            "2022-01-08 05:44:32 - INFO:\ttrain #11500 lr = 3.17e-05 loss = 0.012540 train = 0.995801 valid = 0.824127\n",
            "2022-01-08 05:44:34 - INFO:\tSaved test = 0.816451\n",
            "2022-01-08 05:45:05 - INFO:\ttrain #11520 lr = 3.16e-05 loss = 0.015969 train = 0.994922 valid = 0.817831\n",
            "2022-01-08 05:45:36 - INFO:\ttrain #11540 lr = 3.15e-05 loss = 0.015305 train = 0.995117 valid = 0.819659\n",
            "2022-01-08 05:46:08 - INFO:\ttrain #11560 lr = 3.15e-05 loss = 0.018481 train = 0.994434 valid = 0.818237\n",
            "2022-01-08 05:46:39 - INFO:\ttrain #11580 lr = 3.14e-05 loss = 0.011407 train = 0.996094 valid = 0.821690\n",
            "2022-01-08 05:47:10 - INFO:\ttrain #11600 lr = 3.13e-05 loss = 0.015889 train = 0.995215 valid = 0.825751\n",
            "2022-01-08 05:47:12 - INFO:\tSaved test = 0.816856\n",
            "2022-01-08 05:47:43 - INFO:\ttrain #11620 lr = 3.13e-05 loss = 0.015813 train = 0.994824 valid = 0.823111\n",
            "2022-01-08 05:48:14 - INFO:\ttrain #11640 lr = 3.12e-05 loss = 0.017362 train = 0.994238 valid = 0.814379\n",
            "2022-01-08 05:48:45 - INFO:\ttrain #11660 lr = 3.12e-05 loss = 0.016462 train = 0.994824 valid = 0.823924\n",
            "2022-01-08 05:49:16 - INFO:\ttrain #11680 lr = 3.11e-05 loss = 0.014399 train = 0.995508 valid = 0.828392\n",
            "2022-01-08 05:49:48 - INFO:\ttrain #11700 lr = 3.10e-05 loss = 0.015322 train = 0.994922 valid = 0.819253\n",
            "2022-01-08 05:49:50 - INFO:\tSaved test = 0.808347\n",
            "2022-01-08 05:50:21 - INFO:\ttrain #11720 lr = 3.10e-05 loss = 0.014164 train = 0.995313 valid = 0.825751\n",
            "2022-01-08 05:50:52 - INFO:\ttrain #11740 lr = 3.09e-05 loss = 0.015034 train = 0.994727 valid = 0.820268\n",
            "2022-01-08 05:51:23 - INFO:\ttrain #11760 lr = 3.08e-05 loss = 0.015509 train = 0.995508 valid = 0.818440\n",
            "2022-01-08 05:51:54 - INFO:\ttrain #11780 lr = 3.08e-05 loss = 0.015203 train = 0.994434 valid = 0.821893\n",
            "2022-01-08 05:52:25 - INFO:\ttrain #11800 lr = 3.07e-05 loss = 0.011470 train = 0.996387 valid = 0.824533\n",
            "2022-01-08 05:52:28 - INFO:\tSaved test = 0.815640\n",
            "2022-01-08 05:52:59 - INFO:\ttrain #11820 lr = 3.07e-05 loss = 0.017401 train = 0.994043 valid = 0.816816\n",
            "2022-01-08 05:53:30 - INFO:\ttrain #11840 lr = 3.06e-05 loss = 0.018403 train = 0.993359 valid = 0.814785\n",
            "2022-01-08 05:54:01 - INFO:\ttrain #11860 lr = 3.05e-05 loss = 0.021161 train = 0.992773 valid = 0.814379\n",
            "2022-01-08 05:54:32 - INFO:\ttrain #11880 lr = 3.05e-05 loss = 0.016205 train = 0.994727 valid = 0.821893\n",
            "2022-01-08 05:55:04 - INFO:\ttrain #11900 lr = 3.04e-05 loss = 0.019661 train = 0.993652 valid = 0.825142\n",
            "2022-01-08 05:55:06 - INFO:\tSaved test = 0.811588\n",
            "2022-01-08 05:55:37 - INFO:\ttrain #11920 lr = 3.04e-05 loss = 0.014103 train = 0.995508 valid = 0.821893\n",
            "2022-01-08 05:56:08 - INFO:\ttrain #11940 lr = 3.03e-05 loss = 0.014432 train = 0.995801 valid = 0.824127\n",
            "2022-01-08 05:56:39 - INFO:\ttrain #11960 lr = 3.02e-05 loss = 0.013808 train = 0.996289 valid = 0.824939\n",
            "2022-01-08 05:57:10 - INFO:\ttrain #11980 lr = 3.02e-05 loss = 0.013612 train = 0.995117 valid = 0.823721\n",
            "2022-01-08 05:57:42 - INFO:\ttrain #12000 lr = 3.01e-05 loss = 0.009251 train = 0.997461 valid = 0.824330\n",
            "2022-01-08 05:57:44 - INFO:\tSaved test = 0.815235\n",
            "2022-01-08 05:58:15 - INFO:\ttrain #12020 lr = 3.01e-05 loss = 0.014400 train = 0.995410 valid = 0.824127\n",
            "2022-01-08 05:58:46 - INFO:\ttrain #12040 lr = 3.00e-05 loss = 0.012721 train = 0.995996 valid = 0.825548\n",
            "2022-01-08 05:59:17 - INFO:\ttrain #12060 lr = 2.99e-05 loss = 0.012209 train = 0.995898 valid = 0.817831\n",
            "2022-01-08 05:59:48 - INFO:\ttrain #12080 lr = 2.99e-05 loss = 0.013231 train = 0.995996 valid = 0.815597\n",
            "2022-01-08 06:00:19 - INFO:\ttrain #12100 lr = 2.98e-05 loss = 0.016056 train = 0.993457 valid = 0.822502\n",
            "2022-01-08 06:00:22 - INFO:\tSaved test = 0.804700\n",
            "2022-01-08 06:00:53 - INFO:\ttrain #12120 lr = 2.98e-05 loss = 0.015504 train = 0.994922 valid = 0.819253\n",
            "2022-01-08 06:01:24 - INFO:\ttrain #12140 lr = 2.97e-05 loss = 0.012909 train = 0.994824 valid = 0.822908\n",
            "2022-01-08 06:01:55 - INFO:\ttrain #12160 lr = 2.96e-05 loss = 0.011573 train = 0.995996 valid = 0.825345\n",
            "2022-01-08 06:02:26 - INFO:\ttrain #12180 lr = 2.96e-05 loss = 0.014424 train = 0.994727 valid = 0.821690\n",
            "2022-01-08 06:02:57 - INFO:\ttrain #12200 lr = 2.95e-05 loss = 0.011522 train = 0.996875 valid = 0.824127\n",
            "2022-01-08 06:03:00 - INFO:\tSaved test = 0.817261\n",
            "2022-01-08 06:03:31 - INFO:\ttrain #12220 lr = 2.95e-05 loss = 0.010470 train = 0.996680 valid = 0.826361\n",
            "2022-01-08 06:04:02 - INFO:\ttrain #12240 lr = 2.94e-05 loss = 0.015879 train = 0.994922 valid = 0.829610 updated\n",
            "2022-01-08 06:04:33 - INFO:\ttrain #12260 lr = 2.93e-05 loss = 0.014946 train = 0.994922 valid = 0.818034\n",
            "2022-01-08 06:05:05 - INFO:\ttrain #12280 lr = 2.93e-05 loss = 0.012104 train = 0.996582 valid = 0.825751\n",
            "2022-01-08 06:05:36 - INFO:\ttrain #12300 lr = 2.92e-05 loss = 0.012199 train = 0.995996 valid = 0.822705\n",
            "2022-01-08 06:05:38 - INFO:\tSaved test = 0.800243\n",
            "2022-01-08 06:06:09 - INFO:\ttrain #12320 lr = 2.92e-05 loss = 0.011673 train = 0.996289 valid = 0.818846\n",
            "2022-01-08 06:06:41 - INFO:\ttrain #12340 lr = 2.91e-05 loss = 0.015858 train = 0.994727 valid = 0.821690\n",
            "2022-01-08 06:07:12 - INFO:\ttrain #12360 lr = 2.91e-05 loss = 0.014571 train = 0.995117 valid = 0.820471\n",
            "2022-01-08 06:07:43 - INFO:\ttrain #12380 lr = 2.90e-05 loss = 0.017442 train = 0.994727 valid = 0.822908\n",
            "2022-01-08 06:08:14 - INFO:\ttrain #12400 lr = 2.89e-05 loss = 0.011183 train = 0.996680 valid = 0.822908\n",
            "2022-01-08 06:08:17 - INFO:\tSaved test = 0.814830\n",
            "2022-01-08 06:08:48 - INFO:\ttrain #12420 lr = 2.89e-05 loss = 0.012246 train = 0.995996 valid = 0.827579\n",
            "2022-01-08 06:09:19 - INFO:\ttrain #12440 lr = 2.88e-05 loss = 0.013404 train = 0.995996 valid = 0.829610\n",
            "2022-01-08 06:09:50 - INFO:\ttrain #12460 lr = 2.88e-05 loss = 0.011433 train = 0.996582 valid = 0.830829 updated\n",
            "2022-01-08 06:10:21 - INFO:\ttrain #12480 lr = 2.87e-05 loss = 0.014967 train = 0.994727 valid = 0.822096\n",
            "2022-01-08 06:10:52 - INFO:\ttrain #12500 lr = 2.86e-05 loss = 0.011162 train = 0.996973 valid = 0.826564\n",
            "2022-01-08 06:10:55 - INFO:\tSaved test = 0.809157\n",
            "2022-01-08 06:11:26 - INFO:\ttrain #12520 lr = 2.86e-05 loss = 0.014500 train = 0.995117 valid = 0.825751\n",
            "2022-01-08 06:11:56 - INFO:\ttrain #12540 lr = 2.85e-05 loss = 0.013542 train = 0.996289 valid = 0.823314\n",
            "2022-01-08 06:12:28 - INFO:\ttrain #12560 lr = 2.85e-05 loss = 0.013676 train = 0.995996 valid = 0.822096\n",
            "2022-01-08 06:12:59 - INFO:\ttrain #12580 lr = 2.84e-05 loss = 0.015258 train = 0.994727 valid = 0.823721\n",
            "2022-01-08 06:13:30 - INFO:\ttrain #12600 lr = 2.84e-05 loss = 0.012749 train = 0.995898 valid = 0.825345\n",
            "2022-01-08 06:13:32 - INFO:\tSaved test = 0.816045\n",
            "2022-01-08 06:14:03 - INFO:\ttrain #12620 lr = 2.83e-05 loss = 0.011547 train = 0.996582 valid = 0.823517\n",
            "2022-01-08 06:14:34 - INFO:\ttrain #12640 lr = 2.83e-05 loss = 0.011910 train = 0.996582 valid = 0.826158\n",
            "2022-01-08 06:15:05 - INFO:\ttrain #12660 lr = 2.82e-05 loss = 0.010024 train = 0.996191 valid = 0.828798\n",
            "2022-01-08 06:15:36 - INFO:\ttrain #12680 lr = 2.81e-05 loss = 0.010691 train = 0.996973 valid = 0.817222\n",
            "2022-01-08 06:16:07 - INFO:\ttrain #12700 lr = 2.81e-05 loss = 0.011461 train = 0.995410 valid = 0.822096\n",
            "2022-01-08 06:16:09 - INFO:\tSaved test = 0.805105\n",
            "2022-01-08 06:16:40 - INFO:\ttrain #12720 lr = 2.80e-05 loss = 0.008309 train = 0.997949 valid = 0.824736\n",
            "2022-01-08 06:17:12 - INFO:\ttrain #12740 lr = 2.80e-05 loss = 0.008892 train = 0.996973 valid = 0.823721\n",
            "2022-01-08 06:17:43 - INFO:\ttrain #12760 lr = 2.79e-05 loss = 0.009649 train = 0.997363 valid = 0.824736\n",
            "2022-01-08 06:18:14 - INFO:\ttrain #12780 lr = 2.79e-05 loss = 0.015783 train = 0.994141 valid = 0.830626\n",
            "2022-01-08 06:18:45 - INFO:\ttrain #12800 lr = 2.78e-05 loss = 0.013725 train = 0.995996 valid = 0.824939\n",
            "2022-01-08 06:18:47 - INFO:\tSaved test = 0.810373\n",
            "2022-01-08 06:19:18 - INFO:\ttrain #12820 lr = 2.77e-05 loss = 0.013182 train = 0.995605 valid = 0.825955\n",
            "2022-01-08 06:19:49 - INFO:\ttrain #12840 lr = 2.77e-05 loss = 0.011365 train = 0.996484 valid = 0.824533\n",
            "2022-01-08 06:20:21 - INFO:\ttrain #12860 lr = 2.76e-05 loss = 0.012287 train = 0.995898 valid = 0.821487\n",
            "2022-01-08 06:20:52 - INFO:\ttrain #12880 lr = 2.76e-05 loss = 0.010098 train = 0.996973 valid = 0.831235 updated\n",
            "2022-01-08 06:21:23 - INFO:\ttrain #12900 lr = 2.75e-05 loss = 0.013176 train = 0.995605 valid = 0.822705\n",
            "2022-01-08 06:21:25 - INFO:\tSaved test = 0.808752\n",
            "2022-01-08 06:21:56 - INFO:\ttrain #12920 lr = 2.75e-05 loss = 0.010372 train = 0.996777 valid = 0.829001\n",
            "2022-01-08 06:22:27 - INFO:\ttrain #12940 lr = 2.74e-05 loss = 0.012271 train = 0.996777 valid = 0.824939\n",
            "2022-01-08 06:22:58 - INFO:\ttrain #12960 lr = 2.74e-05 loss = 0.013292 train = 0.995508 valid = 0.822705\n",
            "2022-01-08 06:23:30 - INFO:\ttrain #12980 lr = 2.73e-05 loss = 0.008958 train = 0.997852 valid = 0.829407\n",
            "2022-01-08 06:24:01 - INFO:\ttrain #13000 lr = 2.73e-05 loss = 0.010503 train = 0.996484 valid = 0.829813\n",
            "2022-01-08 06:24:03 - INFO:\tSaved test = 0.817261\n",
            "2022-01-08 06:24:34 - INFO:\ttrain #13020 lr = 2.72e-05 loss = 0.012188 train = 0.995313 valid = 0.828595\n",
            "2022-01-08 06:25:06 - INFO:\ttrain #13040 lr = 2.71e-05 loss = 0.011022 train = 0.996582 valid = 0.826158\n",
            "2022-01-08 06:25:37 - INFO:\ttrain #13060 lr = 2.71e-05 loss = 0.009836 train = 0.996973 valid = 0.830219\n",
            "2022-01-08 06:26:08 - INFO:\ttrain #13080 lr = 2.70e-05 loss = 0.011934 train = 0.996387 valid = 0.824330\n",
            "2022-01-08 06:26:39 - INFO:\ttrain #13100 lr = 2.70e-05 loss = 0.012477 train = 0.995898 valid = 0.826970\n",
            "2022-01-08 06:26:42 - INFO:\tSaved test = 0.807536\n",
            "2022-01-08 06:27:13 - INFO:\ttrain #13120 lr = 2.69e-05 loss = 0.008901 train = 0.997363 valid = 0.829204\n",
            "2022-01-08 06:27:44 - INFO:\ttrain #13140 lr = 2.69e-05 loss = 0.009969 train = 0.997754 valid = 0.827376\n",
            "2022-01-08 06:28:15 - INFO:\ttrain #13160 lr = 2.68e-05 loss = 0.009489 train = 0.997266 valid = 0.820877\n",
            "2022-01-08 06:28:46 - INFO:\ttrain #13180 lr = 2.68e-05 loss = 0.009092 train = 0.997168 valid = 0.822299\n",
            "2022-01-08 06:29:17 - INFO:\ttrain #13200 lr = 2.67e-05 loss = 0.013250 train = 0.995410 valid = 0.823924\n",
            "2022-01-08 06:29:20 - INFO:\tSaved test = 0.815235\n",
            "2022-01-08 06:29:51 - INFO:\ttrain #13220 lr = 2.67e-05 loss = 0.010132 train = 0.996875 valid = 0.827376\n",
            "2022-01-08 06:30:22 - INFO:\ttrain #13240 lr = 2.66e-05 loss = 0.010936 train = 0.996191 valid = 0.816816\n",
            "2022-01-08 06:30:53 - INFO:\ttrain #13260 lr = 2.66e-05 loss = 0.015438 train = 0.994434 valid = 0.822096\n",
            "2022-01-08 06:31:24 - INFO:\ttrain #13280 lr = 2.65e-05 loss = 0.010262 train = 0.997070 valid = 0.825955\n",
            "2022-01-08 06:31:55 - INFO:\ttrain #13300 lr = 2.64e-05 loss = 0.010377 train = 0.996582 valid = 0.822705\n",
            "2022-01-08 06:31:57 - INFO:\tSaved test = 0.812804\n",
            "2022-01-08 06:32:29 - INFO:\ttrain #13320 lr = 2.64e-05 loss = 0.006676 train = 0.998047 valid = 0.826361\n",
            "2022-01-08 06:33:00 - INFO:\ttrain #13340 lr = 2.63e-05 loss = 0.010963 train = 0.996582 valid = 0.825345\n",
            "2022-01-08 06:33:31 - INFO:\ttrain #13360 lr = 2.63e-05 loss = 0.012935 train = 0.996484 valid = 0.826564\n",
            "2022-01-08 06:34:02 - INFO:\ttrain #13380 lr = 2.62e-05 loss = 0.011817 train = 0.996094 valid = 0.825955\n",
            "2022-01-08 06:34:33 - INFO:\ttrain #13400 lr = 2.62e-05 loss = 0.006609 train = 0.998340 valid = 0.820065\n",
            "2022-01-08 06:34:35 - INFO:\tSaved test = 0.811183\n",
            "2022-01-08 06:35:07 - INFO:\ttrain #13420 lr = 2.61e-05 loss = 0.006646 train = 0.998340 valid = 0.828188\n",
            "2022-01-08 06:35:38 - INFO:\ttrain #13440 lr = 2.61e-05 loss = 0.009194 train = 0.997070 valid = 0.822299\n",
            "2022-01-08 06:36:09 - INFO:\ttrain #13460 lr = 2.60e-05 loss = 0.009986 train = 0.996973 valid = 0.823721\n",
            "2022-01-08 06:36:40 - INFO:\ttrain #13480 lr = 2.60e-05 loss = 0.008697 train = 0.997070 valid = 0.820268\n",
            "2022-01-08 06:37:11 - INFO:\ttrain #13500 lr = 2.59e-05 loss = 0.009713 train = 0.996387 valid = 0.825955\n",
            "2022-01-08 06:37:14 - INFO:\tSaved test = 0.811994\n",
            "2022-01-08 06:37:45 - INFO:\ttrain #13520 lr = 2.59e-05 loss = 0.012437 train = 0.995410 valid = 0.823314\n",
            "2022-01-08 06:38:16 - INFO:\ttrain #13540 lr = 2.58e-05 loss = 0.013794 train = 0.995313 valid = 0.819659\n",
            "2022-01-08 06:38:47 - INFO:\ttrain #13560 lr = 2.58e-05 loss = 0.010354 train = 0.996875 valid = 0.826564\n",
            "2022-01-08 06:39:18 - INFO:\ttrain #13580 lr = 2.57e-05 loss = 0.012930 train = 0.995605 valid = 0.829407\n",
            "2022-01-08 06:39:50 - INFO:\ttrain #13600 lr = 2.57e-05 loss = 0.010687 train = 0.996777 valid = 0.826158\n",
            "2022-01-08 06:39:52 - INFO:\tSaved test = 0.816856\n",
            "2022-01-08 06:40:23 - INFO:\ttrain #13620 lr = 2.56e-05 loss = 0.011910 train = 0.996094 valid = 0.822299\n",
            "2022-01-08 06:40:54 - INFO:\ttrain #13640 lr = 2.56e-05 loss = 0.009667 train = 0.996973 valid = 0.822096\n",
            "2022-01-08 06:41:25 - INFO:\ttrain #13660 lr = 2.55e-05 loss = 0.008584 train = 0.997754 valid = 0.819862\n",
            "2022-01-08 06:41:57 - INFO:\ttrain #13680 lr = 2.55e-05 loss = 0.008446 train = 0.997070 valid = 0.828595\n",
            "2022-01-08 06:42:28 - INFO:\ttrain #13700 lr = 2.54e-05 loss = 0.005939 train = 0.998828 valid = 0.829407\n",
            "2022-01-08 06:42:30 - INFO:\tSaved test = 0.807131\n",
            "2022-01-08 06:43:01 - INFO:\ttrain #13720 lr = 2.54e-05 loss = 0.008589 train = 0.997266 valid = 0.827579\n",
            "2022-01-08 06:43:32 - INFO:\ttrain #13740 lr = 2.53e-05 loss = 0.010548 train = 0.996582 valid = 0.829407\n",
            "2022-01-08 06:44:03 - INFO:\ttrain #13760 lr = 2.53e-05 loss = 0.008890 train = 0.997461 valid = 0.826767\n",
            "2022-01-08 06:44:34 - INFO:\ttrain #13780 lr = 2.52e-05 loss = 0.011059 train = 0.995898 valid = 0.828188\n",
            "2022-01-08 06:45:05 - INFO:\ttrain #13800 lr = 2.52e-05 loss = 0.010281 train = 0.997168 valid = 0.819862\n",
            "2022-01-08 06:45:08 - INFO:\tSaved test = 0.811183\n",
            "2022-01-08 06:45:39 - INFO:\ttrain #13820 lr = 2.51e-05 loss = 0.007635 train = 0.997949 valid = 0.829813\n",
            "2022-01-08 06:46:10 - INFO:\ttrain #13840 lr = 2.51e-05 loss = 0.011076 train = 0.995410 valid = 0.821690\n",
            "2022-01-08 06:46:41 - INFO:\ttrain #13860 lr = 2.50e-05 loss = 0.011250 train = 0.995801 valid = 0.819659\n",
            "2022-01-08 06:47:12 - INFO:\ttrain #13880 lr = 2.50e-05 loss = 0.009414 train = 0.996191 valid = 0.827579\n",
            "2022-01-08 06:47:43 - INFO:\ttrain #13900 lr = 2.49e-05 loss = 0.011267 train = 0.995605 valid = 0.811738\n",
            "2022-01-08 06:47:46 - INFO:\tSaved test = 0.794571\n",
            "2022-01-08 06:48:17 - INFO:\ttrain #13920 lr = 2.49e-05 loss = 0.011311 train = 0.996680 valid = 0.813363\n",
            "2022-01-08 06:48:48 - INFO:\ttrain #13940 lr = 2.48e-05 loss = 0.008098 train = 0.997070 valid = 0.819253\n",
            "2022-01-08 06:49:19 - INFO:\ttrain #13960 lr = 2.48e-05 loss = 0.006923 train = 0.998437 valid = 0.823111\n",
            "2022-01-08 06:49:50 - INFO:\ttrain #13980 lr = 2.47e-05 loss = 0.010199 train = 0.996680 valid = 0.824330\n",
            "2022-01-08 06:50:21 - INFO:\ttrain #14000 lr = 2.47e-05 loss = 0.009587 train = 0.996973 valid = 0.821284\n",
            "2022-01-08 06:50:24 - INFO:\tSaved test = 0.799838\n",
            "2022-01-08 06:50:55 - INFO:\ttrain #14020 lr = 2.46e-05 loss = 0.013428 train = 0.995508 valid = 0.813972\n",
            "2022-01-08 06:51:26 - INFO:\ttrain #14040 lr = 2.46e-05 loss = 0.008669 train = 0.996875 valid = 0.818440\n",
            "2022-01-08 06:51:57 - INFO:\ttrain #14060 lr = 2.45e-05 loss = 0.008806 train = 0.997559 valid = 0.821080\n",
            "2022-01-08 06:52:28 - INFO:\ttrain #14080 lr = 2.45e-05 loss = 0.006667 train = 0.998340 valid = 0.820471\n",
            "2022-01-08 06:53:00 - INFO:\ttrain #14100 lr = 2.44e-05 loss = 0.007493 train = 0.997461 valid = 0.817019\n",
            "2022-01-08 06:53:02 - INFO:\tSaved test = 0.809157\n",
            "2022-01-08 06:53:33 - INFO:\ttrain #14120 lr = 2.44e-05 loss = 0.006560 train = 0.998145 valid = 0.818034\n",
            "2022-01-08 06:54:04 - INFO:\ttrain #14140 lr = 2.43e-05 loss = 0.008570 train = 0.997266 valid = 0.817222\n",
            "2022-01-08 06:54:35 - INFO:\ttrain #14160 lr = 2.43e-05 loss = 0.011305 train = 0.996387 valid = 0.822096\n",
            "2022-01-08 06:55:07 - INFO:\ttrain #14180 lr = 2.42e-05 loss = 0.008991 train = 0.997266 valid = 0.823517\n",
            "2022-01-08 06:55:38 - INFO:\ttrain #14200 lr = 2.42e-05 loss = 0.005347 train = 0.998828 valid = 0.824330\n",
            "2022-01-08 06:55:40 - INFO:\tSaved test = 0.816856\n",
            "2022-01-08 06:56:11 - INFO:\ttrain #14220 lr = 2.41e-05 loss = 0.006923 train = 0.998340 valid = 0.827376\n",
            "2022-01-08 06:56:42 - INFO:\ttrain #14240 lr = 2.41e-05 loss = 0.007467 train = 0.997656 valid = 0.817425\n",
            "2022-01-08 06:57:14 - INFO:\ttrain #14260 lr = 2.40e-05 loss = 0.007212 train = 0.997559 valid = 0.821080\n",
            "2022-01-08 06:57:45 - INFO:\ttrain #14280 lr = 2.40e-05 loss = 0.011112 train = 0.996289 valid = 0.821893\n",
            "2022-01-08 06:58:16 - INFO:\ttrain #14300 lr = 2.39e-05 loss = 0.006594 train = 0.998437 valid = 0.821284\n",
            "2022-01-08 06:58:18 - INFO:\tSaved test = 0.813209\n",
            "2022-01-08 06:58:49 - INFO:\ttrain #14320 lr = 2.39e-05 loss = 0.009804 train = 0.996680 valid = 0.828188\n",
            "2022-01-08 06:59:21 - INFO:\ttrain #14340 lr = 2.38e-05 loss = 0.006874 train = 0.998242 valid = 0.828798\n",
            "2022-01-08 06:59:52 - INFO:\ttrain #14360 lr = 2.38e-05 loss = 0.006817 train = 0.997461 valid = 0.823517\n",
            "2022-01-08 07:00:23 - INFO:\ttrain #14380 lr = 2.37e-05 loss = 0.006707 train = 0.998047 valid = 0.823111\n",
            "2022-01-08 07:00:54 - INFO:\ttrain #14400 lr = 2.37e-05 loss = 0.008618 train = 0.997559 valid = 0.828392\n",
            "2022-01-08 07:00:57 - INFO:\tSaved test = 0.814425\n",
            "2022-01-08 07:01:28 - INFO:\ttrain #14420 lr = 2.36e-05 loss = 0.006167 train = 0.998437 valid = 0.822908\n",
            "2022-01-08 07:01:59 - INFO:\ttrain #14440 lr = 2.36e-05 loss = 0.006755 train = 0.998242 valid = 0.823924\n",
            "2022-01-08 07:02:30 - INFO:\ttrain #14460 lr = 2.35e-05 loss = 0.006879 train = 0.997656 valid = 0.825548\n",
            "2022-01-08 07:03:01 - INFO:\ttrain #14480 lr = 2.35e-05 loss = 0.005738 train = 0.998145 valid = 0.829001\n",
            "2022-01-08 07:03:32 - INFO:\ttrain #14500 lr = 2.35e-05 loss = 0.008701 train = 0.997754 valid = 0.824939\n",
            "2022-01-08 07:03:35 - INFO:\tSaved test = 0.806321\n",
            "2022-01-08 07:04:06 - INFO:\ttrain #14520 lr = 2.34e-05 loss = 0.008927 train = 0.997559 valid = 0.827376\n",
            "2022-01-08 07:04:37 - INFO:\ttrain #14540 lr = 2.34e-05 loss = 0.007941 train = 0.997754 valid = 0.824736\n",
            "2022-01-08 07:05:08 - INFO:\ttrain #14560 lr = 2.33e-05 loss = 0.009082 train = 0.996777 valid = 0.821893\n",
            "2022-01-08 07:05:40 - INFO:\ttrain #14580 lr = 2.33e-05 loss = 0.009529 train = 0.996680 valid = 0.819456\n",
            "2022-01-08 07:06:11 - INFO:\ttrain #14600 lr = 2.32e-05 loss = 0.007523 train = 0.997754 valid = 0.822299\n",
            "2022-01-08 07:06:13 - INFO:\tSaved test = 0.808347\n",
            "2022-01-08 07:06:44 - INFO:\ttrain #14620 lr = 2.32e-05 loss = 0.006046 train = 0.998535 valid = 0.822908\n",
            "2022-01-08 07:07:15 - INFO:\ttrain #14640 lr = 2.31e-05 loss = 0.009222 train = 0.997070 valid = 0.822096\n",
            "2022-01-08 07:07:46 - INFO:\ttrain #14660 lr = 2.31e-05 loss = 0.009674 train = 0.996484 valid = 0.821284\n",
            "2022-01-08 07:08:18 - INFO:\ttrain #14680 lr = 2.30e-05 loss = 0.006007 train = 0.998340 valid = 0.825751\n",
            "2022-01-08 07:08:49 - INFO:\ttrain #14700 lr = 2.30e-05 loss = 0.011053 train = 0.996387 valid = 0.820674\n",
            "2022-01-08 07:08:51 - INFO:\tSaved test = 0.814830\n",
            "2022-01-08 07:09:22 - INFO:\ttrain #14720 lr = 2.29e-05 loss = 0.007069 train = 0.998145 valid = 0.827782\n",
            "2022-01-08 07:09:53 - INFO:\ttrain #14740 lr = 2.29e-05 loss = 0.008282 train = 0.996777 valid = 0.824736\n",
            "2022-01-08 07:10:25 - INFO:\ttrain #14760 lr = 2.29e-05 loss = 0.007442 train = 0.997168 valid = 0.823111\n",
            "2022-01-08 07:10:56 - INFO:\ttrain #14780 lr = 2.28e-05 loss = 0.007484 train = 0.997461 valid = 0.824533\n",
            "2022-01-08 07:11:27 - INFO:\ttrain #14800 lr = 2.28e-05 loss = 0.006563 train = 0.997754 valid = 0.822908\n",
            "2022-01-08 07:11:29 - INFO:\tSaved test = 0.807131\n",
            "2022-01-08 07:12:00 - INFO:\ttrain #14820 lr = 2.27e-05 loss = 0.006461 train = 0.998633 valid = 0.823111\n",
            "2022-01-08 07:12:31 - INFO:\ttrain #14840 lr = 2.27e-05 loss = 0.008773 train = 0.997559 valid = 0.823924\n",
            "2022-01-08 07:13:02 - INFO:\ttrain #14860 lr = 2.26e-05 loss = 0.007447 train = 0.997852 valid = 0.825751\n",
            "2022-01-08 07:13:34 - INFO:\ttrain #14880 lr = 2.26e-05 loss = 0.007984 train = 0.997754 valid = 0.820877\n",
            "2022-01-08 07:14:05 - INFO:\ttrain #14900 lr = 2.25e-05 loss = 0.009213 train = 0.996875 valid = 0.820877\n",
            "2022-01-08 07:14:07 - INFO:\tSaved test = 0.811994\n",
            "2022-01-08 07:14:38 - INFO:\ttrain #14920 lr = 2.25e-05 loss = 0.008454 train = 0.997461 valid = 0.824736\n",
            "2022-01-08 07:15:09 - INFO:\ttrain #14940 lr = 2.24e-05 loss = 0.006808 train = 0.997754 valid = 0.818440\n",
            "2022-01-08 07:15:40 - INFO:\ttrain #14960 lr = 2.24e-05 loss = 0.006097 train = 0.998535 valid = 0.820065\n",
            "2022-01-08 07:16:11 - INFO:\ttrain #14980 lr = 2.24e-05 loss = 0.009157 train = 0.997461 valid = 0.820268\n",
            "2022-01-08 07:16:42 - INFO:\ttrain #15000 lr = 2.23e-05 loss = 0.005212 train = 0.998730 valid = 0.821487\n",
            "2022-01-08 07:16:44 - INFO:\tSaved test = 0.812399\n",
            "2022-01-08 07:17:15 - INFO:\ttrain #15020 lr = 2.23e-05 loss = 0.006897 train = 0.997559 valid = 0.820065\n",
            "2022-01-08 07:17:47 - INFO:\ttrain #15040 lr = 2.22e-05 loss = 0.006760 train = 0.998145 valid = 0.819862\n",
            "2022-01-08 07:18:18 - INFO:\ttrain #15060 lr = 2.22e-05 loss = 0.006520 train = 0.998340 valid = 0.823924\n",
            "2022-01-08 07:18:48 - INFO:\ttrain #15080 lr = 2.21e-05 loss = 0.005720 train = 0.998145 valid = 0.826361\n",
            "2022-01-08 07:19:20 - INFO:\ttrain #15100 lr = 2.21e-05 loss = 0.008514 train = 0.997168 valid = 0.820471\n",
            "2022-01-08 07:19:22 - INFO:\tSaved test = 0.809562\n",
            "2022-01-08 07:19:53 - INFO:\ttrain #15120 lr = 2.20e-05 loss = 0.007254 train = 0.997949 valid = 0.822908\n",
            "2022-01-08 07:20:24 - INFO:\ttrain #15140 lr = 2.20e-05 loss = 0.010500 train = 0.996680 valid = 0.812348\n",
            "2022-01-08 07:20:55 - INFO:\ttrain #15160 lr = 2.20e-05 loss = 0.006532 train = 0.998437 valid = 0.827782\n",
            "2022-01-08 07:21:27 - INFO:\ttrain #15180 lr = 2.19e-05 loss = 0.008288 train = 0.996875 valid = 0.816613\n",
            "2022-01-08 07:21:58 - INFO:\ttrain #15200 lr = 2.19e-05 loss = 0.007368 train = 0.997754 valid = 0.822096\n",
            "2022-01-08 07:22:00 - INFO:\tSaved test = 0.812804\n",
            "2022-01-08 07:22:31 - INFO:\ttrain #15220 lr = 2.18e-05 loss = 0.007718 train = 0.997168 valid = 0.827376\n",
            "2022-01-08 07:23:02 - INFO:\ttrain #15240 lr = 2.18e-05 loss = 0.006493 train = 0.998145 valid = 0.827782\n",
            "2022-01-08 07:23:34 - INFO:\ttrain #15260 lr = 2.17e-05 loss = 0.007171 train = 0.997461 valid = 0.826361\n",
            "2022-01-08 07:24:05 - INFO:\ttrain #15280 lr = 2.17e-05 loss = 0.007037 train = 0.997559 valid = 0.821080\n",
            "2022-01-08 07:24:36 - INFO:\ttrain #15300 lr = 2.17e-05 loss = 0.007132 train = 0.997559 valid = 0.824736\n",
            "2022-01-08 07:24:38 - INFO:\tSaved test = 0.817261\n",
            "2022-01-08 07:25:09 - INFO:\ttrain #15320 lr = 2.16e-05 loss = 0.006757 train = 0.998047 valid = 0.821487\n",
            "2022-01-08 07:25:40 - INFO:\ttrain #15340 lr = 2.16e-05 loss = 0.005102 train = 0.999121 valid = 0.824330\n",
            "2022-01-08 07:26:11 - INFO:\ttrain #15360 lr = 2.15e-05 loss = 0.004595 train = 0.999121 valid = 0.824939\n",
            "2022-01-08 07:26:43 - INFO:\ttrain #15380 lr = 2.15e-05 loss = 0.005086 train = 0.998926 valid = 0.823517\n",
            "2022-01-08 07:27:14 - INFO:\ttrain #15400 lr = 2.14e-05 loss = 0.006239 train = 0.997852 valid = 0.828798\n",
            "2022-01-08 07:27:16 - INFO:\tSaved test = 0.811588\n",
            "2022-01-08 07:27:47 - INFO:\ttrain #15420 lr = 2.14e-05 loss = 0.007837 train = 0.997754 valid = 0.820471\n",
            "2022-01-08 07:28:19 - INFO:\ttrain #15440 lr = 2.14e-05 loss = 0.007341 train = 0.997852 valid = 0.818643\n",
            "2022-01-08 07:28:50 - INFO:\ttrain #15460 lr = 2.13e-05 loss = 0.008072 train = 0.997363 valid = 0.822299\n",
            "2022-01-08 07:29:21 - INFO:\ttrain #15480 lr = 2.13e-05 loss = 0.007465 train = 0.997266 valid = 0.822908\n",
            "2022-01-08 07:29:52 - INFO:\ttrain #15500 lr = 2.12e-05 loss = 0.007105 train = 0.998242 valid = 0.825751\n",
            "2022-01-08 07:29:54 - INFO:\tSaved test = 0.812804\n",
            "2022-01-08 07:30:25 - INFO:\ttrain #15520 lr = 2.12e-05 loss = 0.005752 train = 0.998242 valid = 0.825955\n",
            "2022-01-08 07:30:57 - INFO:\ttrain #15540 lr = 2.11e-05 loss = 0.006803 train = 0.997754 valid = 0.823314\n",
            "2022-01-08 07:31:28 - INFO:\ttrain #15560 lr = 2.11e-05 loss = 0.006124 train = 0.998145 valid = 0.825345\n",
            "2022-01-08 07:31:59 - INFO:\ttrain #15580 lr = 2.11e-05 loss = 0.006881 train = 0.997656 valid = 0.822299\n",
            "2022-01-08 07:32:30 - INFO:\ttrain #15600 lr = 2.10e-05 loss = 0.007038 train = 0.997559 valid = 0.824736\n",
            "2022-01-08 07:32:32 - INFO:\tSaved test = 0.815640\n",
            "2022-01-08 07:33:04 - INFO:\ttrain #15620 lr = 2.10e-05 loss = 0.005517 train = 0.998340 valid = 0.825548\n",
            "2022-01-08 07:33:35 - INFO:\ttrain #15640 lr = 2.09e-05 loss = 0.006743 train = 0.997852 valid = 0.821690\n",
            "2022-01-08 07:34:06 - INFO:\ttrain #15660 lr = 2.09e-05 loss = 0.007640 train = 0.997363 valid = 0.824939\n",
            "2022-01-08 07:34:37 - INFO:\ttrain #15680 lr = 2.08e-05 loss = 0.005005 train = 0.998730 valid = 0.821284\n",
            "2022-01-08 07:35:08 - INFO:\ttrain #15700 lr = 2.08e-05 loss = 0.005381 train = 0.998437 valid = 0.824127\n",
            "2022-01-08 07:35:10 - INFO:\tSaved test = 0.811994\n",
            "2022-01-08 07:35:42 - INFO:\ttrain #15720 lr = 2.08e-05 loss = 0.007192 train = 0.998047 valid = 0.822299\n",
            "2022-01-08 07:36:12 - INFO:\ttrain #15740 lr = 2.07e-05 loss = 0.006125 train = 0.998145 valid = 0.820877\n",
            "2022-01-08 07:36:43 - INFO:\ttrain #15760 lr = 2.07e-05 loss = 0.007886 train = 0.997266 valid = 0.823517\n",
            "2022-01-08 07:37:14 - INFO:\ttrain #15780 lr = 2.06e-05 loss = 0.005060 train = 0.998535 valid = 0.818237\n",
            "2022-01-08 07:37:45 - INFO:\ttrain #15800 lr = 2.06e-05 loss = 0.005463 train = 0.998535 valid = 0.819659\n",
            "2022-01-08 07:37:47 - INFO:\tSaved test = 0.811994\n",
            "2022-01-08 07:38:18 - INFO:\ttrain #15820 lr = 2.06e-05 loss = 0.006109 train = 0.997852 valid = 0.822299\n",
            "2022-01-08 07:38:49 - INFO:\ttrain #15840 lr = 2.05e-05 loss = 0.005278 train = 0.998242 valid = 0.825345\n",
            "2022-01-08 07:39:20 - INFO:\ttrain #15860 lr = 2.05e-05 loss = 0.006085 train = 0.998047 valid = 0.824330\n",
            "2022-01-08 07:39:51 - INFO:\ttrain #15880 lr = 2.04e-05 loss = 0.005368 train = 0.998535 valid = 0.824736\n",
            "2022-01-08 07:40:22 - INFO:\ttrain #15900 lr = 2.04e-05 loss = 0.008993 train = 0.997070 valid = 0.823721\n",
            "2022-01-08 07:40:25 - INFO:\tSaved test = 0.810373\n",
            "2022-01-08 07:40:56 - INFO:\ttrain #15920 lr = 2.04e-05 loss = 0.005812 train = 0.998340 valid = 0.821893\n",
            "2022-01-08 07:41:27 - INFO:\ttrain #15940 lr = 2.03e-05 loss = 0.003861 train = 0.999316 valid = 0.820877\n",
            "2022-01-08 07:41:58 - INFO:\ttrain #15960 lr = 2.03e-05 loss = 0.006337 train = 0.997949 valid = 0.821487\n",
            "2022-01-08 07:42:30 - INFO:\ttrain #15980 lr = 2.02e-05 loss = 0.007030 train = 0.997852 valid = 0.823314\n",
            "2022-01-08 07:43:01 - INFO:\ttrain #16000 lr = 2.02e-05 loss = 0.004743 train = 0.998242 valid = 0.824330\n",
            "2022-01-08 07:43:03 - INFO:\tSaved test = 0.811588\n",
            "2022-01-08 07:43:34 - INFO:\ttrain #16020 lr = 2.01e-05 loss = 0.005487 train = 0.998437 valid = 0.827782\n",
            "2022-01-08 07:44:05 - INFO:\ttrain #16040 lr = 2.01e-05 loss = 0.004159 train = 0.999219 valid = 0.824533\n",
            "2022-01-08 07:44:37 - INFO:\ttrain #16060 lr = 2.01e-05 loss = 0.006639 train = 0.998047 valid = 0.827985\n",
            "2022-01-08 07:45:07 - INFO:\ttrain #16080 lr = 2.00e-05 loss = 0.008084 train = 0.996777 valid = 0.827376\n",
            "2022-01-08 07:45:39 - INFO:\ttrain #16100 lr = 2.00e-05 loss = 0.006336 train = 0.997559 valid = 0.820471\n",
            "2022-01-08 07:45:41 - INFO:\tSaved test = 0.818882\n",
            "2022-01-08 07:46:12 - INFO:\ttrain #16120 lr = 1.99e-05 loss = 0.006074 train = 0.998730 valid = 0.823721\n",
            "2022-01-08 07:46:43 - INFO:\ttrain #16140 lr = 1.99e-05 loss = 0.006348 train = 0.998535 valid = 0.823721\n",
            "2022-01-08 07:47:14 - INFO:\ttrain #16160 lr = 1.99e-05 loss = 0.003492 train = 0.999316 valid = 0.830422\n",
            "2022-01-08 07:47:45 - INFO:\ttrain #16180 lr = 1.98e-05 loss = 0.004120 train = 0.999023 valid = 0.826361\n",
            "2022-01-08 07:48:16 - INFO:\ttrain #16200 lr = 1.98e-05 loss = 0.005266 train = 0.998340 valid = 0.825345\n",
            "2022-01-08 07:48:18 - INFO:\tSaved test = 0.817261\n",
            "2022-01-08 07:48:50 - INFO:\ttrain #16220 lr = 1.97e-05 loss = 0.008448 train = 0.997266 valid = 0.823517\n",
            "2022-01-08 07:49:21 - INFO:\ttrain #16240 lr = 1.97e-05 loss = 0.008065 train = 0.998047 valid = 0.821893\n",
            "2022-01-08 07:49:52 - INFO:\ttrain #16260 lr = 1.97e-05 loss = 0.004002 train = 0.999121 valid = 0.823721\n",
            "2022-01-08 07:50:23 - INFO:\ttrain #16280 lr = 1.96e-05 loss = 0.005263 train = 0.998535 valid = 0.820674\n",
            "2022-01-08 07:50:54 - INFO:\ttrain #16300 lr = 1.96e-05 loss = 0.004444 train = 0.998730 valid = 0.820268\n",
            "2022-01-08 07:50:57 - INFO:\tSaved test = 0.809562\n",
            "2022-01-08 07:51:28 - INFO:\ttrain #16320 lr = 1.96e-05 loss = 0.006069 train = 0.998242 valid = 0.821284\n",
            "2022-01-08 07:51:59 - INFO:\ttrain #16340 lr = 1.95e-05 loss = 0.005942 train = 0.997852 valid = 0.820674\n",
            "2022-01-08 07:52:30 - INFO:\ttrain #16360 lr = 1.95e-05 loss = 0.005401 train = 0.998145 valid = 0.826970\n",
            "2022-01-08 07:53:01 - INFO:\ttrain #16380 lr = 1.94e-05 loss = 0.005329 train = 0.998730 valid = 0.827782\n",
            "2022-01-08 07:53:32 - INFO:\ttrain #16400 lr = 1.94e-05 loss = 0.004672 train = 0.998535 valid = 0.821893\n",
            "2022-01-08 07:53:35 - INFO:\tSaved test = 0.814019\n",
            "2022-01-08 07:54:06 - INFO:\ttrain #16420 lr = 1.94e-05 loss = 0.004440 train = 0.998926 valid = 0.827173\n",
            "2022-01-08 07:54:37 - INFO:\ttrain #16440 lr = 1.93e-05 loss = 0.007732 train = 0.997754 valid = 0.822096\n",
            "2022-01-08 07:55:08 - INFO:\ttrain #16460 lr = 1.93e-05 loss = 0.006159 train = 0.998340 valid = 0.819050\n",
            "2022-01-08 07:55:40 - INFO:\ttrain #16480 lr = 1.92e-05 loss = 0.005954 train = 0.998047 valid = 0.829610\n",
            "2022-01-08 07:56:10 - INFO:\ttrain #16500 lr = 1.92e-05 loss = 0.005248 train = 0.998340 valid = 0.821284\n",
            "2022-01-08 07:56:13 - INFO:\tSaved test = 0.810778\n",
            "2022-01-08 07:56:44 - INFO:\ttrain #16520 lr = 1.92e-05 loss = 0.005850 train = 0.998535 valid = 0.820877\n",
            "2022-01-08 07:57:15 - INFO:\ttrain #16540 lr = 1.91e-05 loss = 0.006545 train = 0.998145 valid = 0.824736\n",
            "2022-01-08 07:57:46 - INFO:\ttrain #16560 lr = 1.91e-05 loss = 0.004438 train = 0.998633 valid = 0.826361\n",
            "2022-01-08 07:58:18 - INFO:\ttrain #16580 lr = 1.91e-05 loss = 0.003859 train = 0.999219 valid = 0.825955\n",
            "2022-01-08 07:58:49 - INFO:\ttrain #16600 lr = 1.90e-05 loss = 0.003131 train = 0.999023 valid = 0.827376\n",
            "2022-01-08 07:58:51 - INFO:\tSaved test = 0.812399\n",
            "2022-01-08 07:59:22 - INFO:\ttrain #16620 lr = 1.90e-05 loss = 0.004004 train = 0.999414 valid = 0.826361\n",
            "2022-01-08 07:59:53 - INFO:\ttrain #16640 lr = 1.89e-05 loss = 0.004238 train = 0.998535 valid = 0.823314\n",
            "2022-01-08 08:00:24 - INFO:\ttrain #16660 lr = 1.89e-05 loss = 0.008342 train = 0.997559 valid = 0.822096\n",
            "2022-01-08 08:00:56 - INFO:\ttrain #16680 lr = 1.89e-05 loss = 0.008133 train = 0.997754 valid = 0.817019\n",
            "2022-01-08 08:01:27 - INFO:\ttrain #16700 lr = 1.88e-05 loss = 0.005451 train = 0.998633 valid = 0.819253\n",
            "2022-01-08 08:01:29 - INFO:\tSaved test = 0.818476\n",
            "2022-01-08 08:02:00 - INFO:\ttrain #16720 lr = 1.88e-05 loss = 0.006738 train = 0.998535 valid = 0.822502\n",
            "2022-01-08 08:02:31 - INFO:\ttrain #16740 lr = 1.87e-05 loss = 0.006197 train = 0.998242 valid = 0.822299\n",
            "2022-01-08 08:03:02 - INFO:\ttrain #16760 lr = 1.87e-05 loss = 0.004921 train = 0.998437 valid = 0.821893\n",
            "2022-01-08 08:03:33 - INFO:\ttrain #16780 lr = 1.87e-05 loss = 0.005891 train = 0.998340 valid = 0.825751\n",
            "2022-01-08 08:04:04 - INFO:\ttrain #16800 lr = 1.86e-05 loss = 0.006724 train = 0.997852 valid = 0.827985\n",
            "2022-01-08 08:04:06 - INFO:\tSaved test = 0.812804\n",
            "2022-01-08 08:04:37 - INFO:\ttrain #16820 lr = 1.86e-05 loss = 0.004061 train = 0.998633 valid = 0.828595\n",
            "2022-01-08 08:05:08 - INFO:\ttrain #16840 lr = 1.86e-05 loss = 0.003152 train = 0.999414 valid = 0.827579\n",
            "2022-01-08 08:05:39 - INFO:\ttrain #16860 lr = 1.85e-05 loss = 0.004037 train = 0.998633 valid = 0.823517\n",
            "2022-01-08 08:06:10 - INFO:\ttrain #16880 lr = 1.85e-05 loss = 0.004878 train = 0.998437 valid = 0.828798\n",
            "2022-01-08 08:06:41 - INFO:\ttrain #16900 lr = 1.85e-05 loss = 0.004903 train = 0.998340 valid = 0.823111\n",
            "2022-01-08 08:06:44 - INFO:\tSaved test = 0.811994\n",
            "2022-01-08 08:07:15 - INFO:\ttrain #16920 lr = 1.84e-05 loss = 0.005275 train = 0.998730 valid = 0.828595\n",
            "2022-01-08 08:07:46 - INFO:\ttrain #16940 lr = 1.84e-05 loss = 0.003254 train = 0.999121 valid = 0.830422\n",
            "2022-01-08 08:08:17 - INFO:\ttrain #16960 lr = 1.83e-05 loss = 0.007396 train = 0.997559 valid = 0.820877\n",
            "2022-01-08 08:08:48 - INFO:\ttrain #16980 lr = 1.83e-05 loss = 0.003910 train = 0.999023 valid = 0.825345\n",
            "2022-01-08 08:09:19 - INFO:\ttrain #17000 lr = 1.83e-05 loss = 0.004745 train = 0.998633 valid = 0.823924\n",
            "2022-01-08 08:09:22 - INFO:\tSaved test = 0.811994\n",
            "2022-01-08 08:09:53 - INFO:\ttrain #17020 lr = 1.82e-05 loss = 0.008049 train = 0.996973 valid = 0.822502\n",
            "2022-01-08 08:10:24 - INFO:\ttrain #17040 lr = 1.82e-05 loss = 0.005965 train = 0.998437 valid = 0.821080\n",
            "2022-01-08 08:10:55 - INFO:\ttrain #17060 lr = 1.82e-05 loss = 0.005368 train = 0.998633 valid = 0.825751\n",
            "2022-01-08 08:11:27 - INFO:\ttrain #17080 lr = 1.81e-05 loss = 0.005836 train = 0.998340 valid = 0.824330\n",
            "2022-01-08 08:11:58 - INFO:\ttrain #17100 lr = 1.81e-05 loss = 0.004440 train = 0.998926 valid = 0.823517\n",
            "2022-01-08 08:12:00 - INFO:\tSaved test = 0.812804\n",
            "2022-01-08 08:12:31 - INFO:\ttrain #17120 lr = 1.80e-05 loss = 0.005466 train = 0.997949 valid = 0.822705\n",
            "2022-01-08 08:13:02 - INFO:\ttrain #17140 lr = 1.80e-05 loss = 0.003398 train = 0.999219 valid = 0.824533\n",
            "2022-01-08 08:13:34 - INFO:\ttrain #17160 lr = 1.80e-05 loss = 0.003937 train = 0.998926 valid = 0.823721\n",
            "2022-01-08 08:14:05 - INFO:\ttrain #17180 lr = 1.79e-05 loss = 0.005805 train = 0.997754 valid = 0.819862\n",
            "2022-01-08 08:14:36 - INFO:\ttrain #17200 lr = 1.79e-05 loss = 0.005379 train = 0.998437 valid = 0.825955\n",
            "2022-01-08 08:14:38 - INFO:\tSaved test = 0.810778\n",
            "2022-01-08 08:15:09 - INFO:\ttrain #17220 lr = 1.79e-05 loss = 0.004374 train = 0.998730 valid = 0.823517\n",
            "2022-01-08 08:15:40 - INFO:\ttrain #17240 lr = 1.78e-05 loss = 0.003599 train = 0.998828 valid = 0.824736\n",
            "2022-01-08 08:16:11 - INFO:\ttrain #17260 lr = 1.78e-05 loss = 0.005211 train = 0.998437 valid = 0.822908\n",
            "2022-01-08 08:16:42 - INFO:\ttrain #17280 lr = 1.78e-05 loss = 0.006700 train = 0.997949 valid = 0.825548\n",
            "2022-01-08 08:17:14 - INFO:\ttrain #17300 lr = 1.77e-05 loss = 0.004017 train = 0.999023 valid = 0.822096\n",
            "2022-01-08 08:17:16 - INFO:\tSaved test = 0.818882\n",
            "2022-01-08 08:17:47 - INFO:\ttrain #17320 lr = 1.77e-05 loss = 0.005651 train = 0.997949 valid = 0.822705\n",
            "2022-01-08 08:18:18 - INFO:\ttrain #17340 lr = 1.77e-05 loss = 0.004174 train = 0.998926 valid = 0.824127\n",
            "2022-01-08 08:18:49 - INFO:\ttrain #17360 lr = 1.76e-05 loss = 0.003113 train = 0.999121 valid = 0.823721\n",
            "2022-01-08 08:19:20 - INFO:\ttrain #17380 lr = 1.76e-05 loss = 0.003380 train = 0.999023 valid = 0.823314\n",
            "2022-01-08 08:19:52 - INFO:\ttrain #17400 lr = 1.76e-05 loss = 0.004076 train = 0.998633 valid = 0.818643\n",
            "2022-01-08 08:19:54 - INFO:\tSaved test = 0.816045\n",
            "2022-01-08 08:20:25 - INFO:\ttrain #17420 lr = 1.75e-05 loss = 0.005337 train = 0.998437 valid = 0.824533\n",
            "2022-01-08 08:20:56 - INFO:\ttrain #17440 lr = 1.75e-05 loss = 0.004375 train = 0.998535 valid = 0.820065\n",
            "2022-01-08 08:21:28 - INFO:\ttrain #17460 lr = 1.74e-05 loss = 0.004292 train = 0.999219 valid = 0.827782\n",
            "2022-01-08 08:21:59 - INFO:\ttrain #17480 lr = 1.74e-05 loss = 0.003427 train = 0.999121 valid = 0.819659\n",
            "2022-01-08 08:22:30 - INFO:\ttrain #17500 lr = 1.74e-05 loss = 0.003846 train = 0.998828 valid = 0.823924\n",
            "2022-01-08 08:22:32 - INFO:\tSaved test = 0.819692\n",
            "2022-01-08 08:23:03 - INFO:\ttrain #17520 lr = 1.73e-05 loss = 0.003601 train = 0.999219 valid = 0.823111\n",
            "2022-01-08 08:23:34 - INFO:\ttrain #17540 lr = 1.73e-05 loss = 0.004936 train = 0.998437 valid = 0.822502\n",
            "2022-01-08 08:24:05 - INFO:\ttrain #17560 lr = 1.73e-05 loss = 0.004624 train = 0.998730 valid = 0.820471\n",
            "2022-01-08 08:24:36 - INFO:\ttrain #17580 lr = 1.72e-05 loss = 0.003107 train = 0.999023 valid = 0.823111\n",
            "2022-01-08 08:25:08 - INFO:\ttrain #17600 lr = 1.72e-05 loss = 0.008064 train = 0.997168 valid = 0.820268\n",
            "2022-01-08 08:25:10 - INFO:\tSaved test = 0.813614\n",
            "2022-01-08 08:25:41 - INFO:\ttrain #17620 lr = 1.72e-05 loss = 0.005929 train = 0.998047 valid = 0.820471\n",
            "2022-01-08 08:26:12 - INFO:\ttrain #17640 lr = 1.71e-05 loss = 0.006151 train = 0.997949 valid = 0.820674\n",
            "2022-01-08 08:26:43 - INFO:\ttrain #17660 lr = 1.71e-05 loss = 0.005416 train = 0.998145 valid = 0.823314\n",
            "2022-01-08 08:27:15 - INFO:\ttrain #17680 lr = 1.71e-05 loss = 0.003421 train = 0.998828 valid = 0.825142\n",
            "2022-01-08 08:27:46 - INFO:\ttrain #17700 lr = 1.70e-05 loss = 0.002754 train = 0.999609 valid = 0.824533\n",
            "2022-01-08 08:27:48 - INFO:\tSaved test = 0.813209\n",
            "2022-01-08 08:28:19 - INFO:\ttrain #17720 lr = 1.70e-05 loss = 0.005509 train = 0.998047 valid = 0.821893\n",
            "2022-01-08 08:28:50 - INFO:\ttrain #17740 lr = 1.70e-05 loss = 0.005244 train = 0.998340 valid = 0.827173\n",
            "2022-01-08 08:29:21 - INFO:\ttrain #17760 lr = 1.69e-05 loss = 0.003057 train = 0.999121 valid = 0.826361\n",
            "2022-01-08 08:29:52 - INFO:\ttrain #17780 lr = 1.69e-05 loss = 0.005305 train = 0.998437 valid = 0.824736\n",
            "2022-01-08 08:30:23 - INFO:\ttrain #17800 lr = 1.69e-05 loss = 0.003481 train = 0.998730 valid = 0.828595\n",
            "2022-01-08 08:30:25 - INFO:\tSaved test = 0.814019\n",
            "2022-01-08 08:30:56 - INFO:\ttrain #17820 lr = 1.68e-05 loss = 0.003257 train = 0.999023 valid = 0.825345\n",
            "2022-01-08 08:31:27 - INFO:\ttrain #17840 lr = 1.68e-05 loss = 0.003949 train = 0.999121 valid = 0.824736\n",
            "2022-01-08 08:31:59 - INFO:\ttrain #17860 lr = 1.68e-05 loss = 0.004275 train = 0.998926 valid = 0.830219\n",
            "2022-01-08 08:32:30 - INFO:\ttrain #17880 lr = 1.67e-05 loss = 0.005632 train = 0.998242 valid = 0.823111\n",
            "2022-01-08 08:33:01 - INFO:\ttrain #17900 lr = 1.67e-05 loss = 0.005802 train = 0.998926 valid = 0.828188\n",
            "2022-01-08 08:33:03 - INFO:\tSaved test = 0.816856\n",
            "2022-01-08 08:33:34 - INFO:\ttrain #17920 lr = 1.67e-05 loss = 0.004350 train = 0.998828 valid = 0.831844 updated\n",
            "2022-01-08 08:34:05 - INFO:\ttrain #17940 lr = 1.66e-05 loss = 0.005578 train = 0.998437 valid = 0.830626\n",
            "2022-01-08 08:34:36 - INFO:\ttrain #17960 lr = 1.66e-05 loss = 0.004397 train = 0.998535 valid = 0.830016\n",
            "2022-01-08 08:35:08 - INFO:\ttrain #17980 lr = 1.66e-05 loss = 0.005948 train = 0.998145 valid = 0.824533\n",
            "2022-01-08 08:35:39 - INFO:\ttrain #18000 lr = 1.65e-05 loss = 0.006053 train = 0.998242 valid = 0.822502\n",
            "2022-01-08 08:35:41 - INFO:\tSaved test = 0.819287\n",
            "2022-01-08 08:36:12 - INFO:\ttrain #18020 lr = 1.65e-05 loss = 0.004307 train = 0.998633 valid = 0.831844\n",
            "2022-01-08 08:36:43 - INFO:\ttrain #18040 lr = 1.65e-05 loss = 0.002345 train = 0.999609 valid = 0.828188\n",
            "2022-01-08 08:37:14 - INFO:\ttrain #18060 lr = 1.64e-05 loss = 0.002576 train = 0.999609 valid = 0.826564\n",
            "2022-01-08 08:37:46 - INFO:\ttrain #18080 lr = 1.64e-05 loss = 0.002712 train = 0.999121 valid = 0.825345\n",
            "2022-01-08 08:38:16 - INFO:\ttrain #18100 lr = 1.64e-05 loss = 0.003500 train = 0.999219 valid = 0.823314\n",
            "2022-01-08 08:38:19 - INFO:\tSaved test = 0.814019\n",
            "2022-01-08 08:38:50 - INFO:\ttrain #18120 lr = 1.63e-05 loss = 0.003493 train = 0.999023 valid = 0.826361\n",
            "2022-01-08 08:39:21 - INFO:\ttrain #18140 lr = 1.63e-05 loss = 0.002612 train = 0.999707 valid = 0.829610\n",
            "2022-01-08 08:39:52 - INFO:\ttrain #18160 lr = 1.63e-05 loss = 0.004606 train = 0.998242 valid = 0.825548\n",
            "2022-01-08 08:40:24 - INFO:\ttrain #18180 lr = 1.62e-05 loss = 0.005535 train = 0.998145 valid = 0.822299\n",
            "2022-01-08 08:40:55 - INFO:\ttrain #18200 lr = 1.62e-05 loss = 0.003757 train = 0.998926 valid = 0.824330\n",
            "2022-01-08 08:40:57 - INFO:\tSaved test = 0.813209\n",
            "2022-01-08 08:41:28 - INFO:\ttrain #18220 lr = 1.62e-05 loss = 0.001978 train = 0.999609 valid = 0.823111\n",
            "2022-01-08 08:41:59 - INFO:\ttrain #18240 lr = 1.61e-05 loss = 0.002736 train = 0.999219 valid = 0.828392\n",
            "2022-01-08 08:42:31 - INFO:\ttrain #18260 lr = 1.61e-05 loss = 0.002782 train = 0.999414 valid = 0.828595\n",
            "2022-01-08 08:43:02 - INFO:\ttrain #18280 lr = 1.61e-05 loss = 0.004911 train = 0.998437 valid = 0.820268\n",
            "2022-01-08 08:43:33 - INFO:\ttrain #18300 lr = 1.60e-05 loss = 0.004404 train = 0.998242 valid = 0.821893\n",
            "2022-01-08 08:43:35 - INFO:\tSaved test = 0.811994\n",
            "2022-01-08 08:44:06 - INFO:\ttrain #18320 lr = 1.60e-05 loss = 0.004904 train = 0.998340 valid = 0.819456\n",
            "2022-01-08 08:44:37 - INFO:\ttrain #18340 lr = 1.60e-05 loss = 0.002574 train = 0.999512 valid = 0.822502\n",
            "2022-01-08 08:45:09 - INFO:\ttrain #18360 lr = 1.59e-05 loss = 0.004069 train = 0.998730 valid = 0.820877\n",
            "2022-01-08 08:45:40 - INFO:\ttrain #18380 lr = 1.59e-05 loss = 0.003261 train = 0.999121 valid = 0.822908\n",
            "2022-01-08 08:46:11 - INFO:\ttrain #18400 lr = 1.59e-05 loss = 0.006321 train = 0.997852 valid = 0.822502\n",
            "2022-01-08 08:46:13 - INFO:\tSaved test = 0.811588\n",
            "2022-01-08 08:46:45 - INFO:\ttrain #18420 lr = 1.58e-05 loss = 0.004228 train = 0.998437 valid = 0.827782\n",
            "2022-01-08 08:47:16 - INFO:\ttrain #18440 lr = 1.58e-05 loss = 0.002100 train = 0.999609 valid = 0.824533\n",
            "2022-01-08 08:47:47 - INFO:\ttrain #18460 lr = 1.58e-05 loss = 0.001865 train = 0.999707 valid = 0.825751\n",
            "2022-01-08 08:48:18 - INFO:\ttrain #18480 lr = 1.58e-05 loss = 0.001727 train = 0.999805 valid = 0.823314\n",
            "2022-01-08 08:48:49 - INFO:\ttrain #18500 lr = 1.57e-05 loss = 0.001784 train = 0.999707 valid = 0.826564\n",
            "2022-01-08 08:48:52 - INFO:\tSaved test = 0.816856\n",
            "2022-01-08 08:49:23 - INFO:\ttrain #18520 lr = 1.57e-05 loss = 0.002796 train = 0.999219 valid = 0.825548\n",
            "2022-01-08 08:49:54 - INFO:\ttrain #18540 lr = 1.57e-05 loss = 0.003022 train = 0.999121 valid = 0.826767\n",
            "2022-01-08 08:50:25 - INFO:\ttrain #18560 lr = 1.56e-05 loss = 0.003084 train = 0.999512 valid = 0.823924\n",
            "2022-01-08 08:50:56 - INFO:\ttrain #18580 lr = 1.56e-05 loss = 0.002135 train = 0.999609 valid = 0.826767\n",
            "2022-01-08 08:51:27 - INFO:\ttrain #18600 lr = 1.56e-05 loss = 0.003480 train = 0.999414 valid = 0.826564\n",
            "2022-01-08 08:51:30 - INFO:\tSaved test = 0.814019\n",
            "2022-01-08 08:52:01 - INFO:\ttrain #18620 lr = 1.55e-05 loss = 0.004239 train = 0.998730 valid = 0.824533\n",
            "2022-01-08 08:52:32 - INFO:\ttrain #18640 lr = 1.55e-05 loss = 0.004548 train = 0.998730 valid = 0.823111\n",
            "2022-01-08 08:53:03 - INFO:\ttrain #18660 lr = 1.55e-05 loss = 0.005542 train = 0.998145 valid = 0.822908\n",
            "2022-01-08 08:53:34 - INFO:\ttrain #18680 lr = 1.54e-05 loss = 0.005009 train = 0.998437 valid = 0.821690\n",
            "2022-01-08 08:54:05 - INFO:\ttrain #18700 lr = 1.54e-05 loss = 0.005266 train = 0.998145 valid = 0.822705\n",
            "2022-01-08 08:54:07 - INFO:\tSaved test = 0.815235\n",
            "2022-01-08 08:54:38 - INFO:\ttrain #18720 lr = 1.54e-05 loss = 0.002462 train = 0.999316 valid = 0.823517\n",
            "2022-01-08 08:55:10 - INFO:\ttrain #18740 lr = 1.53e-05 loss = 0.002014 train = 0.999805 valid = 0.825955\n",
            "2022-01-08 08:55:41 - INFO:\ttrain #18760 lr = 1.53e-05 loss = 0.002270 train = 0.999707 valid = 0.823517\n",
            "2022-01-08 08:56:12 - INFO:\ttrain #18780 lr = 1.53e-05 loss = 0.003357 train = 0.999023 valid = 0.823111\n",
            "2022-01-08 08:56:43 - INFO:\ttrain #18800 lr = 1.53e-05 loss = 0.004328 train = 0.998535 valid = 0.825548\n",
            "2022-01-08 08:56:45 - INFO:\tSaved test = 0.812804\n",
            "2022-01-08 08:57:16 - INFO:\ttrain #18820 lr = 1.52e-05 loss = 0.002724 train = 0.999414 valid = 0.827173\n",
            "2022-01-08 08:57:48 - INFO:\ttrain #18840 lr = 1.52e-05 loss = 0.002365 train = 0.999805 valid = 0.825142\n",
            "2022-01-08 08:58:19 - INFO:\ttrain #18860 lr = 1.52e-05 loss = 0.003845 train = 0.998730 valid = 0.821690\n",
            "2022-01-08 08:58:50 - INFO:\ttrain #18880 lr = 1.51e-05 loss = 0.005364 train = 0.998145 valid = 0.824939\n",
            "2022-01-08 08:59:21 - INFO:\ttrain #18900 lr = 1.51e-05 loss = 0.003683 train = 0.998926 valid = 0.825548\n",
            "2022-01-08 08:59:24 - INFO:\tSaved test = 0.811994\n",
            "2022-01-08 08:59:55 - INFO:\ttrain #18920 lr = 1.51e-05 loss = 0.003774 train = 0.999023 valid = 0.821893\n",
            "2022-01-08 09:00:26 - INFO:\ttrain #18940 lr = 1.50e-05 loss = 0.004235 train = 0.998730 valid = 0.825955\n",
            "2022-01-08 09:00:57 - INFO:\ttrain #18960 lr = 1.50e-05 loss = 0.004105 train = 0.998730 valid = 0.822299\n",
            "2022-01-08 09:01:28 - INFO:\ttrain #18980 lr = 1.50e-05 loss = 0.003493 train = 0.999121 valid = 0.829813\n",
            "2022-01-08 09:01:59 - INFO:\ttrain #19000 lr = 1.50e-05 loss = 0.004633 train = 0.999023 valid = 0.829001\n",
            "2022-01-08 09:02:02 - INFO:\tSaved test = 0.819287\n",
            "2022-01-08 09:02:33 - INFO:\ttrain #19020 lr = 1.49e-05 loss = 0.002326 train = 0.999707 valid = 0.824939\n",
            "2022-01-08 09:03:04 - INFO:\ttrain #19040 lr = 1.49e-05 loss = 0.003213 train = 0.998926 valid = 0.827782\n",
            "2022-01-08 09:03:35 - INFO:\ttrain #19060 lr = 1.49e-05 loss = 0.002461 train = 0.999512 valid = 0.824533\n",
            "2022-01-08 09:04:07 - INFO:\ttrain #19080 lr = 1.48e-05 loss = 0.002403 train = 0.999219 valid = 0.827782\n",
            "2022-01-08 09:04:38 - INFO:\ttrain #19100 lr = 1.48e-05 loss = 0.003715 train = 0.998828 valid = 0.824939\n",
            "2022-01-08 09:04:40 - INFO:\tSaved test = 0.807536\n",
            "2022-01-08 09:05:11 - INFO:\ttrain #19120 lr = 1.48e-05 loss = 0.001679 train = 0.999707 valid = 0.830829\n",
            "2022-01-08 09:05:42 - INFO:\ttrain #19140 lr = 1.47e-05 loss = 0.002693 train = 0.999219 valid = 0.821893\n",
            "2022-01-08 09:06:13 - INFO:\ttrain #19160 lr = 1.47e-05 loss = 0.004097 train = 0.999023 valid = 0.819050\n",
            "2022-01-08 09:06:45 - INFO:\ttrain #19180 lr = 1.47e-05 loss = 0.002673 train = 0.999512 valid = 0.827985\n",
            "2022-01-08 09:07:16 - INFO:\ttrain #19200 lr = 1.47e-05 loss = 0.003162 train = 0.999414 valid = 0.825548\n",
            "2022-01-08 09:07:18 - INFO:\tSaved test = 0.811183\n",
            "2022-01-08 09:07:49 - INFO:\ttrain #19220 lr = 1.46e-05 loss = 0.003194 train = 0.999219 valid = 0.826158\n",
            "2022-01-08 09:08:20 - INFO:\ttrain #19240 lr = 1.46e-05 loss = 0.003806 train = 0.998730 valid = 0.821690\n",
            "2022-01-08 09:08:52 - INFO:\ttrain #19260 lr = 1.46e-05 loss = 0.003512 train = 0.998828 valid = 0.830016\n",
            "2022-01-08 09:09:22 - INFO:\ttrain #19280 lr = 1.45e-05 loss = 0.002986 train = 0.999121 valid = 0.826970\n",
            "2022-01-08 09:09:54 - INFO:\ttrain #19300 lr = 1.45e-05 loss = 0.003002 train = 0.999414 valid = 0.832656 updated\n",
            "2022-01-08 09:09:56 - INFO:\tSaved test = 0.818071\n",
            "2022-01-08 09:10:27 - INFO:\ttrain #19320 lr = 1.45e-05 loss = 0.002201 train = 0.999414 valid = 0.828188\n",
            "2022-01-08 09:10:58 - INFO:\ttrain #19340 lr = 1.45e-05 loss = 0.002078 train = 0.999609 valid = 0.828392\n",
            "2022-01-08 09:11:30 - INFO:\ttrain #19360 lr = 1.44e-05 loss = 0.002045 train = 0.999609 valid = 0.828798\n",
            "2022-01-08 09:12:01 - INFO:\ttrain #19380 lr = 1.44e-05 loss = 0.002686 train = 0.999316 valid = 0.826361\n",
            "2022-01-08 09:12:32 - INFO:\ttrain #19400 lr = 1.44e-05 loss = 0.005800 train = 0.997656 valid = 0.818643\n",
            "2022-01-08 09:12:34 - INFO:\tSaved test = 0.810778\n",
            "2022-01-08 09:13:06 - INFO:\ttrain #19420 lr = 1.43e-05 loss = 0.003705 train = 0.999023 valid = 0.823721\n",
            "2022-01-08 09:13:37 - INFO:\ttrain #19440 lr = 1.43e-05 loss = 0.002762 train = 0.999316 valid = 0.823924\n",
            "2022-01-08 09:14:08 - INFO:\ttrain #19460 lr = 1.43e-05 loss = 0.003720 train = 0.998926 valid = 0.823314\n",
            "2022-01-08 09:14:39 - INFO:\ttrain #19480 lr = 1.43e-05 loss = 0.003011 train = 0.999023 valid = 0.823924\n",
            "2022-01-08 09:15:10 - INFO:\ttrain #19500 lr = 1.42e-05 loss = 0.002293 train = 0.999414 valid = 0.821893\n",
            "2022-01-08 09:15:13 - INFO:\tSaved test = 0.810373\n",
            "2022-01-08 09:15:44 - INFO:\ttrain #19520 lr = 1.42e-05 loss = 0.003492 train = 0.998633 valid = 0.820471\n",
            "2022-01-08 09:16:15 - INFO:\ttrain #19540 lr = 1.42e-05 loss = 0.002765 train = 0.999316 valid = 0.820674\n",
            "2022-01-08 09:16:46 - INFO:\ttrain #19560 lr = 1.41e-05 loss = 0.002438 train = 0.999023 valid = 0.823111\n",
            "2022-01-08 09:17:17 - INFO:\ttrain #19580 lr = 1.41e-05 loss = 0.004106 train = 0.998828 valid = 0.824127\n",
            "2022-01-08 09:17:48 - INFO:\ttrain #19600 lr = 1.41e-05 loss = 0.001645 train = 0.999609 valid = 0.823517\n",
            "2022-01-08 09:17:51 - INFO:\tSaved test = 0.816856\n",
            "2022-01-08 09:18:22 - INFO:\ttrain #19620 lr = 1.41e-05 loss = 0.002494 train = 0.999316 valid = 0.823924\n",
            "2022-01-08 09:18:53 - INFO:\ttrain #19640 lr = 1.40e-05 loss = 0.002815 train = 0.999219 valid = 0.823924\n",
            "2022-01-08 09:19:24 - INFO:\ttrain #19660 lr = 1.40e-05 loss = 0.003078 train = 0.999219 valid = 0.823517\n",
            "2022-01-08 09:19:55 - INFO:\ttrain #19680 lr = 1.40e-05 loss = 0.003485 train = 0.998828 valid = 0.824127\n",
            "2022-01-08 09:20:26 - INFO:\ttrain #19700 lr = 1.39e-05 loss = 0.002955 train = 0.999414 valid = 0.823111\n",
            "2022-01-08 09:20:28 - INFO:\tSaved test = 0.819692\n",
            "2022-01-08 09:21:00 - INFO:\ttrain #19720 lr = 1.39e-05 loss = 0.003134 train = 0.999121 valid = 0.822299\n",
            "2022-01-08 09:21:31 - INFO:\ttrain #19740 lr = 1.39e-05 loss = 0.002033 train = 0.999512 valid = 0.824736\n",
            "2022-01-08 09:22:02 - INFO:\ttrain #19760 lr = 1.39e-05 loss = 0.002854 train = 0.999023 valid = 0.827376\n",
            "2022-01-08 09:22:33 - INFO:\ttrain #19780 lr = 1.38e-05 loss = 0.002992 train = 0.999219 valid = 0.825142\n",
            "2022-01-08 09:23:04 - INFO:\ttrain #19800 lr = 1.38e-05 loss = 0.002811 train = 0.999414 valid = 0.824939\n",
            "2022-01-08 09:23:07 - INFO:\tSaved test = 0.811994\n",
            "2022-01-08 09:23:38 - INFO:\ttrain #19820 lr = 1.38e-05 loss = 0.001572 train = 0.999707 valid = 0.826970\n",
            "2022-01-08 09:24:09 - INFO:\ttrain #19840 lr = 1.38e-05 loss = 0.004056 train = 0.998730 valid = 0.821080\n",
            "2022-01-08 09:24:40 - INFO:\ttrain #19860 lr = 1.37e-05 loss = 0.002556 train = 0.999121 valid = 0.825142\n",
            "2022-01-08 09:25:11 - INFO:\ttrain #19880 lr = 1.37e-05 loss = 0.002375 train = 0.999316 valid = 0.821893\n",
            "2022-01-08 09:25:42 - INFO:\ttrain #19900 lr = 1.37e-05 loss = 0.001348 train = 0.999805 valid = 0.827376\n",
            "2022-01-08 09:25:44 - INFO:\tSaved test = 0.813209\n",
            "2022-01-08 09:26:15 - INFO:\ttrain #19920 lr = 1.36e-05 loss = 0.002135 train = 0.999512 valid = 0.829001\n",
            "2022-01-08 09:26:46 - INFO:\ttrain #19940 lr = 1.36e-05 loss = 0.001894 train = 0.999707 valid = 0.830219\n",
            "2022-01-08 09:27:18 - INFO:\ttrain #19960 lr = 1.36e-05 loss = 0.002640 train = 0.999316 valid = 0.828188\n",
            "2022-01-08 09:27:49 - INFO:\ttrain #19980 lr = 1.36e-05 loss = 0.002979 train = 0.999414 valid = 0.827376\n",
            "2022-01-08 09:28:20 - INFO:\ttrain #20000 lr = 1.35e-05 loss = 0.002357 train = 0.999414 valid = 0.827985\n",
            "2022-01-08 09:28:22 - INFO:\tSaved test = 0.813209\n",
            "2022-01-08 09:28:53 - INFO:\ttrain #20020 lr = 1.35e-05 loss = 0.005252 train = 0.998340 valid = 0.825142\n",
            "2022-01-08 09:29:25 - INFO:\ttrain #20040 lr = 1.35e-05 loss = 0.003415 train = 0.998828 valid = 0.828595\n",
            "2022-01-08 09:29:56 - INFO:\ttrain #20060 lr = 1.35e-05 loss = 0.003131 train = 0.999121 valid = 0.826361\n",
            "2022-01-08 09:30:27 - INFO:\ttrain #20080 lr = 1.34e-05 loss = 0.002391 train = 0.999316 valid = 0.831844\n",
            "2022-01-08 09:30:57 - INFO:\ttrain #20100 lr = 1.34e-05 loss = 0.001685 train = 0.999609 valid = 0.829001\n",
            "2022-01-08 09:31:00 - INFO:\tSaved test = 0.811183\n",
            "2022-01-08 09:31:31 - INFO:\ttrain #20120 lr = 1.34e-05 loss = 0.001884 train = 0.999805 valid = 0.831032\n",
            "2022-01-08 09:32:02 - INFO:\ttrain #20140 lr = 1.33e-05 loss = 0.002184 train = 0.999316 valid = 0.821690\n",
            "2022-01-08 09:32:33 - INFO:\ttrain #20160 lr = 1.33e-05 loss = 0.003152 train = 0.998828 valid = 0.825751\n",
            "2022-01-08 09:33:04 - INFO:\ttrain #20180 lr = 1.33e-05 loss = 0.002425 train = 0.999219 valid = 0.824533\n",
            "2022-01-08 09:33:35 - INFO:\ttrain #20200 lr = 1.33e-05 loss = 0.002479 train = 0.999512 valid = 0.827376\n",
            "2022-01-08 09:33:38 - INFO:\tSaved test = 0.811588\n",
            "2022-01-08 09:34:09 - INFO:\ttrain #20220 lr = 1.32e-05 loss = 0.002973 train = 0.999121 valid = 0.827985\n",
            "2022-01-08 09:34:40 - INFO:\ttrain #20240 lr = 1.32e-05 loss = 0.002937 train = 0.998926 valid = 0.830829\n",
            "2022-01-08 09:35:11 - INFO:\ttrain #20260 lr = 1.32e-05 loss = 0.002330 train = 0.999414 valid = 0.827579\n",
            "2022-01-08 09:35:42 - INFO:\ttrain #20280 lr = 1.32e-05 loss = 0.002390 train = 0.999121 valid = 0.825548\n",
            "2022-01-08 09:36:14 - INFO:\ttrain #20300 lr = 1.31e-05 loss = 0.002665 train = 0.999219 valid = 0.826970\n",
            "2022-01-08 09:36:16 - INFO:\tSaved test = 0.811994\n",
            "2022-01-08 09:36:47 - INFO:\ttrain #20320 lr = 1.31e-05 loss = 0.003370 train = 0.999023 valid = 0.827173\n",
            "2022-01-08 09:37:18 - INFO:\ttrain #20340 lr = 1.31e-05 loss = 0.005414 train = 0.997949 valid = 0.824736\n",
            "2022-01-08 09:37:49 - INFO:\ttrain #20360 lr = 1.31e-05 loss = 0.002091 train = 0.999707 valid = 0.827579\n",
            "2022-01-08 09:38:21 - INFO:\ttrain #20380 lr = 1.30e-05 loss = 0.003163 train = 0.999219 valid = 0.825955\n",
            "2022-01-08 09:38:52 - INFO:\ttrain #20400 lr = 1.30e-05 loss = 0.003008 train = 0.999121 valid = 0.821080\n",
            "2022-01-08 09:38:54 - INFO:\tSaved test = 0.813614\n",
            "2022-01-08 09:39:25 - INFO:\ttrain #20420 lr = 1.30e-05 loss = 0.001820 train = 0.999609 valid = 0.827173\n",
            "2022-01-08 09:39:57 - INFO:\ttrain #20440 lr = 1.29e-05 loss = 0.002539 train = 0.999121 valid = 0.825142\n",
            "2022-01-08 09:40:28 - INFO:\ttrain #20460 lr = 1.29e-05 loss = 0.002143 train = 0.999121 valid = 0.828188\n",
            "2022-01-08 09:40:59 - INFO:\ttrain #20480 lr = 1.29e-05 loss = 0.001360 train = 0.999902 valid = 0.826564\n",
            "2022-01-08 09:41:30 - INFO:\ttrain #20500 lr = 1.29e-05 loss = 0.002129 train = 0.999316 valid = 0.823721\n",
            "2022-01-08 09:41:32 - INFO:\tSaved test = 0.810778\n",
            "2022-01-08 09:42:03 - INFO:\ttrain #20520 lr = 1.28e-05 loss = 0.002307 train = 0.999414 valid = 0.826158\n",
            "2022-01-08 09:42:35 - INFO:\ttrain #20540 lr = 1.28e-05 loss = 0.001569 train = 0.999609 valid = 0.824736\n",
            "2022-01-08 09:43:06 - INFO:\ttrain #20560 lr = 1.28e-05 loss = 0.001767 train = 0.999512 valid = 0.826970\n",
            "2022-01-08 09:43:37 - INFO:\ttrain #20580 lr = 1.28e-05 loss = 0.003255 train = 0.998633 valid = 0.825955\n",
            "2022-01-08 09:44:08 - INFO:\ttrain #20600 lr = 1.27e-05 loss = 0.002310 train = 0.999512 valid = 0.825548\n",
            "2022-01-08 09:44:10 - INFO:\tSaved test = 0.813209\n",
            "2022-01-08 09:44:41 - INFO:\ttrain #20620 lr = 1.27e-05 loss = 0.002675 train = 0.999316 valid = 0.825345\n",
            "2022-01-08 09:45:13 - INFO:\ttrain #20640 lr = 1.27e-05 loss = 0.002203 train = 0.999219 valid = 0.826158\n",
            "2022-01-08 09:45:44 - INFO:\ttrain #20660 lr = 1.27e-05 loss = 0.002090 train = 0.999512 valid = 0.825548\n",
            "2022-01-08 09:46:15 - INFO:\ttrain #20680 lr = 1.26e-05 loss = 0.003640 train = 0.998926 valid = 0.822908\n",
            "2022-01-08 09:46:46 - INFO:\ttrain #20700 lr = 1.26e-05 loss = 0.003578 train = 0.998828 valid = 0.822096\n",
            "2022-01-08 09:46:48 - INFO:\tSaved test = 0.818476\n",
            "2022-01-08 09:47:20 - INFO:\ttrain #20720 lr = 1.26e-05 loss = 0.003967 train = 0.998633 valid = 0.827173\n",
            "2022-01-08 09:47:51 - INFO:\ttrain #20740 lr = 1.26e-05 loss = 0.001760 train = 0.999512 valid = 0.827782\n",
            "2022-01-08 09:48:22 - INFO:\ttrain #20760 lr = 1.25e-05 loss = 0.003294 train = 0.998926 valid = 0.827985\n",
            "2022-01-08 09:48:53 - INFO:\ttrain #20780 lr = 1.25e-05 loss = 0.002197 train = 0.999512 valid = 0.826970\n",
            "2022-01-08 09:49:24 - INFO:\ttrain #20800 lr = 1.25e-05 loss = 0.003312 train = 0.998730 valid = 0.825548\n",
            "2022-01-08 09:49:26 - INFO:\tSaved test = 0.822934\n",
            "2022-01-08 09:49:57 - INFO:\ttrain #20820 lr = 1.25e-05 loss = 0.003579 train = 0.998926 valid = 0.822908\n",
            "2022-01-08 09:50:29 - INFO:\ttrain #20840 lr = 1.24e-05 loss = 0.003053 train = 0.998828 valid = 0.826158\n",
            "2022-01-08 09:51:00 - INFO:\ttrain #20860 lr = 1.24e-05 loss = 0.001662 train = 0.999707 valid = 0.827579\n",
            "2022-01-08 09:51:31 - INFO:\ttrain #20880 lr = 1.24e-05 loss = 0.001918 train = 0.999512 valid = 0.824127\n",
            "2022-01-08 09:52:02 - INFO:\ttrain #20900 lr = 1.24e-05 loss = 0.001951 train = 0.999609 valid = 0.824533\n",
            "2022-01-08 09:52:04 - INFO:\tSaved test = 0.814019\n",
            "2022-01-08 09:52:36 - INFO:\ttrain #20920 lr = 1.23e-05 loss = 0.002304 train = 0.999121 valid = 0.824127\n",
            "2022-01-08 09:53:06 - INFO:\ttrain #20940 lr = 1.23e-05 loss = 0.004110 train = 0.998730 valid = 0.825142\n",
            "2022-01-08 09:53:37 - INFO:\ttrain #20960 lr = 1.23e-05 loss = 0.002150 train = 0.999609 valid = 0.827173\n",
            "2022-01-08 09:54:09 - INFO:\ttrain #20980 lr = 1.23e-05 loss = 0.001501 train = 0.999609 valid = 0.824533\n",
            "2022-01-08 09:54:40 - INFO:\ttrain #21000 lr = 1.22e-05 loss = 0.002255 train = 0.999316 valid = 0.825142\n",
            "2022-01-08 09:54:42 - INFO:\tSaved test = 0.821718\n",
            "2022-01-08 09:55:12 - INFO:\ttrain #21020 lr = 1.22e-05 loss = 0.002451 train = 0.999219 valid = 0.829204\n",
            "2022-01-08 09:55:44 - INFO:\ttrain #21040 lr = 1.22e-05 loss = 0.003687 train = 0.998730 valid = 0.822705\n",
            "2022-01-08 09:56:15 - INFO:\ttrain #21060 lr = 1.22e-05 loss = 0.002759 train = 0.998828 valid = 0.823314\n",
            "2022-01-08 09:56:46 - INFO:\ttrain #21080 lr = 1.21e-05 loss = 0.002773 train = 0.999219 valid = 0.821487\n",
            "2022-01-08 09:57:17 - INFO:\ttrain #21100 lr = 1.21e-05 loss = 0.002151 train = 0.999316 valid = 0.820674\n",
            "2022-01-08 09:57:19 - INFO:\tSaved test = 0.812804\n",
            "2022-01-08 09:57:51 - INFO:\ttrain #21120 lr = 1.21e-05 loss = 0.002613 train = 0.999121 valid = 0.824736\n",
            "2022-01-08 09:58:22 - INFO:\ttrain #21140 lr = 1.21e-05 loss = 0.001281 train = 0.999707 valid = 0.831235\n",
            "2022-01-08 09:58:53 - INFO:\ttrain #21160 lr = 1.20e-05 loss = 0.001777 train = 0.999707 valid = 0.825345\n",
            "2022-01-08 09:59:24 - INFO:\ttrain #21180 lr = 1.20e-05 loss = 0.001787 train = 0.999609 valid = 0.826564\n",
            "2022-01-08 09:59:55 - INFO:\ttrain #21200 lr = 1.20e-05 loss = 0.001573 train = 0.999609 valid = 0.825955\n",
            "2022-01-08 09:59:58 - INFO:\tSaved test = 0.818071\n",
            "2022-01-08 10:00:29 - INFO:\ttrain #21220 lr = 1.20e-05 loss = 0.001584 train = 0.999609 valid = 0.829610\n",
            "2022-01-08 10:01:00 - INFO:\ttrain #21240 lr = 1.20e-05 loss = 0.001373 train = 0.999805 valid = 0.827985\n",
            "2022-01-08 10:01:31 - INFO:\ttrain #21260 lr = 1.19e-05 loss = 0.001354 train = 0.999707 valid = 0.824736\n",
            "2022-01-08 10:02:03 - INFO:\ttrain #21280 lr = 1.19e-05 loss = 0.002865 train = 0.999316 valid = 0.824939\n",
            "2022-01-08 10:02:34 - INFO:\ttrain #21300 lr = 1.19e-05 loss = 0.002050 train = 0.999609 valid = 0.824330\n",
            "2022-01-08 10:02:36 - INFO:\tSaved test = 0.817261\n",
            "2022-01-08 10:03:07 - INFO:\ttrain #21320 lr = 1.19e-05 loss = 0.002858 train = 0.999023 valid = 0.824939\n",
            "2022-01-08 10:03:38 - INFO:\ttrain #21340 lr = 1.18e-05 loss = 0.001992 train = 0.999707 valid = 0.826564\n",
            "2022-01-08 10:04:09 - INFO:\ttrain #21360 lr = 1.18e-05 loss = 0.002497 train = 0.999121 valid = 0.824330\n",
            "2022-01-08 10:04:40 - INFO:\ttrain #21380 lr = 1.18e-05 loss = 0.001685 train = 0.999609 valid = 0.824533\n",
            "2022-01-08 10:05:12 - INFO:\ttrain #21400 lr = 1.18e-05 loss = 0.001683 train = 0.999609 valid = 0.827782\n",
            "2022-01-08 10:05:14 - INFO:\tSaved test = 0.817261\n",
            "2022-01-08 10:05:45 - INFO:\ttrain #21420 lr = 1.17e-05 loss = 0.002265 train = 0.999316 valid = 0.829204\n",
            "2022-01-08 10:06:16 - INFO:\ttrain #21440 lr = 1.17e-05 loss = 0.002682 train = 0.999414 valid = 0.825345\n",
            "2022-01-08 10:06:47 - INFO:\ttrain #21460 lr = 1.17e-05 loss = 0.002207 train = 0.999121 valid = 0.823111\n",
            "2022-01-08 10:07:19 - INFO:\ttrain #21480 lr = 1.17e-05 loss = 0.002527 train = 0.999316 valid = 0.825751\n",
            "2022-01-08 10:07:50 - INFO:\ttrain #21500 lr = 1.16e-05 loss = 0.003047 train = 0.998926 valid = 0.822705\n",
            "2022-01-08 10:07:52 - INFO:\tSaved test = 0.816856\n",
            "2022-01-08 10:08:23 - INFO:\ttrain #21520 lr = 1.16e-05 loss = 0.002271 train = 0.999121 valid = 0.820268\n",
            "2022-01-08 10:08:54 - INFO:\ttrain #21540 lr = 1.16e-05 loss = 0.003227 train = 0.998926 valid = 0.825751\n",
            "2022-01-08 10:09:25 - INFO:\ttrain #21560 lr = 1.16e-05 loss = 0.001908 train = 0.999316 valid = 0.820065\n",
            "2022-01-08 10:09:57 - INFO:\ttrain #21580 lr = 1.16e-05 loss = 0.001194 train = 0.999902 valid = 0.822705\n",
            "2022-01-08 10:10:28 - INFO:\ttrain #21600 lr = 1.15e-05 loss = 0.001526 train = 0.999805 valid = 0.822908\n",
            "2022-01-08 10:10:30 - INFO:\tSaved test = 0.816451\n",
            "2022-01-08 10:11:01 - INFO:\ttrain #21620 lr = 1.15e-05 loss = 0.001943 train = 0.999609 valid = 0.826767\n",
            "2022-01-08 10:11:32 - INFO:\ttrain #21640 lr = 1.15e-05 loss = 0.002225 train = 0.999512 valid = 0.825345\n",
            "2022-01-08 10:12:04 - INFO:\ttrain #21660 lr = 1.15e-05 loss = 0.002073 train = 0.999316 valid = 0.828392\n",
            "2022-01-08 10:12:35 - INFO:\ttrain #21680 lr = 1.14e-05 loss = 0.002247 train = 0.999414 valid = 0.823314\n",
            "2022-01-08 10:13:06 - INFO:\ttrain #21700 lr = 1.14e-05 loss = 0.002331 train = 0.999414 valid = 0.822096\n",
            "2022-01-08 10:13:08 - INFO:\tSaved test = 0.820097\n",
            "2022-01-08 10:13:40 - INFO:\ttrain #21720 lr = 1.14e-05 loss = 0.001466 train = 0.999707 valid = 0.824736\n",
            "2022-01-08 10:14:11 - INFO:\ttrain #21740 lr = 1.14e-05 loss = 0.001723 train = 0.999414 valid = 0.827173\n",
            "2022-01-08 10:14:42 - INFO:\ttrain #21760 lr = 1.13e-05 loss = 0.001343 train = 0.999609 valid = 0.824330\n",
            "2022-01-08 10:15:13 - INFO:\ttrain #21780 lr = 1.13e-05 loss = 0.001109 train = 0.999805 valid = 0.828392\n",
            "2022-01-08 10:15:44 - INFO:\ttrain #21800 lr = 1.13e-05 loss = 0.001725 train = 0.999512 valid = 0.827173\n",
            "2022-01-08 10:15:47 - INFO:\tSaved test = 0.814019\n",
            "2022-01-08 10:16:18 - INFO:\ttrain #21820 lr = 1.13e-05 loss = 0.001105 train = 0.999902 valid = 0.827173\n",
            "2022-01-08 10:16:49 - INFO:\ttrain #21840 lr = 1.13e-05 loss = 0.001813 train = 0.999414 valid = 0.823721\n",
            "2022-01-08 10:17:20 - INFO:\ttrain #21860 lr = 1.12e-05 loss = 0.001983 train = 0.999414 valid = 0.824127\n",
            "2022-01-08 10:17:51 - INFO:\ttrain #21880 lr = 1.12e-05 loss = 0.002639 train = 0.999121 valid = 0.826970\n",
            "2022-01-08 10:18:22 - INFO:\ttrain #21900 lr = 1.12e-05 loss = 0.001917 train = 0.999414 valid = 0.826361\n",
            "2022-01-08 10:18:25 - INFO:\tSaved test = 0.825365\n",
            "2022-01-08 10:18:56 - INFO:\ttrain #21920 lr = 1.12e-05 loss = 0.002067 train = 0.999414 valid = 0.827985\n",
            "2022-01-08 10:19:27 - INFO:\ttrain #21940 lr = 1.11e-05 loss = 0.002759 train = 0.999121 valid = 0.826158\n",
            "2022-01-08 10:19:58 - INFO:\ttrain #21960 lr = 1.11e-05 loss = 0.001114 train = 0.999902 valid = 0.827579\n",
            "2022-01-08 10:20:30 - INFO:\ttrain #21980 lr = 1.11e-05 loss = 0.001590 train = 0.999512 valid = 0.829610\n",
            "2022-01-08 10:21:01 - INFO:\ttrain #22000 lr = 1.11e-05 loss = 0.002550 train = 0.999023 valid = 0.827173\n",
            "2022-01-08 10:21:03 - INFO:\tSaved test = 0.816451\n",
            "2022-01-08 10:21:34 - INFO:\ttrain #22020 lr = 1.11e-05 loss = 0.001216 train = 0.999902 valid = 0.828798\n",
            "2022-01-08 10:22:06 - INFO:\ttrain #22040 lr = 1.10e-05 loss = 0.003481 train = 0.998730 valid = 0.825345\n",
            "2022-01-08 10:22:37 - INFO:\ttrain #22060 lr = 1.10e-05 loss = 0.003010 train = 0.999121 valid = 0.824939\n",
            "2022-01-08 10:23:08 - INFO:\ttrain #22080 lr = 1.10e-05 loss = 0.002665 train = 0.998828 valid = 0.822908\n",
            "2022-01-08 10:23:39 - INFO:\ttrain #22100 lr = 1.10e-05 loss = 0.001962 train = 0.999512 valid = 0.831235\n",
            "2022-01-08 10:23:41 - INFO:\tSaved test = 0.814425\n",
            "2022-01-08 10:24:12 - INFO:\ttrain #22120 lr = 1.09e-05 loss = 0.001137 train = 0.999805 valid = 0.827782\n",
            "2022-01-08 10:24:44 - INFO:\ttrain #22140 lr = 1.09e-05 loss = 0.001192 train = 0.999805 valid = 0.825345\n",
            "2022-01-08 10:25:15 - INFO:\ttrain #22160 lr = 1.09e-05 loss = 0.001927 train = 0.999512 valid = 0.826767\n",
            "2022-01-08 10:25:46 - INFO:\ttrain #22180 lr = 1.09e-05 loss = 0.002095 train = 0.999609 valid = 0.825345\n",
            "2022-01-08 10:26:17 - INFO:\ttrain #22200 lr = 1.09e-05 loss = 0.001867 train = 0.999414 valid = 0.827173\n",
            "2022-01-08 10:26:19 - INFO:\tSaved test = 0.816856\n",
            "2022-01-08 10:26:50 - INFO:\ttrain #22220 lr = 1.08e-05 loss = 0.001707 train = 0.999512 valid = 0.824939\n",
            "2022-01-08 10:27:21 - INFO:\ttrain #22240 lr = 1.08e-05 loss = 0.002432 train = 0.999219 valid = 0.826361\n",
            "2022-01-08 10:27:52 - INFO:\ttrain #22260 lr = 1.08e-05 loss = 0.002508 train = 0.999023 valid = 0.827579\n",
            "2022-01-08 10:28:23 - INFO:\ttrain #22280 lr = 1.08e-05 loss = 0.002160 train = 0.999414 valid = 0.825955\n",
            "2022-01-08 10:28:55 - INFO:\ttrain #22300 lr = 1.08e-05 loss = 0.002207 train = 0.999512 valid = 0.825955\n",
            "2022-01-08 10:28:57 - INFO:\tSaved test = 0.815235\n",
            "2022-01-08 10:29:28 - INFO:\ttrain #22320 lr = 1.07e-05 loss = 0.001089 train = 0.999707 valid = 0.830626\n",
            "2022-01-08 10:29:59 - INFO:\ttrain #22340 lr = 1.07e-05 loss = 0.000874 train = 0.999902 valid = 0.828392\n",
            "2022-01-08 10:30:30 - INFO:\ttrain #22360 lr = 1.07e-05 loss = 0.001203 train = 0.999805 valid = 0.829407\n",
            "2022-01-08 10:31:02 - INFO:\ttrain #22380 lr = 1.07e-05 loss = 0.001429 train = 0.999707 valid = 0.827782\n",
            "2022-01-08 10:31:33 - INFO:\ttrain #22400 lr = 1.06e-05 loss = 0.001918 train = 0.999316 valid = 0.826158\n",
            "2022-01-08 10:31:35 - INFO:\tSaved test = 0.807536\n",
            "2022-01-08 10:32:06 - INFO:\ttrain #22420 lr = 1.06e-05 loss = 0.003285 train = 0.999121 valid = 0.824533\n",
            "2022-01-08 10:32:37 - INFO:\ttrain #22440 lr = 1.06e-05 loss = 0.002275 train = 0.999219 valid = 0.825751\n",
            "2022-01-08 10:33:09 - INFO:\ttrain #22460 lr = 1.06e-05 loss = 0.002418 train = 0.999219 valid = 0.826564\n",
            "2022-01-08 10:33:39 - INFO:\ttrain #22480 lr = 1.06e-05 loss = 0.002479 train = 0.999316 valid = 0.824736\n",
            "2022-01-08 10:34:11 - INFO:\ttrain #22500 lr = 1.05e-05 loss = 0.002273 train = 0.999219 valid = 0.825751\n",
            "2022-01-08 10:34:13 - INFO:\tSaved test = 0.817261\n",
            "2022-01-08 10:34:44 - INFO:\ttrain #22520 lr = 1.05e-05 loss = 0.001889 train = 0.999219 valid = 0.827985\n",
            "2022-01-08 10:35:15 - INFO:\ttrain #22540 lr = 1.05e-05 loss = 0.000861 train = 0.999902 valid = 0.826767\n",
            "2022-01-08 10:35:47 - INFO:\ttrain #22560 lr = 1.05e-05 loss = 0.002990 train = 0.998926 valid = 0.824127\n",
            "2022-01-08 10:36:18 - INFO:\ttrain #22580 lr = 1.05e-05 loss = 0.001299 train = 0.999707 valid = 0.824330\n",
            "2022-01-08 10:36:49 - INFO:\ttrain #22600 lr = 1.04e-05 loss = 0.002319 train = 0.999121 valid = 0.827579\n",
            "2022-01-08 10:36:51 - INFO:\tSaved test = 0.810778\n",
            "2022-01-08 10:37:22 - INFO:\ttrain #22620 lr = 1.04e-05 loss = 0.002020 train = 0.999414 valid = 0.830219\n",
            "2022-01-08 10:37:54 - INFO:\ttrain #22640 lr = 1.04e-05 loss = 0.000737 train = 0.999805 valid = 0.826767\n",
            "2022-01-08 10:38:25 - INFO:\ttrain #22660 lr = 1.04e-05 loss = 0.000753 train = 0.999902 valid = 0.827985\n",
            "2022-01-08 10:38:56 - INFO:\ttrain #22680 lr = 1.04e-05 loss = 0.000897 train = 0.999707 valid = 0.827579\n",
            "2022-01-08 10:39:27 - INFO:\ttrain #22700 lr = 1.03e-05 loss = 0.001222 train = 0.999707 valid = 0.827579\n",
            "2022-01-08 10:39:29 - INFO:\tSaved test = 0.815235\n",
            "2022-01-08 10:40:00 - INFO:\ttrain #22720 lr = 1.03e-05 loss = 0.000725 train = 0.999805 valid = 0.825548\n",
            "2022-01-08 10:40:31 - INFO:\ttrain #22740 lr = 1.03e-05 loss = 0.000844 train = 0.999805 valid = 0.824533\n",
            "2022-01-08 10:41:03 - INFO:\ttrain #22760 lr = 1.03e-05 loss = 0.001409 train = 0.999609 valid = 0.825751\n",
            "2022-01-08 10:41:34 - INFO:\ttrain #22780 lr = 1.02e-05 loss = 0.001313 train = 0.999707 valid = 0.829407\n",
            "2022-01-08 10:42:05 - INFO:\ttrain #22800 lr = 1.02e-05 loss = 0.001991 train = 0.999219 valid = 0.823517\n",
            "2022-01-08 10:42:07 - INFO:\tSaved test = 0.814019\n",
            "2022-01-08 10:42:38 - INFO:\ttrain #22820 lr = 1.02e-05 loss = 0.002486 train = 0.999316 valid = 0.825751\n",
            "2022-01-08 10:43:09 - INFO:\ttrain #22840 lr = 1.02e-05 loss = 0.002308 train = 0.999316 valid = 0.823721\n",
            "2022-01-08 10:43:41 - INFO:\ttrain #22860 lr = 1.02e-05 loss = 0.002700 train = 0.999414 valid = 0.825142\n",
            "2022-01-08 10:44:12 - INFO:\ttrain #22880 lr = 1.01e-05 loss = 0.000614 train = 1.000000 valid = 0.826361\n",
            "2022-01-08 10:44:43 - INFO:\ttrain #22900 lr = 1.01e-05 loss = 0.000788 train = 0.999902 valid = 0.819456\n",
            "2022-01-08 10:44:45 - INFO:\tSaved test = 0.816856\n",
            "2022-01-08 10:45:17 - INFO:\ttrain #22920 lr = 1.01e-05 loss = 0.000644 train = 1.000000 valid = 0.822502\n",
            "2022-01-08 10:45:48 - INFO:\ttrain #22940 lr = 1.01e-05 loss = 0.000947 train = 0.999805 valid = 0.826158\n",
            "2022-01-08 10:46:19 - INFO:\ttrain #22960 lr = 1.01e-05 loss = 0.002231 train = 0.999414 valid = 0.821690\n",
            "2022-01-08 10:46:50 - INFO:\ttrain #22980 lr = 1.00e-05 loss = 0.000891 train = 0.999902 valid = 0.822705\n",
            "2022-01-08 10:47:21 - INFO:\ttrain #23000 lr = 1.00e-05 loss = 0.000623 train = 0.999902 valid = 0.825955\n",
            "2022-01-08 10:47:24 - INFO:\tSaved test = 0.817261\n",
            "2022-01-08 10:47:55 - INFO:\ttrain #23020 lr = 1.00e-05 loss = 0.001213 train = 0.999609 valid = 0.824533\n",
            "2022-01-08 10:48:26 - INFO:\ttrain #23040 lr = 9.98e-06 loss = 0.001698 train = 0.999609 valid = 0.823721\n",
            "2022-01-08 10:48:57 - INFO:\ttrain #23060 lr = 9.96e-06 loss = 0.002195 train = 0.999219 valid = 0.825142\n",
            "2022-01-08 10:49:28 - INFO:\ttrain #23080 lr = 9.94e-06 loss = 0.001157 train = 0.999805 valid = 0.827782\n",
            "2022-01-08 10:49:59 - INFO:\ttrain #23100 lr = 9.92e-06 loss = 0.002404 train = 0.999219 valid = 0.827579\n",
            "2022-01-08 10:50:02 - INFO:\tSaved test = 0.816856\n",
            "2022-01-08 10:50:33 - INFO:\ttrain #23120 lr = 9.91e-06 loss = 0.001965 train = 0.999512 valid = 0.830219\n",
            "2022-01-08 10:51:04 - INFO:\ttrain #23140 lr = 9.89e-06 loss = 0.001446 train = 0.999512 valid = 0.827782\n",
            "2022-01-08 10:51:35 - INFO:\ttrain #23160 lr = 9.87e-06 loss = 0.001301 train = 0.999512 valid = 0.827376\n",
            "2022-01-08 10:52:07 - INFO:\ttrain #23180 lr = 9.85e-06 loss = 0.001941 train = 0.999316 valid = 0.820065\n",
            "2022-01-08 10:52:38 - INFO:\ttrain #23200 lr = 9.83e-06 loss = 0.001036 train = 0.999805 valid = 0.826767\n",
            "2022-01-08 10:52:40 - INFO:\tSaved test = 0.818882\n",
            "2022-01-08 10:53:11 - INFO:\ttrain #23220 lr = 9.81e-06 loss = 0.002105 train = 0.999512 valid = 0.827376\n",
            "2022-01-08 10:53:42 - INFO:\ttrain #23240 lr = 9.79e-06 loss = 0.001051 train = 0.999902 valid = 0.828188\n",
            "2022-01-08 10:54:14 - INFO:\ttrain #23260 lr = 9.77e-06 loss = 0.000827 train = 0.999805 valid = 0.827579\n",
            "2022-01-08 10:54:45 - INFO:\ttrain #23280 lr = 9.75e-06 loss = 0.001435 train = 0.999414 valid = 0.828392\n",
            "2022-01-08 10:55:16 - INFO:\ttrain #23300 lr = 9.73e-06 loss = 0.001478 train = 0.999609 valid = 0.827985\n",
            "2022-01-08 10:55:18 - INFO:\tSaved test = 0.817666\n",
            "2022-01-08 10:55:50 - INFO:\ttrain #23320 lr = 9.71e-06 loss = 0.001271 train = 0.999805 valid = 0.823924\n",
            "2022-01-08 10:56:21 - INFO:\ttrain #23340 lr = 9.69e-06 loss = 0.003492 train = 0.999023 valid = 0.827782\n",
            "2022-01-08 10:56:52 - INFO:\ttrain #23360 lr = 9.67e-06 loss = 0.001994 train = 0.999414 valid = 0.827579\n",
            "2022-01-08 10:57:23 - INFO:\ttrain #23380 lr = 9.65e-06 loss = 0.001460 train = 0.999707 valid = 0.829204\n",
            "2022-01-08 10:57:54 - INFO:\ttrain #23400 lr = 9.63e-06 loss = 0.001171 train = 0.999512 valid = 0.828798\n",
            "2022-01-08 10:57:56 - INFO:\tSaved test = 0.819287\n",
            "2022-01-08 10:58:27 - INFO:\ttrain #23420 lr = 9.61e-06 loss = 0.001129 train = 0.999609 valid = 0.827782\n",
            "2022-01-08 10:58:58 - INFO:\ttrain #23440 lr = 9.59e-06 loss = 0.001695 train = 0.999609 valid = 0.828188\n",
            "2022-01-08 10:59:29 - INFO:\ttrain #23460 lr = 9.57e-06 loss = 0.001042 train = 0.999805 valid = 0.829001\n",
            "2022-01-08 11:00:00 - INFO:\ttrain #23480 lr = 9.55e-06 loss = 0.001371 train = 0.999609 valid = 0.830016\n",
            "2022-01-08 11:00:32 - INFO:\ttrain #23500 lr = 9.54e-06 loss = 0.001128 train = 0.999707 valid = 0.827579\n",
            "2022-01-08 11:00:34 - INFO:\tSaved test = 0.816451\n",
            "2022-01-08 11:01:05 - INFO:\ttrain #23520 lr = 9.52e-06 loss = 0.001389 train = 0.999805 valid = 0.826564\n",
            "2022-01-08 11:01:36 - INFO:\ttrain #23540 lr = 9.50e-06 loss = 0.002350 train = 0.999512 valid = 0.829407\n",
            "2022-01-08 11:02:07 - INFO:\ttrain #23560 lr = 9.48e-06 loss = 0.001365 train = 0.999707 valid = 0.827376\n",
            "2022-01-08 11:02:39 - INFO:\ttrain #23580 lr = 9.46e-06 loss = 0.001698 train = 0.999707 valid = 0.832859 updated\n",
            "2022-01-08 11:03:10 - INFO:\ttrain #23600 lr = 9.44e-06 loss = 0.001166 train = 0.999707 valid = 0.828798\n",
            "2022-01-08 11:03:12 - INFO:\tSaved test = 0.816856\n",
            "2022-01-08 11:03:43 - INFO:\ttrain #23620 lr = 9.42e-06 loss = 0.001685 train = 0.999512 valid = 0.827173\n",
            "2022-01-08 11:04:15 - INFO:\ttrain #23640 lr = 9.40e-06 loss = 0.001880 train = 0.999512 valid = 0.828595\n",
            "2022-01-08 11:04:46 - INFO:\ttrain #23660 lr = 9.38e-06 loss = 0.001758 train = 0.999414 valid = 0.825345\n",
            "2022-01-08 11:05:17 - INFO:\ttrain #23680 lr = 9.37e-06 loss = 0.001697 train = 0.999414 valid = 0.828188\n",
            "2022-01-08 11:05:48 - INFO:\ttrain #23700 lr = 9.35e-06 loss = 0.001773 train = 0.999414 valid = 0.825345\n",
            "2022-01-08 11:05:51 - INFO:\tSaved test = 0.815640\n",
            "2022-01-08 11:06:22 - INFO:\ttrain #23720 lr = 9.33e-06 loss = 0.001814 train = 0.999512 valid = 0.829204\n",
            "2022-01-08 11:06:53 - INFO:\ttrain #23740 lr = 9.31e-06 loss = 0.001449 train = 0.999609 valid = 0.826970\n",
            "2022-01-08 11:07:24 - INFO:\ttrain #23760 lr = 9.29e-06 loss = 0.000986 train = 0.999707 valid = 0.825345\n",
            "2022-01-08 11:07:55 - INFO:\ttrain #23780 lr = 9.27e-06 loss = 0.001083 train = 0.999707 valid = 0.825751\n",
            "2022-01-08 11:08:26 - INFO:\ttrain #23800 lr = 9.25e-06 loss = 0.001511 train = 0.999512 valid = 0.825345\n",
            "2022-01-08 11:08:29 - INFO:\tSaved test = 0.818476\n",
            "2022-01-08 11:09:00 - INFO:\ttrain #23820 lr = 9.24e-06 loss = 0.001282 train = 0.999609 valid = 0.825955\n",
            "2022-01-08 11:09:31 - INFO:\ttrain #23840 lr = 9.22e-06 loss = 0.002017 train = 0.999121 valid = 0.827985\n",
            "2022-01-08 11:10:02 - INFO:\ttrain #23860 lr = 9.20e-06 loss = 0.001489 train = 0.999512 valid = 0.830016\n",
            "2022-01-08 11:10:33 - INFO:\ttrain #23880 lr = 9.18e-06 loss = 0.001700 train = 0.999316 valid = 0.830219\n",
            "2022-01-08 11:11:04 - INFO:\ttrain #23900 lr = 9.16e-06 loss = 0.002135 train = 0.999414 valid = 0.826158\n",
            "2022-01-08 11:11:07 - INFO:\tSaved test = 0.816045\n",
            "2022-01-08 11:11:38 - INFO:\ttrain #23920 lr = 9.14e-06 loss = 0.001084 train = 0.999902 valid = 0.828188\n",
            "2022-01-08 11:12:09 - INFO:\ttrain #23940 lr = 9.13e-06 loss = 0.001313 train = 0.999707 valid = 0.829001\n",
            "2022-01-08 11:12:40 - INFO:\ttrain #23960 lr = 9.11e-06 loss = 0.000829 train = 0.999805 valid = 0.832656\n",
            "2022-01-08 11:13:11 - INFO:\ttrain #23980 lr = 9.09e-06 loss = 0.001276 train = 0.999707 valid = 0.828188\n",
            "2022-01-08 11:13:43 - INFO:\ttrain #24000 lr = 9.07e-06 loss = 0.000876 train = 0.999902 valid = 0.830219\n",
            "2022-01-08 11:13:45 - INFO:\tSaved test = 0.816856\n",
            "2022-01-08 11:14:16 - INFO:\ttrain #24020 lr = 9.05e-06 loss = 0.002074 train = 0.999609 valid = 0.831235\n",
            "2022-01-08 11:14:47 - INFO:\ttrain #24040 lr = 9.03e-06 loss = 0.001657 train = 0.999512 valid = 0.829204\n",
            "2022-01-08 11:15:19 - INFO:\ttrain #24060 lr = 9.02e-06 loss = 0.001453 train = 0.999609 valid = 0.829001\n",
            "2022-01-08 11:15:50 - INFO:\ttrain #24080 lr = 9.00e-06 loss = 0.001900 train = 0.999121 valid = 0.826361\n",
            "2022-01-08 11:16:21 - INFO:\ttrain #24100 lr = 8.98e-06 loss = 0.000865 train = 0.999902 valid = 0.831844\n",
            "2022-01-08 11:16:23 - INFO:\tSaved test = 0.816856\n",
            "2022-01-08 11:16:55 - INFO:\ttrain #24120 lr = 8.96e-06 loss = 0.000815 train = 0.999609 valid = 0.825955\n",
            "2022-01-08 11:17:26 - INFO:\ttrain #24140 lr = 8.94e-06 loss = 0.001095 train = 0.999609 valid = 0.831032\n",
            "2022-01-08 11:17:57 - INFO:\ttrain #24160 lr = 8.93e-06 loss = 0.000796 train = 0.999805 valid = 0.832859\n",
            "2022-01-08 11:18:28 - INFO:\ttrain #24180 lr = 8.91e-06 loss = 0.001694 train = 0.999414 valid = 0.827782\n",
            "2022-01-08 11:18:59 - INFO:\ttrain #24200 lr = 8.89e-06 loss = 0.000844 train = 1.000000 valid = 0.824939\n",
            "2022-01-08 11:19:01 - INFO:\tSaved test = 0.818071\n",
            "2022-01-08 11:19:33 - INFO:\ttrain #24220 lr = 8.87e-06 loss = 0.000714 train = 0.999805 valid = 0.826564\n",
            "2022-01-08 11:20:04 - INFO:\ttrain #24240 lr = 8.86e-06 loss = 0.001329 train = 0.999707 valid = 0.824736\n",
            "2022-01-08 11:20:35 - INFO:\ttrain #24260 lr = 8.84e-06 loss = 0.001424 train = 0.999707 valid = 0.825345\n",
            "2022-01-08 11:21:06 - INFO:\ttrain #24280 lr = 8.82e-06 loss = 0.002930 train = 0.999023 valid = 0.827579\n",
            "2022-01-08 11:21:37 - INFO:\ttrain #24300 lr = 8.80e-06 loss = 0.000970 train = 0.999707 valid = 0.830626\n",
            "2022-01-08 11:21:40 - INFO:\tSaved test = 0.816451\n",
            "2022-01-08 11:22:11 - INFO:\ttrain #24320 lr = 8.79e-06 loss = 0.001409 train = 0.999609 valid = 0.829204\n",
            "2022-01-08 11:22:42 - INFO:\ttrain #24340 lr = 8.77e-06 loss = 0.000884 train = 0.999902 valid = 0.827985\n",
            "2022-01-08 11:23:13 - INFO:\ttrain #24360 lr = 8.75e-06 loss = 0.000590 train = 1.000000 valid = 0.831235\n",
            "2022-01-08 11:23:44 - INFO:\ttrain #24380 lr = 8.73e-06 loss = 0.001452 train = 0.999414 valid = 0.830422\n",
            "2022-01-08 11:24:15 - INFO:\ttrain #24400 lr = 8.72e-06 loss = 0.000914 train = 0.999805 valid = 0.829001\n",
            "2022-01-08 11:24:17 - INFO:\tSaved test = 0.817666\n",
            "2022-01-08 11:24:48 - INFO:\ttrain #24420 lr = 8.70e-06 loss = 0.001248 train = 0.999512 valid = 0.824330\n",
            "2022-01-08 11:25:19 - INFO:\ttrain #24440 lr = 8.68e-06 loss = 0.001133 train = 0.999805 valid = 0.830016\n",
            "2022-01-08 11:25:51 - INFO:\ttrain #24460 lr = 8.66e-06 loss = 0.001243 train = 0.999707 valid = 0.831032\n",
            "2022-01-08 11:26:22 - INFO:\ttrain #24480 lr = 8.65e-06 loss = 0.003772 train = 0.998926 valid = 0.828595\n",
            "2022-01-08 11:26:53 - INFO:\ttrain #24500 lr = 8.63e-06 loss = 0.002600 train = 0.999023 valid = 0.826564\n",
            "2022-01-08 11:26:55 - INFO:\tSaved test = 0.815235\n",
            "2022-01-08 11:27:27 - INFO:\ttrain #24520 lr = 8.61e-06 loss = 0.001320 train = 0.999805 valid = 0.830219\n",
            "2022-01-08 11:27:57 - INFO:\ttrain #24540 lr = 8.59e-06 loss = 0.001018 train = 0.999707 valid = 0.828595\n",
            "2022-01-08 11:28:27 - INFO:\ttrain #24560 lr = 8.58e-06 loss = 0.000850 train = 0.999707 valid = 0.829407\n",
            "2022-01-08 11:28:58 - INFO:\ttrain #24580 lr = 8.56e-06 loss = 0.000666 train = 0.999805 valid = 0.829407\n",
            "2022-01-08 11:29:29 - INFO:\ttrain #24600 lr = 8.54e-06 loss = 0.001749 train = 0.999512 valid = 0.828188\n",
            "2022-01-08 11:29:31 - INFO:\tSaved test = 0.816451\n",
            "2022-01-08 11:30:01 - INFO:\ttrain #24620 lr = 8.53e-06 loss = 0.001275 train = 0.999512 valid = 0.826767\n",
            "2022-01-08 11:30:31 - INFO:\ttrain #24640 lr = 8.51e-06 loss = 0.001060 train = 0.999805 valid = 0.830219\n",
            "2022-01-08 11:31:01 - INFO:\ttrain #24660 lr = 8.49e-06 loss = 0.001702 train = 0.999414 valid = 0.828188\n",
            "2022-01-08 11:31:32 - INFO:\ttrain #24680 lr = 8.47e-06 loss = 0.001977 train = 0.999512 valid = 0.828188\n",
            "2022-01-08 11:32:02 - INFO:\ttrain #24700 lr = 8.46e-06 loss = 0.001409 train = 0.999414 valid = 0.829001\n",
            "2022-01-08 11:32:04 - INFO:\tSaved test = 0.814425\n",
            "2022-01-08 11:32:35 - INFO:\ttrain #24720 lr = 8.44e-06 loss = 0.001263 train = 0.999707 valid = 0.829813\n",
            "2022-01-08 11:33:05 - INFO:\ttrain #24740 lr = 8.42e-06 loss = 0.000966 train = 0.999707 valid = 0.827173\n",
            "2022-01-08 11:33:35 - INFO:\ttrain #24760 lr = 8.41e-06 loss = 0.001400 train = 0.999609 valid = 0.827173\n",
            "2022-01-08 11:34:05 - INFO:\ttrain #24780 lr = 8.39e-06 loss = 0.000443 train = 1.000000 valid = 0.828798\n",
            "2022-01-08 11:34:36 - INFO:\ttrain #24800 lr = 8.37e-06 loss = 0.000516 train = 0.999902 valid = 0.830829\n",
            "2022-01-08 11:34:38 - INFO:\tSaved test = 0.818476\n",
            "2022-01-08 11:35:08 - INFO:\ttrain #24820 lr = 8.36e-06 loss = 0.000518 train = 0.999902 valid = 0.830626\n",
            "2022-01-08 11:35:39 - INFO:\ttrain #24840 lr = 8.34e-06 loss = 0.000916 train = 0.999805 valid = 0.829610\n",
            "2022-01-08 11:36:10 - INFO:\ttrain #24860 lr = 8.32e-06 loss = 0.000879 train = 0.999805 valid = 0.830016\n",
            "2022-01-08 11:36:40 - INFO:\ttrain #24880 lr = 8.31e-06 loss = 0.000725 train = 1.000000 valid = 0.828595\n",
            "2022-01-08 11:37:11 - INFO:\ttrain #24900 lr = 8.29e-06 loss = 0.001488 train = 0.999707 valid = 0.831235\n",
            "2022-01-08 11:37:13 - INFO:\tSaved test = 0.816451\n",
            "2022-01-08 11:37:44 - INFO:\ttrain #24920 lr = 8.27e-06 loss = 0.001301 train = 0.999609 valid = 0.829001\n",
            "2022-01-08 11:38:16 - INFO:\ttrain #24940 lr = 8.26e-06 loss = 0.000807 train = 0.999805 valid = 0.829001\n",
            "2022-01-08 11:38:47 - INFO:\ttrain #24960 lr = 8.24e-06 loss = 0.000567 train = 0.999902 valid = 0.829407\n",
            "2022-01-08 11:39:19 - INFO:\ttrain #24980 lr = 8.22e-06 loss = 0.001313 train = 0.999609 valid = 0.829407\n",
            "2022-01-08 11:39:50 - INFO:\ttrain #25000 lr = 8.21e-06 loss = 0.001022 train = 0.999707 valid = 0.831438\n",
            "2022-01-08 11:39:53 - INFO:\tSaved test = 0.822528\n",
            "2022-01-08 11:40:24 - INFO:\ttrain #25020 lr = 8.19e-06 loss = 0.001224 train = 0.999512 valid = 0.826767\n",
            "2022-01-08 11:40:55 - INFO:\ttrain #25040 lr = 8.17e-06 loss = 0.003402 train = 0.998730 valid = 0.825955\n",
            "2022-01-08 11:41:26 - INFO:\ttrain #25060 lr = 8.16e-06 loss = 0.002527 train = 0.999121 valid = 0.829001\n",
            "2022-01-08 11:41:57 - INFO:\ttrain #25080 lr = 8.14e-06 loss = 0.001396 train = 0.999609 valid = 0.827173\n",
            "2022-01-08 11:42:28 - INFO:\ttrain #25100 lr = 8.13e-06 loss = 0.000936 train = 0.999902 valid = 0.828798\n",
            "2022-01-08 11:42:30 - INFO:\tSaved test = 0.818882\n",
            "2022-01-08 11:43:00 - INFO:\ttrain #25120 lr = 8.11e-06 loss = 0.000728 train = 0.999902 valid = 0.830016\n",
            "2022-01-08 11:43:31 - INFO:\ttrain #25140 lr = 8.09e-06 loss = 0.000744 train = 0.999805 valid = 0.829001\n",
            "2022-01-08 11:44:01 - INFO:\ttrain #25160 lr = 8.08e-06 loss = 0.000704 train = 0.999902 valid = 0.830016\n",
            "2022-01-08 11:44:32 - INFO:\ttrain #25180 lr = 8.06e-06 loss = 0.000963 train = 0.999805 valid = 0.830829\n",
            "2022-01-08 11:45:03 - INFO:\ttrain #25200 lr = 8.04e-06 loss = 0.001253 train = 0.999707 valid = 0.824533\n",
            "2022-01-08 11:45:06 - INFO:\tSaved test = 0.814019\n",
            "2022-01-08 11:45:38 - INFO:\ttrain #25220 lr = 8.03e-06 loss = 0.000910 train = 0.999805 valid = 0.826158\n",
            "2022-01-08 11:46:09 - INFO:\ttrain #25240 lr = 8.01e-06 loss = 0.000523 train = 0.999902 valid = 0.827579\n",
            "2022-01-08 11:46:40 - INFO:\ttrain #25260 lr = 8.00e-06 loss = 0.000646 train = 0.999902 valid = 0.826361\n",
            "2022-01-08 11:47:12 - INFO:\ttrain #25280 lr = 7.98e-06 loss = 0.000672 train = 0.999902 valid = 0.828798\n",
            "2022-01-08 11:47:43 - INFO:\ttrain #25300 lr = 7.96e-06 loss = 0.001930 train = 0.999316 valid = 0.826361\n",
            "2022-01-08 11:47:45 - INFO:\tSaved test = 0.820502\n",
            "2022-01-08 11:48:17 - INFO:\ttrain #25320 lr = 7.95e-06 loss = 0.002001 train = 0.999414 valid = 0.825955\n",
            "2022-01-08 11:48:48 - INFO:\ttrain #25340 lr = 7.93e-06 loss = 0.000825 train = 0.999805 valid = 0.832047\n",
            "2022-01-08 11:49:20 - INFO:\ttrain #25360 lr = 7.92e-06 loss = 0.000544 train = 0.999902 valid = 0.828798\n",
            "2022-01-08 11:49:51 - INFO:\ttrain #25380 lr = 7.90e-06 loss = 0.001194 train = 0.999609 valid = 0.831235\n",
            "2022-01-08 11:50:22 - INFO:\ttrain #25400 lr = 7.89e-06 loss = 0.000803 train = 0.999805 valid = 0.829813\n",
            "2022-01-08 11:50:24 - INFO:\tSaved test = 0.816451\n",
            "2022-01-08 11:50:55 - INFO:\ttrain #25420 lr = 7.87e-06 loss = 0.000711 train = 0.999902 valid = 0.830626\n",
            "2022-01-08 11:51:27 - INFO:\ttrain #25440 lr = 7.85e-06 loss = 0.000532 train = 1.000000 valid = 0.829204\n",
            "2022-01-08 11:51:58 - INFO:\ttrain #25460 lr = 7.84e-06 loss = 0.001287 train = 0.999707 valid = 0.826767\n",
            "2022-01-08 11:52:29 - INFO:\ttrain #25480 lr = 7.82e-06 loss = 0.000421 train = 0.999902 valid = 0.832047\n",
            "2022-01-08 11:53:01 - INFO:\ttrain #25500 lr = 7.81e-06 loss = 0.000840 train = 0.999805 valid = 0.825142\n",
            "2022-01-08 11:53:03 - INFO:\tSaved test = 0.822528\n",
            "2022-01-08 11:53:34 - INFO:\ttrain #25520 lr = 7.79e-06 loss = 0.000884 train = 0.999707 valid = 0.832047\n",
            "2022-01-08 11:54:06 - INFO:\ttrain #25540 lr = 7.78e-06 loss = 0.000713 train = 0.999805 valid = 0.828595\n",
            "2022-01-08 11:54:37 - INFO:\ttrain #25560 lr = 7.76e-06 loss = 0.001314 train = 0.999707 valid = 0.821080\n",
            "2022-01-08 11:55:08 - INFO:\ttrain #25580 lr = 7.74e-06 loss = 0.001506 train = 0.999414 valid = 0.829407\n",
            "2022-01-08 11:55:39 - INFO:\ttrain #25600 lr = 7.73e-06 loss = 0.000797 train = 0.999805 valid = 0.826361\n",
            "2022-01-08 11:55:42 - INFO:\tSaved test = 0.820502\n",
            "2022-01-08 11:56:13 - INFO:\ttrain #25620 lr = 7.71e-06 loss = 0.000651 train = 0.999902 valid = 0.827579\n",
            "2022-01-08 11:56:44 - INFO:\ttrain #25640 lr = 7.70e-06 loss = 0.000598 train = 0.999902 valid = 0.831235\n",
            "2022-01-08 11:57:16 - INFO:\ttrain #25660 lr = 7.68e-06 loss = 0.001004 train = 0.999707 valid = 0.825548\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-20-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-19-cb6be00f235b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(more_epoch, valid_result_threshold)\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mcum_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m             \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# orig, omit upload when idim==odim, use lowrank linear\n",
        "train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mTxuPhUBU5hw",
        "outputId": "fe83484f-2717-4c90-a7a2-6142cba67348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-09 00:01:57 - INFO:\ttrain epoch = 1 ~ 100000 threshold = 1.0\n",
            "2022-01-09 00:02:01 - DEBUG:\ttrain #1 lr = 1.00e-04 loss = 4.099680 train = 0.027344 \n",
            "2022-01-09 00:02:02 - DEBUG:\ttrain #2 lr = 1.00e-04 loss = 3.825120 train = 0.060547 \n",
            "2022-01-09 00:02:03 - DEBUG:\ttrain #3 lr = 1.00e-04 loss = 3.407600 train = 0.146484 \n",
            "2022-01-09 00:02:03 - DEBUG:\ttrain #4 lr = 1.00e-04 loss = 3.224407 train = 0.218750 \n",
            "2022-01-09 00:02:04 - DEBUG:\ttrain #5 lr = 1.00e-04 loss = 3.127806 train = 0.226562 \n",
            "2022-01-09 00:02:09 - INFO:\ttrain #10 lr = 9.99e-05 loss = 2.760747 train = 0.331641 valid = 0.416328 updated\n",
            "2022-01-09 00:02:18 - INFO:\ttrain #20 lr = 9.98e-05 loss = 2.364871 train = 0.423828 valid = 0.531682 updated\n",
            "2022-01-09 00:02:28 - INFO:\ttrain #30 lr = 9.97e-05 loss = 2.034938 train = 0.515820 valid = 0.577985 updated\n",
            "2022-01-09 00:02:37 - INFO:\ttrain #40 lr = 9.96e-05 loss = 1.804515 train = 0.558984 valid = 0.616166 updated\n",
            "2022-01-09 00:02:46 - INFO:\ttrain #50 lr = 9.95e-05 loss = 1.570231 train = 0.609375 valid = 0.651503 updated\n",
            "2022-01-09 00:02:55 - INFO:\ttrain #60 lr = 9.94e-05 loss = 1.452454 train = 0.638086 valid = 0.682778 updated\n",
            "2022-01-09 00:03:04 - INFO:\ttrain #70 lr = 9.93e-05 loss = 1.344154 train = 0.660156 valid = 0.706336 updated\n",
            "2022-01-09 00:03:13 - INFO:\ttrain #80 lr = 9.92e-05 loss = 1.236922 train = 0.685352 valid = 0.730301 updated\n",
            "2022-01-09 00:03:22 - INFO:\ttrain #90 lr = 9.91e-05 loss = 1.114633 train = 0.714648 valid = 0.748578 updated\n",
            "2022-01-09 00:03:31 - INFO:\ttrain #100 lr = 9.90e-05 loss = 1.048341 train = 0.726367 valid = 0.765232 updated\n",
            "2022-01-09 00:03:32 - INFO:\tSaved test = 0.764587\n",
            "2022-01-09 00:03:41 - INFO:\ttrain #110 lr = 9.89e-05 loss = 0.943600 train = 0.759961 valid = 0.759951\n",
            "2022-01-09 00:03:50 - INFO:\ttrain #120 lr = 9.88e-05 loss = 0.926023 train = 0.755273 valid = 0.777011 updated\n",
            "2022-01-09 00:03:59 - INFO:\ttrain #130 lr = 9.87e-05 loss = 0.884899 train = 0.772461 valid = 0.778229 updated\n",
            "2022-01-09 00:04:08 - INFO:\ttrain #140 lr = 9.86e-05 loss = 0.829114 train = 0.780273 valid = 0.791633 updated\n",
            "2022-01-09 00:04:17 - INFO:\ttrain #150 lr = 9.85e-05 loss = 0.793954 train = 0.792578 valid = 0.799756 updated\n",
            "2022-01-09 00:04:26 - INFO:\ttrain #160 lr = 9.84e-05 loss = 0.757303 train = 0.797266 valid = 0.800569 updated\n",
            "2022-01-09 00:04:34 - INFO:\ttrain #170 lr = 9.83e-05 loss = 0.731037 train = 0.799023 valid = 0.808692 updated\n",
            "2022-01-09 00:04:43 - INFO:\ttrain #180 lr = 9.82e-05 loss = 0.725598 train = 0.800195 valid = 0.803006\n",
            "2022-01-09 00:04:52 - INFO:\ttrain #190 lr = 9.81e-05 loss = 0.680335 train = 0.816992 valid = 0.813566 updated\n",
            "2022-01-09 00:05:01 - INFO:\ttrain #200 lr = 9.80e-05 loss = 0.658426 train = 0.818164 valid = 0.818034 updated\n",
            "2022-01-09 00:05:02 - INFO:\tSaved test = 0.802269\n",
            "2022-01-09 00:05:11 - INFO:\ttrain #210 lr = 9.79e-05 loss = 0.625479 train = 0.831445 valid = 0.840374 updated\n",
            "2022-01-09 00:05:20 - INFO:\ttrain #220 lr = 9.78e-05 loss = 0.605677 train = 0.838086 valid = 0.831032\n",
            "2022-01-09 00:05:29 - INFO:\ttrain #230 lr = 9.77e-05 loss = 0.587389 train = 0.834180 valid = 0.819659\n",
            "2022-01-09 00:05:38 - INFO:\ttrain #240 lr = 9.76e-05 loss = 0.567698 train = 0.846484 valid = 0.816816\n",
            "2022-01-09 00:05:47 - INFO:\ttrain #250 lr = 9.75e-05 loss = 0.547086 train = 0.845898 valid = 0.840780 updated\n",
            "2022-01-09 00:05:56 - INFO:\ttrain #260 lr = 9.74e-05 loss = 0.529560 train = 0.853711 valid = 0.833875\n",
            "2022-01-09 00:06:05 - INFO:\ttrain #270 lr = 9.73e-05 loss = 0.514089 train = 0.855469 valid = 0.851340 updated\n",
            "2022-01-09 00:06:14 - INFO:\ttrain #280 lr = 9.72e-05 loss = 0.508015 train = 0.861914 valid = 0.796507\n",
            "2022-01-09 00:06:23 - INFO:\ttrain #290 lr = 9.71e-05 loss = 0.492586 train = 0.860352 valid = 0.850122\n",
            "2022-01-09 00:06:32 - INFO:\ttrain #300 lr = 9.70e-05 loss = 0.468879 train = 0.874219 valid = 0.846060\n",
            "2022-01-09 00:06:33 - INFO:\tSaved test = 0.818882\n",
            "2022-01-09 00:06:42 - INFO:\ttrain #310 lr = 9.69e-05 loss = 0.472396 train = 0.870117 valid = 0.848497\n",
            "2022-01-09 00:06:51 - INFO:\ttrain #320 lr = 9.69e-05 loss = 0.472152 train = 0.866016 valid = 0.843217\n",
            "2022-01-09 00:07:00 - INFO:\ttrain #330 lr = 9.68e-05 loss = 0.435811 train = 0.881445 valid = 0.824127\n",
            "2022-01-09 00:07:09 - INFO:\ttrain #340 lr = 9.67e-05 loss = 0.438001 train = 0.879883 valid = 0.830626\n",
            "2022-01-09 00:07:18 - INFO:\ttrain #350 lr = 9.66e-05 loss = 0.416281 train = 0.884766 valid = 0.852559 updated\n",
            "2022-01-09 00:07:27 - INFO:\ttrain #360 lr = 9.65e-05 loss = 0.420381 train = 0.882227 valid = 0.855402 updated\n",
            "2022-01-09 00:07:36 - INFO:\ttrain #370 lr = 9.64e-05 loss = 0.427923 train = 0.878320 valid = 0.855808 updated\n",
            "2022-01-09 00:07:45 - INFO:\ttrain #380 lr = 9.63e-05 loss = 0.382450 train = 0.891602 valid = 0.854590\n",
            "2022-01-09 00:07:54 - INFO:\ttrain #390 lr = 9.62e-05 loss = 0.368067 train = 0.894727 valid = 0.858652 updated\n",
            "2022-01-09 00:08:03 - INFO:\ttrain #400 lr = 9.61e-05 loss = 0.391434 train = 0.887500 valid = 0.870837 updated\n",
            "2022-01-09 00:08:04 - INFO:\tSaved test = 0.839141\n",
            "2022-01-09 00:08:13 - INFO:\ttrain #410 lr = 9.60e-05 loss = 0.386632 train = 0.895508 valid = 0.857027\n",
            "2022-01-09 00:08:22 - INFO:\ttrain #420 lr = 9.59e-05 loss = 0.346250 train = 0.901953 valid = 0.852559\n",
            "2022-01-09 00:08:31 - INFO:\ttrain #430 lr = 9.58e-05 loss = 0.349135 train = 0.899414 valid = 0.864338\n",
            "2022-01-09 00:08:40 - INFO:\ttrain #440 lr = 9.57e-05 loss = 0.336727 train = 0.905273 valid = 0.830219\n",
            "2022-01-09 00:08:49 - INFO:\ttrain #450 lr = 9.56e-05 loss = 0.340760 train = 0.902539 valid = 0.855808\n",
            "2022-01-09 00:08:58 - INFO:\ttrain #460 lr = 9.55e-05 loss = 0.333850 train = 0.903906 valid = 0.864338\n",
            "2022-01-09 00:09:07 - INFO:\ttrain #470 lr = 9.54e-05 loss = 0.311767 train = 0.911719 valid = 0.851340\n",
            "2022-01-09 00:09:16 - INFO:\ttrain #480 lr = 9.53e-05 loss = 0.306013 train = 0.911914 valid = 0.852153\n",
            "2022-01-09 00:09:25 - INFO:\ttrain #490 lr = 9.52e-05 loss = 0.337060 train = 0.906445 valid = 0.855808\n",
            "2022-01-09 00:09:33 - INFO:\ttrain #500 lr = 9.51e-05 loss = 0.294022 train = 0.920312 valid = 0.856621\n",
            "2022-01-09 00:09:35 - INFO:\tSaved test = 0.824149\n",
            "2022-01-09 00:09:44 - INFO:\ttrain #510 lr = 9.50e-05 loss = 0.319616 train = 0.909766 valid = 0.865963\n",
            "2022-01-09 00:09:53 - INFO:\ttrain #520 lr = 9.49e-05 loss = 0.306194 train = 0.909570 valid = 0.829407\n",
            "2022-01-09 00:10:02 - INFO:\ttrain #530 lr = 9.48e-05 loss = 0.281640 train = 0.921094 valid = 0.859870\n",
            "2022-01-09 00:10:11 - INFO:\ttrain #540 lr = 9.47e-05 loss = 0.276056 train = 0.919336 valid = 0.863932\n",
            "2022-01-09 00:10:19 - INFO:\ttrain #550 lr = 9.46e-05 loss = 0.274350 train = 0.924023 valid = 0.852965\n",
            "2022-01-09 00:10:28 - INFO:\ttrain #560 lr = 9.46e-05 loss = 0.272192 train = 0.922070 valid = 0.860276\n",
            "2022-01-09 00:10:37 - INFO:\ttrain #570 lr = 9.45e-05 loss = 0.258100 train = 0.926758 valid = 0.859870\n",
            "2022-01-09 00:10:46 - INFO:\ttrain #580 lr = 9.44e-05 loss = 0.280338 train = 0.921484 valid = 0.860276\n",
            "2022-01-09 00:10:55 - INFO:\ttrain #590 lr = 9.43e-05 loss = 0.244125 train = 0.933398 valid = 0.856621\n",
            "2022-01-09 00:11:04 - INFO:\ttrain #600 lr = 9.42e-05 loss = 0.273188 train = 0.921094 valid = 0.865556\n",
            "2022-01-09 00:11:05 - INFO:\tSaved test = 0.840762\n",
            "2022-01-09 00:11:14 - INFO:\ttrain #610 lr = 9.41e-05 loss = 0.253827 train = 0.927148 valid = 0.850122\n",
            "2022-01-09 00:11:23 - INFO:\ttrain #620 lr = 9.40e-05 loss = 0.251577 train = 0.925781 valid = 0.866369\n",
            "2022-01-09 00:11:32 - INFO:\ttrain #630 lr = 9.39e-05 loss = 0.235429 train = 0.933789 valid = 0.853371\n",
            "2022-01-09 00:11:41 - INFO:\ttrain #640 lr = 9.38e-05 loss = 0.243081 train = 0.933008 valid = 0.864744\n",
            "2022-01-09 00:11:50 - INFO:\ttrain #650 lr = 9.37e-05 loss = 0.214352 train = 0.940430 valid = 0.839155\n",
            "2022-01-09 00:11:59 - INFO:\ttrain #660 lr = 9.36e-05 loss = 0.226687 train = 0.934570 valid = 0.865963\n",
            "2022-01-09 00:12:08 - INFO:\ttrain #670 lr = 9.35e-05 loss = 0.230257 train = 0.933398 valid = 0.857839\n",
            "2022-01-09 00:12:17 - INFO:\ttrain #680 lr = 9.34e-05 loss = 0.229749 train = 0.935547 valid = 0.873274 updated\n",
            "2022-01-09 00:12:26 - INFO:\ttrain #690 lr = 9.33e-05 loss = 0.218118 train = 0.939258 valid = 0.855402\n",
            "2022-01-09 00:12:35 - INFO:\ttrain #700 lr = 9.32e-05 loss = 0.216758 train = 0.936523 valid = 0.865963\n",
            "2022-01-09 00:12:37 - INFO:\tSaved test = 0.839546\n",
            "2022-01-09 00:12:46 - INFO:\ttrain #710 lr = 9.31e-05 loss = 0.214293 train = 0.941211 valid = 0.869618\n",
            "2022-01-09 00:12:54 - INFO:\ttrain #720 lr = 9.31e-05 loss = 0.226097 train = 0.935742 valid = 0.863932\n",
            "2022-01-09 00:13:03 - INFO:\ttrain #730 lr = 9.30e-05 loss = 0.205722 train = 0.942383 valid = 0.852559\n",
            "2022-01-09 00:13:12 - INFO:\ttrain #740 lr = 9.29e-05 loss = 0.204369 train = 0.938281 valid = 0.849716\n",
            "2022-01-09 00:13:21 - INFO:\ttrain #750 lr = 9.28e-05 loss = 0.203985 train = 0.943359 valid = 0.862713\n",
            "2022-01-09 00:13:30 - INFO:\ttrain #760 lr = 9.27e-05 loss = 0.205289 train = 0.940430 valid = 0.858245\n",
            "2022-01-09 00:13:38 - INFO:\ttrain #770 lr = 9.26e-05 loss = 0.199411 train = 0.945703 valid = 0.859870\n",
            "2022-01-09 00:13:47 - INFO:\ttrain #780 lr = 9.25e-05 loss = 0.198948 train = 0.944727 valid = 0.847279\n",
            "2022-01-09 00:13:56 - INFO:\ttrain #790 lr = 9.24e-05 loss = 0.193317 train = 0.941797 valid = 0.848091\n",
            "2022-01-09 00:14:05 - INFO:\ttrain #800 lr = 9.23e-05 loss = 0.195296 train = 0.943555 valid = 0.865963\n",
            "2022-01-09 00:14:06 - INFO:\tSaved test = 0.841167\n",
            "2022-01-09 00:14:16 - INFO:\ttrain #810 lr = 9.22e-05 loss = 0.169195 train = 0.948828 valid = 0.844029\n",
            "2022-01-09 00:14:25 - INFO:\ttrain #820 lr = 9.21e-05 loss = 0.191510 train = 0.938672 valid = 0.850528\n",
            "2022-01-09 00:14:34 - INFO:\ttrain #830 lr = 9.20e-05 loss = 0.192532 train = 0.946875 valid = 0.865556\n",
            "2022-01-09 00:14:43 - INFO:\ttrain #840 lr = 9.19e-05 loss = 0.164633 train = 0.949609 valid = 0.863932\n",
            "2022-01-09 00:14:52 - INFO:\ttrain #850 lr = 9.19e-05 loss = 0.182290 train = 0.948828 valid = 0.855402\n",
            "2022-01-09 00:15:01 - INFO:\ttrain #860 lr = 9.18e-05 loss = 0.181269 train = 0.947656 valid = 0.842811\n",
            "2022-01-09 00:15:10 - INFO:\ttrain #870 lr = 9.17e-05 loss = 0.184210 train = 0.948242 valid = 0.868806\n",
            "2022-01-09 00:15:19 - INFO:\ttrain #880 lr = 9.16e-05 loss = 0.174187 train = 0.951367 valid = 0.871649\n",
            "2022-01-09 00:15:28 - INFO:\ttrain #890 lr = 9.15e-05 loss = 0.177527 train = 0.948828 valid = 0.861901\n",
            "2022-01-09 00:15:37 - INFO:\ttrain #900 lr = 9.14e-05 loss = 0.171048 train = 0.951562 valid = 0.865150\n",
            "2022-01-09 00:15:38 - INFO:\tSaved test = 0.841167\n",
            "2022-01-09 00:15:47 - INFO:\ttrain #910 lr = 9.13e-05 loss = 0.156163 train = 0.958008 valid = 0.861495\n",
            "2022-01-09 00:15:56 - INFO:\ttrain #920 lr = 9.12e-05 loss = 0.155446 train = 0.955078 valid = 0.868400\n",
            "2022-01-09 00:16:05 - INFO:\ttrain #930 lr = 9.11e-05 loss = 0.165348 train = 0.954102 valid = 0.855808\n",
            "2022-01-09 00:16:14 - INFO:\ttrain #940 lr = 9.10e-05 loss = 0.172667 train = 0.951953 valid = 0.863932\n",
            "2022-01-09 00:16:23 - INFO:\ttrain #950 lr = 9.09e-05 loss = 0.142841 train = 0.956055 valid = 0.873680 updated\n",
            "2022-01-09 00:16:32 - INFO:\ttrain #960 lr = 9.08e-05 loss = 0.162212 train = 0.951367 valid = 0.867587\n",
            "2022-01-09 00:16:41 - INFO:\ttrain #970 lr = 9.08e-05 loss = 0.159744 train = 0.954688 valid = 0.868806\n",
            "2022-01-09 00:16:50 - INFO:\ttrain #980 lr = 9.07e-05 loss = 0.147941 train = 0.956445 valid = 0.863119\n",
            "2022-01-09 00:16:59 - INFO:\ttrain #990 lr = 9.06e-05 loss = 0.149294 train = 0.953320 valid = 0.863526\n",
            "2022-01-09 00:17:08 - INFO:\ttrain #1000 lr = 9.05e-05 loss = 0.151815 train = 0.957812 valid = 0.867181\n",
            "2022-01-09 00:17:09 - INFO:\tSaved test = 0.836710\n",
            "2022-01-09 00:17:18 - INFO:\ttrain #1010 lr = 9.04e-05 loss = 0.154896 train = 0.957617 valid = 0.853777\n",
            "2022-01-09 00:17:27 - INFO:\ttrain #1020 lr = 9.03e-05 loss = 0.157687 train = 0.958203 valid = 0.863526\n",
            "2022-01-09 00:17:36 - INFO:\ttrain #1030 lr = 9.02e-05 loss = 0.137467 train = 0.961719 valid = 0.859870\n",
            "2022-01-09 00:17:45 - INFO:\ttrain #1040 lr = 9.01e-05 loss = 0.141945 train = 0.957422 valid = 0.874492 updated\n",
            "2022-01-09 00:17:54 - INFO:\ttrain #1050 lr = 9.00e-05 loss = 0.143121 train = 0.958984 valid = 0.866775\n",
            "2022-01-09 00:18:03 - INFO:\ttrain #1060 lr = 8.99e-05 loss = 0.140595 train = 0.959180 valid = 0.854184\n",
            "2022-01-09 00:18:12 - INFO:\ttrain #1070 lr = 8.99e-05 loss = 0.138574 train = 0.960742 valid = 0.866369\n",
            "2022-01-09 00:18:21 - INFO:\ttrain #1080 lr = 8.98e-05 loss = 0.144877 train = 0.958789 valid = 0.850528\n",
            "2022-01-09 00:18:30 - INFO:\ttrain #1090 lr = 8.97e-05 loss = 0.149582 train = 0.961133 valid = 0.867994\n",
            "2022-01-09 00:18:39 - INFO:\ttrain #1100 lr = 8.96e-05 loss = 0.125055 train = 0.967969 valid = 0.865963\n",
            "2022-01-09 00:18:40 - INFO:\tSaved test = 0.846029\n",
            "2022-01-09 00:18:49 - INFO:\ttrain #1110 lr = 8.95e-05 loss = 0.141216 train = 0.959766 valid = 0.873274\n",
            "2022-01-09 00:18:58 - INFO:\ttrain #1120 lr = 8.94e-05 loss = 0.134593 train = 0.961719 valid = 0.877742 updated\n",
            "2022-01-09 00:19:07 - INFO:\ttrain #1130 lr = 8.93e-05 loss = 0.137706 train = 0.961719 valid = 0.859870\n",
            "2022-01-09 00:19:17 - INFO:\ttrain #1140 lr = 8.92e-05 loss = 0.137855 train = 0.958594 valid = 0.857433\n",
            "2022-01-09 00:19:26 - INFO:\ttrain #1150 lr = 8.91e-05 loss = 0.127666 train = 0.962305 valid = 0.863526\n",
            "2022-01-09 00:19:35 - INFO:\ttrain #1160 lr = 8.90e-05 loss = 0.124495 train = 0.961914 valid = 0.861901\n",
            "2022-01-09 00:19:45 - INFO:\ttrain #1170 lr = 8.90e-05 loss = 0.118636 train = 0.963672 valid = 0.874492\n",
            "2022-01-09 00:19:54 - INFO:\ttrain #1180 lr = 8.89e-05 loss = 0.126121 train = 0.964063 valid = 0.864744\n",
            "2022-01-09 00:20:03 - INFO:\ttrain #1190 lr = 8.88e-05 loss = 0.127324 train = 0.965234 valid = 0.864744\n",
            "2022-01-09 00:20:12 - INFO:\ttrain #1200 lr = 8.87e-05 loss = 0.127491 train = 0.961719 valid = 0.866369\n",
            "2022-01-09 00:20:13 - INFO:\tSaved test = 0.847650\n",
            "2022-01-09 00:20:22 - INFO:\ttrain #1210 lr = 8.86e-05 loss = 0.110765 train = 0.966602 valid = 0.872461\n",
            "2022-01-09 00:20:31 - INFO:\ttrain #1220 lr = 8.85e-05 loss = 0.142316 train = 0.963281 valid = 0.871243\n",
            "2022-01-09 00:20:40 - INFO:\ttrain #1230 lr = 8.84e-05 loss = 0.128502 train = 0.964453 valid = 0.878960 updated\n",
            "2022-01-09 00:20:49 - INFO:\ttrain #1240 lr = 8.83e-05 loss = 0.111409 train = 0.968359 valid = 0.867181\n",
            "2022-01-09 00:20:58 - INFO:\ttrain #1250 lr = 8.82e-05 loss = 0.111280 train = 0.967383 valid = 0.864744\n",
            "2022-01-09 00:21:07 - INFO:\ttrain #1260 lr = 8.82e-05 loss = 0.122375 train = 0.969922 valid = 0.870837\n",
            "2022-01-09 00:21:16 - INFO:\ttrain #1270 lr = 8.81e-05 loss = 0.105924 train = 0.970508 valid = 0.869618\n",
            "2022-01-09 00:21:25 - INFO:\ttrain #1280 lr = 8.80e-05 loss = 0.107604 train = 0.967969 valid = 0.861901\n",
            "2022-01-09 00:21:34 - INFO:\ttrain #1290 lr = 8.79e-05 loss = 0.112272 train = 0.967383 valid = 0.859058\n",
            "2022-01-09 00:21:43 - INFO:\ttrain #1300 lr = 8.78e-05 loss = 0.110463 train = 0.969336 valid = 0.854184\n",
            "2022-01-09 00:21:45 - INFO:\tSaved test = 0.839141\n",
            "2022-01-09 00:21:54 - INFO:\ttrain #1310 lr = 8.77e-05 loss = 0.109644 train = 0.968945 valid = 0.862307\n",
            "2022-01-09 00:22:03 - INFO:\ttrain #1320 lr = 8.76e-05 loss = 0.120780 train = 0.964844 valid = 0.867994\n",
            "2022-01-09 00:22:12 - INFO:\ttrain #1330 lr = 8.75e-05 loss = 0.100736 train = 0.971680 valid = 0.864338\n",
            "2022-01-09 00:22:21 - INFO:\ttrain #1340 lr = 8.75e-05 loss = 0.110198 train = 0.971484 valid = 0.865150\n",
            "2022-01-09 00:22:30 - INFO:\ttrain #1350 lr = 8.74e-05 loss = 0.111072 train = 0.970313 valid = 0.861089\n",
            "2022-01-09 00:22:39 - INFO:\ttrain #1360 lr = 8.73e-05 loss = 0.107187 train = 0.970313 valid = 0.865963\n",
            "2022-01-09 00:22:48 - INFO:\ttrain #1370 lr = 8.72e-05 loss = 0.104699 train = 0.969922 valid = 0.852153\n",
            "2022-01-09 00:22:57 - INFO:\ttrain #1380 lr = 8.71e-05 loss = 0.097275 train = 0.972852 valid = 0.845248\n",
            "2022-01-09 00:23:06 - INFO:\ttrain #1390 lr = 8.70e-05 loss = 0.115781 train = 0.967969 valid = 0.867587\n",
            "2022-01-09 00:23:15 - INFO:\ttrain #1400 lr = 8.69e-05 loss = 0.098486 train = 0.969727 valid = 0.870024\n",
            "2022-01-09 00:23:17 - INFO:\tSaved test = 0.835089\n",
            "2022-01-09 00:23:26 - INFO:\ttrain #1410 lr = 8.68e-05 loss = 0.102590 train = 0.974219 valid = 0.874086\n",
            "2022-01-09 00:23:35 - INFO:\ttrain #1420 lr = 8.68e-05 loss = 0.109384 train = 0.971289 valid = 0.859464\n",
            "2022-01-09 00:23:44 - INFO:\ttrain #1430 lr = 8.67e-05 loss = 0.094086 train = 0.972656 valid = 0.859464\n",
            "2022-01-09 00:23:53 - INFO:\ttrain #1440 lr = 8.66e-05 loss = 0.101420 train = 0.970703 valid = 0.857839\n",
            "2022-01-09 00:24:02 - INFO:\ttrain #1450 lr = 8.65e-05 loss = 0.095050 train = 0.973633 valid = 0.863119\n",
            "2022-01-09 00:24:11 - INFO:\ttrain #1460 lr = 8.64e-05 loss = 0.100921 train = 0.974023 valid = 0.865150\n",
            "2022-01-09 00:24:20 - INFO:\ttrain #1470 lr = 8.63e-05 loss = 0.086689 train = 0.975586 valid = 0.875305\n",
            "2022-01-09 00:24:28 - INFO:\ttrain #1480 lr = 8.62e-05 loss = 0.100627 train = 0.970703 valid = 0.861495\n",
            "2022-01-09 00:24:37 - INFO:\ttrain #1490 lr = 8.62e-05 loss = 0.090407 train = 0.972266 valid = 0.871649\n",
            "2022-01-09 00:24:46 - INFO:\ttrain #1500 lr = 8.61e-05 loss = 0.098990 train = 0.977734 valid = 0.874086\n",
            "2022-01-09 00:24:48 - INFO:\tSaved test = 0.850486\n",
            "2022-01-09 00:24:57 - INFO:\ttrain #1510 lr = 8.60e-05 loss = 0.100349 train = 0.970898 valid = 0.859058\n",
            "2022-01-09 00:25:06 - INFO:\ttrain #1520 lr = 8.59e-05 loss = 0.099911 train = 0.972656 valid = 0.865150\n",
            "2022-01-09 00:25:15 - INFO:\ttrain #1530 lr = 8.58e-05 loss = 0.095373 train = 0.977344 valid = 0.831032\n",
            "2022-01-09 00:25:24 - INFO:\ttrain #1540 lr = 8.57e-05 loss = 0.099770 train = 0.971289 valid = 0.857027\n",
            "2022-01-09 00:25:33 - INFO:\ttrain #1550 lr = 8.56e-05 loss = 0.081537 train = 0.976367 valid = 0.864338\n",
            "2022-01-09 00:25:42 - INFO:\ttrain #1560 lr = 8.56e-05 loss = 0.097623 train = 0.973047 valid = 0.872461\n",
            "2022-01-09 00:25:51 - INFO:\ttrain #1570 lr = 8.55e-05 loss = 0.083265 train = 0.978320 valid = 0.869212\n",
            "2022-01-09 00:26:00 - INFO:\ttrain #1580 lr = 8.54e-05 loss = 0.088738 train = 0.974414 valid = 0.859058\n",
            "2022-01-09 00:26:09 - INFO:\ttrain #1590 lr = 8.53e-05 loss = 0.090598 train = 0.975977 valid = 0.872461\n",
            "2022-01-09 00:26:18 - INFO:\ttrain #1600 lr = 8.52e-05 loss = 0.094545 train = 0.975000 valid = 0.850934\n",
            "2022-01-09 00:26:20 - INFO:\tSaved test = 0.828606\n",
            "2022-01-09 00:26:29 - INFO:\ttrain #1610 lr = 8.51e-05 loss = 0.073816 train = 0.976953 valid = 0.869618\n",
            "2022-01-09 00:26:38 - INFO:\ttrain #1620 lr = 8.50e-05 loss = 0.088218 train = 0.975000 valid = 0.872055\n",
            "2022-01-09 00:26:47 - INFO:\ttrain #1630 lr = 8.50e-05 loss = 0.104174 train = 0.974414 valid = 0.868400\n",
            "2022-01-09 00:26:56 - INFO:\ttrain #1640 lr = 8.49e-05 loss = 0.100777 train = 0.972461 valid = 0.872055\n",
            "2022-01-09 00:27:05 - INFO:\ttrain #1650 lr = 8.48e-05 loss = 0.087945 train = 0.976953 valid = 0.857839\n",
            "2022-01-09 00:27:14 - INFO:\ttrain #1660 lr = 8.47e-05 loss = 0.086225 train = 0.977148 valid = 0.852153\n",
            "2022-01-09 00:27:23 - INFO:\ttrain #1670 lr = 8.46e-05 loss = 0.100793 train = 0.971289 valid = 0.872868\n",
            "2022-01-09 00:27:33 - INFO:\ttrain #1680 lr = 8.45e-05 loss = 0.075907 train = 0.977344 valid = 0.871649\n",
            "2022-01-09 00:27:42 - INFO:\ttrain #1690 lr = 8.45e-05 loss = 0.074379 train = 0.977734 valid = 0.862713\n",
            "2022-01-09 00:27:50 - INFO:\ttrain #1700 lr = 8.44e-05 loss = 0.096966 train = 0.972266 valid = 0.866369\n",
            "2022-01-09 00:27:52 - INFO:\tSaved test = 0.850486\n",
            "2022-01-09 00:28:01 - INFO:\ttrain #1710 lr = 8.43e-05 loss = 0.082169 train = 0.976562 valid = 0.864744\n",
            "2022-01-09 00:28:10 - INFO:\ttrain #1720 lr = 8.42e-05 loss = 0.086925 train = 0.977539 valid = 0.857839\n",
            "2022-01-09 00:28:19 - INFO:\ttrain #1730 lr = 8.41e-05 loss = 0.074547 train = 0.978711 valid = 0.867587\n",
            "2022-01-09 00:28:28 - INFO:\ttrain #1740 lr = 8.40e-05 loss = 0.093075 train = 0.973437 valid = 0.867994\n",
            "2022-01-09 00:28:38 - INFO:\ttrain #1750 lr = 8.39e-05 loss = 0.066700 train = 0.979883 valid = 0.862307\n",
            "2022-01-09 00:28:47 - INFO:\ttrain #1760 lr = 8.39e-05 loss = 0.072410 train = 0.979297 valid = 0.871243\n",
            "2022-01-09 00:28:57 - INFO:\ttrain #1770 lr = 8.38e-05 loss = 0.084887 train = 0.977734 valid = 0.870837\n",
            "2022-01-09 00:29:06 - INFO:\ttrain #1780 lr = 8.37e-05 loss = 0.074653 train = 0.976953 valid = 0.863526\n",
            "2022-01-09 00:29:15 - INFO:\ttrain #1790 lr = 8.36e-05 loss = 0.076358 train = 0.979102 valid = 0.869212\n",
            "2022-01-09 00:29:24 - INFO:\ttrain #1800 lr = 8.35e-05 loss = 0.087422 train = 0.974805 valid = 0.871649\n",
            "2022-01-09 00:29:25 - INFO:\tSaved test = 0.855348\n",
            "2022-01-09 00:29:34 - INFO:\ttrain #1810 lr = 8.34e-05 loss = 0.066122 train = 0.982422 valid = 0.866369\n",
            "2022-01-09 00:29:43 - INFO:\ttrain #1820 lr = 8.34e-05 loss = 0.081732 train = 0.976562 valid = 0.865150\n",
            "2022-01-09 00:29:52 - INFO:\ttrain #1830 lr = 8.33e-05 loss = 0.070993 train = 0.982617 valid = 0.867587\n",
            "2022-01-09 00:30:01 - INFO:\ttrain #1840 lr = 8.32e-05 loss = 0.077075 train = 0.977734 valid = 0.850528\n",
            "2022-01-09 00:30:10 - INFO:\ttrain #1850 lr = 8.31e-05 loss = 0.057011 train = 0.983594 valid = 0.867587\n",
            "2022-01-09 00:30:19 - INFO:\ttrain #1860 lr = 8.30e-05 loss = 0.070604 train = 0.980273 valid = 0.869212\n",
            "2022-01-09 00:30:28 - INFO:\ttrain #1870 lr = 8.29e-05 loss = 0.088309 train = 0.976953 valid = 0.856621\n",
            "2022-01-09 00:30:37 - INFO:\ttrain #1880 lr = 8.29e-05 loss = 0.069236 train = 0.982031 valid = 0.858652\n",
            "2022-01-09 00:30:46 - INFO:\ttrain #1890 lr = 8.28e-05 loss = 0.070163 train = 0.983008 valid = 0.865963\n",
            "2022-01-09 00:30:55 - INFO:\ttrain #1900 lr = 8.27e-05 loss = 0.073392 train = 0.980078 valid = 0.869618\n",
            "2022-01-09 00:30:56 - INFO:\tSaved test = 0.852107\n",
            "2022-01-09 00:31:05 - INFO:\ttrain #1910 lr = 8.26e-05 loss = 0.073672 train = 0.981641 valid = 0.871243\n",
            "2022-01-09 00:31:14 - INFO:\ttrain #1920 lr = 8.25e-05 loss = 0.064626 train = 0.982031 valid = 0.874492\n",
            "2022-01-09 00:31:23 - INFO:\ttrain #1930 lr = 8.24e-05 loss = 0.073926 train = 0.978906 valid = 0.865556\n",
            "2022-01-09 00:31:32 - INFO:\ttrain #1940 lr = 8.24e-05 loss = 0.061901 train = 0.982227 valid = 0.876117\n",
            "2022-01-09 00:31:41 - INFO:\ttrain #1950 lr = 8.23e-05 loss = 0.052110 train = 0.985352 valid = 0.883022 updated\n",
            "2022-01-09 00:31:50 - INFO:\ttrain #1960 lr = 8.22e-05 loss = 0.067340 train = 0.983008 valid = 0.857027\n",
            "2022-01-09 00:31:59 - INFO:\ttrain #1970 lr = 8.21e-05 loss = 0.067862 train = 0.981836 valid = 0.854590\n",
            "2022-01-09 00:32:08 - INFO:\ttrain #1980 lr = 8.20e-05 loss = 0.068083 train = 0.984766 valid = 0.877742\n",
            "2022-01-09 00:32:17 - INFO:\ttrain #1990 lr = 8.20e-05 loss = 0.059414 train = 0.982227 valid = 0.859058\n",
            "2022-01-09 00:32:26 - INFO:\ttrain #2000 lr = 8.19e-05 loss = 0.067892 train = 0.981836 valid = 0.878148\n",
            "2022-01-09 00:32:28 - INFO:\tSaved test = 0.856159\n",
            "2022-01-09 00:32:37 - INFO:\ttrain #2010 lr = 8.18e-05 loss = 0.057791 train = 0.988672 valid = 0.867587\n",
            "2022-01-09 00:32:46 - INFO:\ttrain #2020 lr = 8.17e-05 loss = 0.084812 train = 0.979688 valid = 0.872461\n",
            "2022-01-09 00:32:55 - INFO:\ttrain #2030 lr = 8.16e-05 loss = 0.065579 train = 0.983203 valid = 0.870837\n",
            "2022-01-09 00:33:04 - INFO:\ttrain #2040 lr = 8.15e-05 loss = 0.073315 train = 0.980664 valid = 0.861495\n",
            "2022-01-09 00:33:14 - INFO:\ttrain #2050 lr = 8.15e-05 loss = 0.094765 train = 0.977344 valid = 0.870837\n",
            "2022-01-09 00:33:23 - INFO:\ttrain #2060 lr = 8.14e-05 loss = 0.064767 train = 0.984570 valid = 0.873680\n",
            "2022-01-09 00:33:32 - INFO:\ttrain #2070 lr = 8.13e-05 loss = 0.063889 train = 0.984766 valid = 0.867994\n",
            "2022-01-09 00:33:41 - INFO:\ttrain #2080 lr = 8.12e-05 loss = 0.076669 train = 0.980664 valid = 0.850528\n",
            "2022-01-09 00:33:50 - INFO:\ttrain #2090 lr = 8.11e-05 loss = 0.058747 train = 0.983984 valid = 0.873680\n",
            "2022-01-09 00:33:59 - INFO:\ttrain #2100 lr = 8.11e-05 loss = 0.081665 train = 0.978906 valid = 0.868400\n",
            "2022-01-09 00:34:00 - INFO:\tSaved test = 0.842382\n",
            "2022-01-09 00:34:09 - INFO:\ttrain #2110 lr = 8.10e-05 loss = 0.060381 train = 0.984375 valid = 0.846872\n",
            "2022-01-09 00:34:19 - INFO:\ttrain #2120 lr = 8.09e-05 loss = 0.062063 train = 0.983984 valid = 0.863932\n",
            "2022-01-09 00:34:28 - INFO:\ttrain #2130 lr = 8.08e-05 loss = 0.055948 train = 0.983203 valid = 0.872461\n",
            "2022-01-09 00:34:37 - INFO:\ttrain #2140 lr = 8.07e-05 loss = 0.059433 train = 0.983203 valid = 0.880585\n",
            "2022-01-09 00:34:46 - INFO:\ttrain #2150 lr = 8.07e-05 loss = 0.065621 train = 0.982617 valid = 0.862713\n",
            "2022-01-09 00:34:55 - INFO:\ttrain #2160 lr = 8.06e-05 loss = 0.063202 train = 0.981641 valid = 0.864744\n",
            "2022-01-09 00:35:04 - INFO:\ttrain #2170 lr = 8.05e-05 loss = 0.050252 train = 0.986719 valid = 0.871243\n",
            "2022-01-09 00:35:13 - INFO:\ttrain #2180 lr = 8.04e-05 loss = 0.058709 train = 0.985547 valid = 0.866775\n",
            "2022-01-09 00:35:22 - INFO:\ttrain #2190 lr = 8.03e-05 loss = 0.047491 train = 0.986719 valid = 0.867587\n",
            "2022-01-09 00:35:31 - INFO:\ttrain #2200 lr = 8.03e-05 loss = 0.076543 train = 0.980859 valid = 0.859058\n",
            "2022-01-09 00:35:33 - INFO:\tSaved test = 0.848460\n",
            "2022-01-09 00:35:42 - INFO:\ttrain #2210 lr = 8.02e-05 loss = 0.059833 train = 0.984375 valid = 0.860682\n",
            "2022-01-09 00:35:51 - INFO:\ttrain #2220 lr = 8.01e-05 loss = 0.056918 train = 0.983789 valid = 0.856621\n",
            "2022-01-09 00:36:00 - INFO:\ttrain #2230 lr = 8.00e-05 loss = 0.074203 train = 0.981445 valid = 0.867181\n",
            "2022-01-09 00:36:09 - INFO:\ttrain #2240 lr = 7.99e-05 loss = 0.051290 train = 0.985938 valid = 0.865150\n",
            "2022-01-09 00:36:18 - INFO:\ttrain #2250 lr = 7.99e-05 loss = 0.054524 train = 0.984375 valid = 0.844029\n",
            "2022-01-09 00:36:27 - INFO:\ttrain #2260 lr = 7.98e-05 loss = 0.068379 train = 0.983398 valid = 0.874898\n",
            "2022-01-09 00:36:37 - INFO:\ttrain #2270 lr = 7.97e-05 loss = 0.070251 train = 0.984961 valid = 0.860682\n",
            "2022-01-09 00:36:46 - INFO:\ttrain #2280 lr = 7.96e-05 loss = 0.122706 train = 0.975195 valid = 0.873680\n",
            "2022-01-09 00:36:55 - INFO:\ttrain #2290 lr = 7.95e-05 loss = 0.041486 train = 0.987695 valid = 0.860276\n",
            "2022-01-09 00:37:04 - INFO:\ttrain #2300 lr = 7.95e-05 loss = 0.043213 train = 0.986133 valid = 0.855808\n",
            "2022-01-09 00:37:05 - INFO:\tSaved test = 0.832658\n",
            "2022-01-09 00:37:14 - INFO:\ttrain #2310 lr = 7.94e-05 loss = 0.052788 train = 0.987109 valid = 0.871649\n",
            "2022-01-09 00:37:23 - INFO:\ttrain #2320 lr = 7.93e-05 loss = 0.050466 train = 0.986719 valid = 0.853777\n",
            "2022-01-09 00:37:32 - INFO:\ttrain #2330 lr = 7.92e-05 loss = 0.059369 train = 0.984570 valid = 0.867181\n",
            "2022-01-09 00:37:41 - INFO:\ttrain #2340 lr = 7.91e-05 loss = 0.062663 train = 0.982617 valid = 0.840780\n",
            "2022-01-09 00:37:50 - INFO:\ttrain #2350 lr = 7.91e-05 loss = 0.060747 train = 0.983594 valid = 0.863119\n",
            "2022-01-09 00:37:59 - INFO:\ttrain #2360 lr = 7.90e-05 loss = 0.061676 train = 0.984766 valid = 0.868400\n",
            "2022-01-09 00:38:08 - INFO:\ttrain #2370 lr = 7.89e-05 loss = 0.058542 train = 0.983984 valid = 0.858245\n",
            "2022-01-09 00:38:17 - INFO:\ttrain #2380 lr = 7.88e-05 loss = 0.048949 train = 0.985547 valid = 0.863932\n",
            "2022-01-09 00:38:26 - INFO:\ttrain #2390 lr = 7.87e-05 loss = 0.047918 train = 0.988086 valid = 0.857433\n",
            "2022-01-09 00:38:35 - INFO:\ttrain #2400 lr = 7.87e-05 loss = 0.054649 train = 0.987109 valid = 0.858652\n",
            "2022-01-09 00:38:36 - INFO:\tSaved test = 0.849271\n",
            "2022-01-09 00:38:45 - INFO:\ttrain #2410 lr = 7.86e-05 loss = 0.049460 train = 0.987305 valid = 0.867994\n",
            "2022-01-09 00:38:54 - INFO:\ttrain #2420 lr = 7.85e-05 loss = 0.051619 train = 0.986328 valid = 0.874086\n",
            "2022-01-09 00:39:03 - INFO:\ttrain #2430 lr = 7.84e-05 loss = 0.050796 train = 0.987891 valid = 0.852965\n",
            "2022-01-09 00:39:12 - INFO:\ttrain #2440 lr = 7.83e-05 loss = 0.061610 train = 0.983789 valid = 0.860276\n",
            "2022-01-09 00:39:21 - INFO:\ttrain #2450 lr = 7.83e-05 loss = 0.053874 train = 0.986719 valid = 0.875711\n",
            "2022-01-09 00:39:30 - INFO:\ttrain #2460 lr = 7.82e-05 loss = 0.043171 train = 0.987109 valid = 0.867994\n",
            "2022-01-09 00:39:39 - INFO:\ttrain #2470 lr = 7.81e-05 loss = 0.049739 train = 0.986914 valid = 0.865150\n",
            "2022-01-09 00:39:48 - INFO:\ttrain #2480 lr = 7.80e-05 loss = 0.051049 train = 0.986914 valid = 0.874898\n",
            "2022-01-09 00:39:57 - INFO:\ttrain #2490 lr = 7.80e-05 loss = 0.049290 train = 0.987500 valid = 0.861901\n",
            "2022-01-09 00:40:06 - INFO:\ttrain #2500 lr = 7.79e-05 loss = 0.058804 train = 0.987109 valid = 0.870024\n",
            "2022-01-09 00:40:07 - INFO:\tSaved test = 0.846840\n",
            "2022-01-09 00:40:16 - INFO:\ttrain #2510 lr = 7.78e-05 loss = 0.058542 train = 0.985547 valid = 0.858652\n",
            "2022-01-09 00:40:25 - INFO:\ttrain #2520 lr = 7.77e-05 loss = 0.053828 train = 0.987500 valid = 0.852965\n",
            "2022-01-09 00:40:34 - INFO:\ttrain #2530 lr = 7.76e-05 loss = 0.060261 train = 0.984766 valid = 0.869618\n",
            "2022-01-09 00:40:43 - INFO:\ttrain #2540 lr = 7.76e-05 loss = 0.075923 train = 0.983008 valid = 0.870024\n",
            "2022-01-09 00:40:52 - INFO:\ttrain #2550 lr = 7.75e-05 loss = 0.039946 train = 0.990234 valid = 0.871649\n",
            "2022-01-09 00:41:01 - INFO:\ttrain #2560 lr = 7.74e-05 loss = 0.037625 train = 0.991602 valid = 0.870431\n",
            "2022-01-09 00:41:10 - INFO:\ttrain #2570 lr = 7.73e-05 loss = 0.051997 train = 0.987500 valid = 0.870431\n",
            "2022-01-09 00:41:19 - INFO:\ttrain #2580 lr = 7.73e-05 loss = 0.051410 train = 0.986523 valid = 0.864744\n",
            "2022-01-09 00:41:28 - INFO:\ttrain #2590 lr = 7.72e-05 loss = 0.052568 train = 0.987109 valid = 0.873274\n",
            "2022-01-09 00:41:37 - INFO:\ttrain #2600 lr = 7.71e-05 loss = 0.048529 train = 0.989258 valid = 0.880585\n",
            "2022-01-09 00:41:39 - INFO:\tSaved test = 0.863857\n",
            "2022-01-09 00:41:48 - INFO:\ttrain #2610 lr = 7.70e-05 loss = 0.051848 train = 0.988281 valid = 0.867587\n",
            "2022-01-09 00:41:56 - INFO:\ttrain #2620 lr = 7.70e-05 loss = 0.034415 train = 0.990820 valid = 0.867994\n",
            "2022-01-09 00:42:05 - INFO:\ttrain #2630 lr = 7.69e-05 loss = 0.038158 train = 0.988867 valid = 0.860276\n",
            "2022-01-09 00:42:14 - INFO:\ttrain #2640 lr = 7.68e-05 loss = 0.060490 train = 0.985352 valid = 0.874086\n",
            "2022-01-09 00:42:23 - INFO:\ttrain #2650 lr = 7.67e-05 loss = 0.039325 train = 0.989844 valid = 0.870431\n",
            "2022-01-09 00:42:32 - INFO:\ttrain #2660 lr = 7.66e-05 loss = 0.043659 train = 0.989453 valid = 0.865556\n",
            "2022-01-09 00:42:41 - INFO:\ttrain #2670 lr = 7.66e-05 loss = 0.043812 train = 0.988672 valid = 0.863119\n",
            "2022-01-09 00:42:50 - INFO:\ttrain #2680 lr = 7.65e-05 loss = 0.040640 train = 0.991016 valid = 0.862713\n",
            "2022-01-09 00:42:59 - INFO:\ttrain #2690 lr = 7.64e-05 loss = 0.048417 train = 0.989453 valid = 0.866775\n",
            "2022-01-09 00:43:08 - INFO:\ttrain #2700 lr = 7.63e-05 loss = 0.037568 train = 0.991211 valid = 0.870024\n",
            "2022-01-09 00:43:10 - INFO:\tSaved test = 0.856564\n",
            "2022-01-09 00:43:19 - INFO:\ttrain #2710 lr = 7.63e-05 loss = 0.073349 train = 0.983594 valid = 0.861089\n",
            "2022-01-09 00:43:28 - INFO:\ttrain #2720 lr = 7.62e-05 loss = 0.023388 train = 0.993359 valid = 0.869618\n",
            "2022-01-09 00:43:37 - INFO:\ttrain #2730 lr = 7.61e-05 loss = 0.039854 train = 0.988672 valid = 0.884647 updated\n",
            "2022-01-09 00:43:46 - INFO:\ttrain #2740 lr = 7.60e-05 loss = 0.037760 train = 0.990234 valid = 0.866369\n",
            "2022-01-09 00:43:55 - INFO:\ttrain #2750 lr = 7.60e-05 loss = 0.040254 train = 0.989844 valid = 0.873680\n",
            "2022-01-09 00:44:04 - INFO:\ttrain #2760 lr = 7.59e-05 loss = 0.038225 train = 0.991992 valid = 0.870024\n",
            "2022-01-09 00:44:13 - INFO:\ttrain #2770 lr = 7.58e-05 loss = 0.037378 train = 0.990820 valid = 0.865150\n",
            "2022-01-09 00:44:21 - INFO:\ttrain #2780 lr = 7.57e-05 loss = 0.042686 train = 0.988867 valid = 0.867994\n",
            "2022-01-09 00:44:30 - INFO:\ttrain #2790 lr = 7.57e-05 loss = 0.037366 train = 0.990430 valid = 0.872868\n",
            "2022-01-09 00:44:39 - INFO:\ttrain #2800 lr = 7.56e-05 loss = 0.053083 train = 0.987500 valid = 0.854996\n",
            "2022-01-09 00:44:40 - INFO:\tSaved test = 0.853323\n",
            "2022-01-09 00:44:49 - INFO:\ttrain #2810 lr = 7.55e-05 loss = 0.040655 train = 0.990039 valid = 0.855402\n",
            "2022-01-09 00:44:58 - INFO:\ttrain #2820 lr = 7.54e-05 loss = 0.057151 train = 0.987500 valid = 0.869212\n",
            "2022-01-09 00:45:06 - INFO:\ttrain #2830 lr = 7.54e-05 loss = 0.049005 train = 0.987695 valid = 0.869212\n",
            "2022-01-09 00:45:15 - INFO:\ttrain #2840 lr = 7.53e-05 loss = 0.055162 train = 0.985156 valid = 0.859870\n",
            "2022-01-09 00:45:23 - INFO:\ttrain #2850 lr = 7.52e-05 loss = 0.042063 train = 0.989258 valid = 0.875305\n",
            "2022-01-09 00:45:32 - INFO:\ttrain #2860 lr = 7.51e-05 loss = 0.030999 train = 0.992383 valid = 0.863119\n",
            "2022-01-09 00:45:41 - INFO:\ttrain #2870 lr = 7.51e-05 loss = 0.054336 train = 0.987695 valid = 0.866369\n",
            "2022-01-09 00:45:49 - INFO:\ttrain #2880 lr = 7.50e-05 loss = 0.036960 train = 0.990820 valid = 0.874898\n",
            "2022-01-09 00:45:58 - INFO:\ttrain #2890 lr = 7.49e-05 loss = 0.041690 train = 0.989453 valid = 0.869212\n",
            "2022-01-09 00:46:07 - INFO:\ttrain #2900 lr = 7.48e-05 loss = 0.040604 train = 0.991406 valid = 0.864744\n",
            "2022-01-09 00:46:08 - INFO:\tSaved test = 0.852512\n",
            "2022-01-09 00:46:17 - INFO:\ttrain #2910 lr = 7.48e-05 loss = 0.046828 train = 0.989453 valid = 0.876117\n",
            "2022-01-09 00:46:25 - INFO:\ttrain #2920 lr = 7.47e-05 loss = 0.039554 train = 0.991602 valid = 0.875305\n",
            "2022-01-09 00:46:34 - INFO:\ttrain #2930 lr = 7.46e-05 loss = 0.039246 train = 0.990625 valid = 0.872868\n",
            "2022-01-09 00:46:43 - INFO:\ttrain #2940 lr = 7.45e-05 loss = 0.039603 train = 0.989648 valid = 0.864338\n",
            "2022-01-09 00:46:52 - INFO:\ttrain #2950 lr = 7.45e-05 loss = 0.051056 train = 0.989844 valid = 0.868400\n",
            "2022-01-09 00:47:00 - INFO:\ttrain #2960 lr = 7.44e-05 loss = 0.041505 train = 0.991602 valid = 0.862307\n",
            "2022-01-09 00:47:09 - INFO:\ttrain #2970 lr = 7.43e-05 loss = 0.027679 train = 0.992578 valid = 0.881397\n",
            "2022-01-09 00:47:18 - INFO:\ttrain #2980 lr = 7.42e-05 loss = 0.027659 train = 0.993359 valid = 0.875305\n",
            "2022-01-09 00:47:27 - INFO:\ttrain #2990 lr = 7.42e-05 loss = 0.038647 train = 0.991406 valid = 0.870837\n",
            "2022-01-09 00:47:35 - INFO:\ttrain #3000 lr = 7.41e-05 loss = 0.038690 train = 0.991602 valid = 0.865150\n",
            "2022-01-09 00:47:36 - INFO:\tSaved test = 0.847650\n",
            "2022-01-09 00:47:45 - INFO:\ttrain #3010 lr = 7.40e-05 loss = 0.050959 train = 0.986523 valid = 0.870431\n",
            "2022-01-09 00:47:55 - INFO:\ttrain #3020 lr = 7.39e-05 loss = 0.038649 train = 0.990039 valid = 0.865963\n",
            "2022-01-09 00:48:04 - INFO:\ttrain #3030 lr = 7.39e-05 loss = 0.027624 train = 0.993555 valid = 0.875305\n",
            "2022-01-09 00:48:13 - INFO:\ttrain #3040 lr = 7.38e-05 loss = 0.024495 train = 0.993945 valid = 0.869212\n",
            "2022-01-09 00:48:21 - INFO:\ttrain #3050 lr = 7.37e-05 loss = 0.034059 train = 0.992578 valid = 0.853777\n",
            "2022-01-09 00:48:30 - INFO:\ttrain #3060 lr = 7.36e-05 loss = 0.035169 train = 0.990820 valid = 0.868806\n",
            "2022-01-09 00:48:39 - INFO:\ttrain #3070 lr = 7.36e-05 loss = 0.074251 train = 0.986328 valid = 0.860682\n",
            "2022-01-09 00:48:47 - INFO:\ttrain #3080 lr = 7.35e-05 loss = 0.026017 train = 0.993945 valid = 0.867994\n",
            "2022-01-09 00:48:57 - INFO:\ttrain #3090 lr = 7.34e-05 loss = 0.044827 train = 0.987500 valid = 0.839561\n",
            "2022-01-09 00:49:06 - INFO:\ttrain #3100 lr = 7.33e-05 loss = 0.043843 train = 0.990625 valid = 0.867994\n",
            "2022-01-09 00:49:07 - INFO:\tSaved test = 0.852917\n",
            "2022-01-09 00:49:16 - INFO:\ttrain #3110 lr = 7.33e-05 loss = 0.046708 train = 0.990039 valid = 0.870431\n",
            "2022-01-09 00:49:26 - INFO:\ttrain #3120 lr = 7.32e-05 loss = 0.027643 train = 0.992383 valid = 0.870024\n",
            "2022-01-09 00:49:35 - INFO:\ttrain #3130 lr = 7.31e-05 loss = 0.039241 train = 0.990430 valid = 0.858652\n",
            "2022-01-09 00:49:44 - INFO:\ttrain #3140 lr = 7.31e-05 loss = 0.033791 train = 0.992969 valid = 0.870837\n",
            "2022-01-09 00:49:53 - INFO:\ttrain #3150 lr = 7.30e-05 loss = 0.048270 train = 0.991797 valid = 0.873680\n",
            "2022-01-09 00:50:03 - INFO:\ttrain #3160 lr = 7.29e-05 loss = 0.032763 train = 0.992773 valid = 0.870431\n",
            "2022-01-09 00:50:12 - INFO:\ttrain #3170 lr = 7.28e-05 loss = 0.029935 train = 0.991211 valid = 0.869212\n",
            "2022-01-09 00:50:21 - INFO:\ttrain #3180 lr = 7.28e-05 loss = 0.029377 train = 0.993164 valid = 0.872055\n",
            "2022-01-09 00:50:30 - INFO:\ttrain #3190 lr = 7.27e-05 loss = 0.031625 train = 0.992578 valid = 0.868806\n",
            "2022-01-09 00:50:40 - INFO:\ttrain #3200 lr = 7.26e-05 loss = 0.028992 train = 0.994141 valid = 0.872868\n",
            "2022-01-09 00:50:41 - INFO:\tSaved test = 0.856159\n",
            "2022-01-09 00:50:50 - INFO:\ttrain #3210 lr = 7.25e-05 loss = 0.070140 train = 0.988867 valid = 0.863526\n",
            "2022-01-09 00:51:00 - INFO:\ttrain #3220 lr = 7.25e-05 loss = 0.028508 train = 0.993164 valid = 0.859870\n",
            "2022-01-09 00:51:09 - INFO:\ttrain #3230 lr = 7.24e-05 loss = 0.029263 train = 0.992578 valid = 0.855402\n",
            "2022-01-09 00:51:18 - INFO:\ttrain #3240 lr = 7.23e-05 loss = 0.046336 train = 0.989844 valid = 0.870837\n",
            "2022-01-09 00:51:27 - INFO:\ttrain #3250 lr = 7.23e-05 loss = 0.023568 train = 0.994336 valid = 0.873680\n",
            "2022-01-09 00:51:36 - INFO:\ttrain #3260 lr = 7.22e-05 loss = 0.032393 train = 0.992969 valid = 0.867994\n",
            "2022-01-09 00:51:44 - INFO:\ttrain #3270 lr = 7.21e-05 loss = 0.046785 train = 0.992383 valid = 0.861495\n",
            "2022-01-09 00:51:53 - INFO:\ttrain #3280 lr = 7.20e-05 loss = 0.026773 train = 0.993555 valid = 0.867994\n",
            "2022-01-09 00:52:02 - INFO:\ttrain #3290 lr = 7.20e-05 loss = 0.045389 train = 0.991797 valid = 0.869212\n",
            "2022-01-09 00:52:10 - INFO:\ttrain #3300 lr = 7.19e-05 loss = 0.056708 train = 0.988672 valid = 0.869212\n",
            "2022-01-09 00:52:12 - INFO:\tSaved test = 0.844814\n",
            "2022-01-09 00:52:20 - INFO:\ttrain #3310 lr = 7.18e-05 loss = 0.052251 train = 0.991211 valid = 0.867587\n",
            "2022-01-09 00:52:29 - INFO:\ttrain #3320 lr = 7.17e-05 loss = 0.025490 train = 0.993750 valid = 0.867587\n",
            "2022-01-09 00:52:38 - INFO:\ttrain #3330 lr = 7.17e-05 loss = 0.028357 train = 0.994141 valid = 0.870431\n",
            "2022-01-09 00:52:46 - INFO:\ttrain #3340 lr = 7.16e-05 loss = 0.026896 train = 0.993945 valid = 0.866775\n",
            "2022-01-09 00:52:55 - INFO:\ttrain #3350 lr = 7.15e-05 loss = 0.031527 train = 0.993945 valid = 0.862307\n",
            "2022-01-09 00:53:03 - INFO:\ttrain #3360 lr = 7.15e-05 loss = 0.030518 train = 0.992969 valid = 0.873274\n",
            "2022-01-09 00:53:12 - INFO:\ttrain #3370 lr = 7.14e-05 loss = 0.021420 train = 0.994531 valid = 0.876117\n",
            "2022-01-09 00:53:20 - INFO:\ttrain #3380 lr = 7.13e-05 loss = 0.037152 train = 0.992773 valid = 0.877335\n",
            "2022-01-09 00:53:29 - INFO:\ttrain #3390 lr = 7.12e-05 loss = 0.024956 train = 0.995508 valid = 0.876929\n",
            "2022-01-09 00:53:38 - INFO:\ttrain #3400 lr = 7.12e-05 loss = 0.033253 train = 0.993555 valid = 0.870431\n",
            "2022-01-09 00:53:39 - INFO:\tSaved test = 0.844814\n",
            "2022-01-09 00:53:47 - INFO:\ttrain #3410 lr = 7.11e-05 loss = 0.071808 train = 0.990430 valid = 0.874492\n",
            "2022-01-09 00:53:56 - INFO:\ttrain #3420 lr = 7.10e-05 loss = 0.039322 train = 0.990625 valid = 0.867587\n",
            "2022-01-09 00:54:05 - INFO:\ttrain #3430 lr = 7.10e-05 loss = 0.028651 train = 0.992969 valid = 0.869618\n",
            "2022-01-09 00:54:13 - INFO:\ttrain #3440 lr = 7.09e-05 loss = 0.024420 train = 0.993945 valid = 0.877742\n",
            "2022-01-09 00:54:22 - INFO:\ttrain #3450 lr = 7.08e-05 loss = 0.028717 train = 0.993555 valid = 0.871243\n",
            "2022-01-09 00:54:31 - INFO:\ttrain #3460 lr = 7.08e-05 loss = 0.025841 train = 0.994727 valid = 0.864744\n",
            "2022-01-09 00:54:39 - INFO:\ttrain #3470 lr = 7.07e-05 loss = 0.024931 train = 0.994336 valid = 0.866369\n",
            "2022-01-09 00:54:48 - INFO:\ttrain #3480 lr = 7.06e-05 loss = 0.025768 train = 0.993359 valid = 0.870837\n",
            "2022-01-09 00:54:57 - INFO:\ttrain #3490 lr = 7.05e-05 loss = 0.014636 train = 0.996680 valid = 0.868400\n",
            "2022-01-09 00:55:06 - INFO:\ttrain #3500 lr = 7.05e-05 loss = 0.025223 train = 0.994141 valid = 0.872055\n",
            "2022-01-09 00:55:07 - INFO:\tSaved test = 0.848865\n",
            "2022-01-09 00:55:16 - INFO:\ttrain #3510 lr = 7.04e-05 loss = 0.024285 train = 0.995703 valid = 0.866369\n",
            "2022-01-09 00:55:26 - INFO:\ttrain #3520 lr = 7.03e-05 loss = 0.025079 train = 0.995117 valid = 0.867181\n",
            "2022-01-09 00:55:34 - INFO:\ttrain #3530 lr = 7.03e-05 loss = 0.019804 train = 0.996094 valid = 0.876929\n",
            "2022-01-09 00:55:43 - INFO:\ttrain #3540 lr = 7.02e-05 loss = 0.021181 train = 0.994727 valid = 0.867181\n",
            "2022-01-09 00:55:51 - INFO:\ttrain #3550 lr = 7.01e-05 loss = 0.029586 train = 0.993164 valid = 0.877335\n",
            "2022-01-09 00:56:00 - INFO:\ttrain #3560 lr = 7.00e-05 loss = 0.042971 train = 0.992969 valid = 0.869212\n",
            "2022-01-09 00:56:09 - INFO:\ttrain #3570 lr = 7.00e-05 loss = 0.012369 train = 0.996680 valid = 0.873680\n",
            "2022-01-09 00:56:17 - INFO:\ttrain #3580 lr = 6.99e-05 loss = 0.029723 train = 0.993750 valid = 0.865150\n",
            "2022-01-09 00:56:26 - INFO:\ttrain #3590 lr = 6.98e-05 loss = 0.040404 train = 0.992188 valid = 0.878148\n",
            "2022-01-09 00:56:35 - INFO:\ttrain #3600 lr = 6.98e-05 loss = 0.046854 train = 0.992188 valid = 0.878148\n",
            "2022-01-09 00:56:36 - INFO:\tSaved test = 0.850891\n",
            "2022-01-09 00:56:44 - INFO:\ttrain #3610 lr = 6.97e-05 loss = 0.028599 train = 0.994727 valid = 0.871649\n",
            "2022-01-09 00:56:53 - INFO:\ttrain #3620 lr = 6.96e-05 loss = 0.018229 train = 0.996484 valid = 0.867994\n",
            "2022-01-09 00:57:02 - INFO:\ttrain #3630 lr = 6.96e-05 loss = 0.016753 train = 0.996094 valid = 0.865963\n",
            "2022-01-09 00:57:10 - INFO:\ttrain #3640 lr = 6.95e-05 loss = 0.019181 train = 0.995898 valid = 0.852559\n",
            "2022-01-09 00:57:19 - INFO:\ttrain #3650 lr = 6.94e-05 loss = 0.055703 train = 0.987500 valid = 0.867181\n",
            "2022-01-09 00:57:28 - INFO:\ttrain #3660 lr = 6.93e-05 loss = 0.031608 train = 0.993164 valid = 0.879366\n",
            "2022-01-09 00:57:36 - INFO:\ttrain #3670 lr = 6.93e-05 loss = 0.037747 train = 0.992383 valid = 0.870024\n",
            "2022-01-09 00:57:45 - INFO:\ttrain #3680 lr = 6.92e-05 loss = 0.032784 train = 0.993750 valid = 0.869212\n",
            "2022-01-09 00:57:54 - INFO:\ttrain #3690 lr = 6.91e-05 loss = 0.041486 train = 0.993945 valid = 0.870431\n",
            "2022-01-09 00:58:02 - INFO:\ttrain #3700 lr = 6.91e-05 loss = 0.019165 train = 0.996484 valid = 0.864338\n",
            "2022-01-09 00:58:04 - INFO:\tSaved test = 0.839951\n",
            "2022-01-09 00:58:12 - INFO:\ttrain #3710 lr = 6.90e-05 loss = 0.025090 train = 0.994141 valid = 0.878554\n",
            "2022-01-09 00:58:21 - INFO:\ttrain #3720 lr = 6.89e-05 loss = 0.016513 train = 0.995313 valid = 0.876929\n",
            "2022-01-09 00:58:30 - INFO:\ttrain #3730 lr = 6.89e-05 loss = 0.022012 train = 0.994727 valid = 0.880585\n",
            "2022-01-09 00:58:39 - INFO:\ttrain #3740 lr = 6.88e-05 loss = 0.070121 train = 0.991211 valid = 0.871243\n",
            "2022-01-09 00:58:49 - INFO:\ttrain #3750 lr = 6.87e-05 loss = 0.013134 train = 0.996289 valid = 0.870837\n",
            "2022-01-09 00:58:57 - INFO:\ttrain #3760 lr = 6.87e-05 loss = 0.025411 train = 0.996484 valid = 0.867994\n",
            "2022-01-09 00:59:07 - INFO:\ttrain #3770 lr = 6.86e-05 loss = 0.020832 train = 0.995898 valid = 0.872461\n",
            "2022-01-09 00:59:16 - INFO:\ttrain #3780 lr = 6.85e-05 loss = 0.017868 train = 0.996094 valid = 0.872461\n",
            "2022-01-09 00:59:25 - INFO:\ttrain #3790 lr = 6.85e-05 loss = 0.042336 train = 0.992383 valid = 0.866369\n",
            "2022-01-09 00:59:34 - INFO:\ttrain #3800 lr = 6.84e-05 loss = 0.017767 train = 0.995898 valid = 0.875305\n",
            "2022-01-09 00:59:35 - INFO:\tSaved test = 0.852917\n",
            "2022-01-09 00:59:44 - INFO:\ttrain #3810 lr = 6.83e-05 loss = 0.035266 train = 0.992969 valid = 0.864338\n",
            "2022-01-09 00:59:53 - INFO:\ttrain #3820 lr = 6.82e-05 loss = 0.038476 train = 0.991406 valid = 0.854184\n",
            "2022-01-09 01:00:03 - INFO:\ttrain #3830 lr = 6.82e-05 loss = 0.027252 train = 0.994141 valid = 0.874086\n",
            "2022-01-09 01:00:12 - INFO:\ttrain #3840 lr = 6.81e-05 loss = 0.030039 train = 0.993750 valid = 0.871243\n",
            "2022-01-09 01:00:21 - INFO:\ttrain #3850 lr = 6.80e-05 loss = 0.024002 train = 0.995313 valid = 0.876523\n",
            "2022-01-09 01:00:30 - INFO:\ttrain #3860 lr = 6.80e-05 loss = 0.036777 train = 0.993555 valid = 0.859870\n",
            "2022-01-09 01:00:39 - INFO:\ttrain #3870 lr = 6.79e-05 loss = 0.028416 train = 0.994336 valid = 0.867181\n",
            "2022-01-09 01:00:48 - INFO:\ttrain #3880 lr = 6.78e-05 loss = 0.016020 train = 0.996094 valid = 0.876929\n",
            "2022-01-09 01:00:57 - INFO:\ttrain #3890 lr = 6.78e-05 loss = 0.044755 train = 0.991992 valid = 0.871649\n",
            "2022-01-09 01:01:06 - INFO:\ttrain #3900 lr = 6.77e-05 loss = 0.021914 train = 0.994922 valid = 0.870024\n",
            "2022-01-09 01:01:07 - INFO:\tSaved test = 0.850486\n",
            "2022-01-09 01:01:16 - INFO:\ttrain #3910 lr = 6.76e-05 loss = 0.038747 train = 0.991016 valid = 0.862307\n",
            "2022-01-09 01:01:25 - INFO:\ttrain #3920 lr = 6.76e-05 loss = 0.032738 train = 0.995508 valid = 0.870024\n",
            "2022-01-09 01:01:34 - INFO:\ttrain #3930 lr = 6.75e-05 loss = 0.019236 train = 0.996680 valid = 0.866775\n",
            "2022-01-09 01:01:43 - INFO:\ttrain #3940 lr = 6.74e-05 loss = 0.027397 train = 0.994727 valid = 0.859870\n",
            "2022-01-09 01:01:52 - INFO:\ttrain #3950 lr = 6.74e-05 loss = 0.041923 train = 0.994336 valid = 0.867587\n",
            "2022-01-09 01:02:01 - INFO:\ttrain #3960 lr = 6.73e-05 loss = 0.028505 train = 0.994727 valid = 0.866369\n",
            "2022-01-09 01:02:10 - INFO:\ttrain #3970 lr = 6.72e-05 loss = 0.019019 train = 0.995898 valid = 0.865150\n",
            "2022-01-09 01:02:19 - INFO:\ttrain #3980 lr = 6.72e-05 loss = 0.026668 train = 0.994336 valid = 0.868806\n",
            "2022-01-09 01:02:27 - INFO:\ttrain #3990 lr = 6.71e-05 loss = 0.037900 train = 0.993945 valid = 0.875305\n",
            "2022-01-09 01:02:36 - INFO:\ttrain #4000 lr = 6.70e-05 loss = 0.014274 train = 0.997070 valid = 0.871649\n",
            "2022-01-09 01:02:38 - INFO:\tSaved test = 0.854943\n",
            "2022-01-09 01:02:47 - INFO:\ttrain #4010 lr = 6.70e-05 loss = 0.024663 train = 0.996094 valid = 0.876523\n",
            "2022-01-09 01:02:56 - INFO:\ttrain #4020 lr = 6.69e-05 loss = 0.015288 train = 0.997266 valid = 0.874086\n",
            "2022-01-09 01:03:05 - INFO:\ttrain #4030 lr = 6.68e-05 loss = 0.029424 train = 0.995313 valid = 0.876117\n",
            "2022-01-09 01:03:14 - INFO:\ttrain #4040 lr = 6.68e-05 loss = 0.010427 train = 0.997070 valid = 0.870837\n",
            "2022-01-09 01:03:23 - INFO:\ttrain #4050 lr = 6.67e-05 loss = 0.022567 train = 0.996680 valid = 0.885459 updated\n",
            "2022-01-09 01:03:32 - INFO:\ttrain #4060 lr = 6.66e-05 loss = 0.017664 train = 0.996680 valid = 0.879366\n",
            "2022-01-09 01:03:41 - INFO:\ttrain #4070 lr = 6.66e-05 loss = 0.012693 train = 0.998047 valid = 0.879366\n",
            "2022-01-09 01:03:51 - INFO:\ttrain #4080 lr = 6.65e-05 loss = 0.026602 train = 0.995898 valid = 0.867994\n",
            "2022-01-09 01:04:00 - INFO:\ttrain #4090 lr = 6.64e-05 loss = 0.026272 train = 0.995508 valid = 0.865556\n",
            "2022-01-09 01:04:09 - INFO:\ttrain #4100 lr = 6.64e-05 loss = 0.034187 train = 0.994727 valid = 0.872055\n",
            "2022-01-09 01:04:10 - INFO:\tSaved test = 0.853728\n",
            "2022-01-09 01:04:20 - INFO:\ttrain #4110 lr = 6.63e-05 loss = 0.026355 train = 0.996094 valid = 0.871243\n",
            "2022-01-09 01:04:29 - INFO:\ttrain #4120 lr = 6.62e-05 loss = 0.028477 train = 0.994531 valid = 0.859464\n",
            "2022-01-09 01:04:38 - INFO:\ttrain #4130 lr = 6.62e-05 loss = 0.039540 train = 0.993164 valid = 0.868806\n",
            "2022-01-09 01:04:47 - INFO:\ttrain #4140 lr = 6.61e-05 loss = 0.023220 train = 0.996094 valid = 0.871243\n",
            "2022-01-09 01:04:56 - INFO:\ttrain #4150 lr = 6.60e-05 loss = 0.024301 train = 0.995117 valid = 0.867587\n",
            "2022-01-09 01:05:04 - INFO:\ttrain #4160 lr = 6.60e-05 loss = 0.017217 train = 0.995898 valid = 0.878148\n",
            "2022-01-09 01:05:13 - INFO:\ttrain #4170 lr = 6.59e-05 loss = 0.042414 train = 0.994336 valid = 0.874898\n",
            "2022-01-09 01:05:23 - INFO:\ttrain #4180 lr = 6.58e-05 loss = 0.026746 train = 0.993945 valid = 0.876523\n",
            "2022-01-09 01:05:31 - INFO:\ttrain #4190 lr = 6.58e-05 loss = 0.025718 train = 0.995313 valid = 0.875711\n",
            "2022-01-09 01:05:40 - INFO:\ttrain #4200 lr = 6.57e-05 loss = 0.022884 train = 0.996680 valid = 0.870837\n",
            "2022-01-09 01:05:41 - INFO:\tSaved test = 0.855754\n",
            "2022-01-09 01:05:50 - INFO:\ttrain #4210 lr = 6.56e-05 loss = 0.030382 train = 0.994336 valid = 0.883022\n",
            "2022-01-09 01:05:59 - INFO:\ttrain #4220 lr = 6.56e-05 loss = 0.037751 train = 0.993750 valid = 0.884240\n",
            "2022-01-09 01:06:08 - INFO:\ttrain #4230 lr = 6.55e-05 loss = 0.012399 train = 0.996289 valid = 0.878554\n",
            "2022-01-09 01:06:16 - INFO:\ttrain #4240 lr = 6.54e-05 loss = 0.014074 train = 0.997656 valid = 0.879773\n",
            "2022-01-09 01:06:25 - INFO:\ttrain #4250 lr = 6.54e-05 loss = 0.014570 train = 0.997461 valid = 0.869618\n",
            "2022-01-09 01:06:34 - INFO:\ttrain #4260 lr = 6.53e-05 loss = 0.018992 train = 0.997070 valid = 0.873274\n",
            "2022-01-09 01:06:42 - INFO:\ttrain #4270 lr = 6.52e-05 loss = 0.016346 train = 0.996680 valid = 0.874898\n",
            "2022-01-09 01:06:51 - INFO:\ttrain #4280 lr = 6.52e-05 loss = 0.015403 train = 0.997266 valid = 0.874898\n",
            "2022-01-09 01:07:00 - INFO:\ttrain #4290 lr = 6.51e-05 loss = 0.017720 train = 0.997266 valid = 0.872055\n",
            "2022-01-09 01:07:08 - INFO:\ttrain #4300 lr = 6.50e-05 loss = 0.010953 train = 0.997461 valid = 0.870837\n",
            "2022-01-09 01:07:10 - INFO:\tSaved test = 0.862237\n",
            "2022-01-09 01:07:18 - INFO:\ttrain #4310 lr = 6.50e-05 loss = 0.012313 train = 0.996484 valid = 0.869618\n",
            "2022-01-09 01:07:27 - INFO:\ttrain #4320 lr = 6.49e-05 loss = 0.045739 train = 0.993945 valid = 0.870024\n",
            "2022-01-09 01:07:36 - INFO:\ttrain #4330 lr = 6.49e-05 loss = 0.015456 train = 0.996875 valid = 0.873274\n",
            "2022-01-09 01:07:45 - INFO:\ttrain #4340 lr = 6.48e-05 loss = 0.007181 train = 0.999023 valid = 0.871649\n",
            "2022-01-09 01:07:54 - INFO:\ttrain #4350 lr = 6.47e-05 loss = 0.027640 train = 0.995313 valid = 0.870837\n",
            "2022-01-09 01:08:02 - INFO:\ttrain #4360 lr = 6.47e-05 loss = 0.029446 train = 0.994336 valid = 0.866369\n",
            "2022-01-09 01:08:11 - INFO:\ttrain #4370 lr = 6.46e-05 loss = 0.017944 train = 0.998047 valid = 0.876117\n",
            "2022-01-09 01:08:20 - INFO:\ttrain #4380 lr = 6.45e-05 loss = 0.019007 train = 0.996289 valid = 0.869212\n",
            "2022-01-09 01:08:28 - INFO:\ttrain #4390 lr = 6.45e-05 loss = 0.030796 train = 0.995898 valid = 0.875711\n",
            "2022-01-09 01:08:37 - INFO:\ttrain #4400 lr = 6.44e-05 loss = 0.017610 train = 0.997266 valid = 0.870431\n",
            "2022-01-09 01:08:38 - INFO:\tSaved test = 0.860616\n",
            "2022-01-09 01:08:47 - INFO:\ttrain #4410 lr = 6.43e-05 loss = 0.019473 train = 0.996484 valid = 0.863119\n",
            "2022-01-09 01:08:56 - INFO:\ttrain #4420 lr = 6.43e-05 loss = 0.019398 train = 0.996680 valid = 0.873274\n",
            "2022-01-09 01:09:04 - INFO:\ttrain #4430 lr = 6.42e-05 loss = 0.022901 train = 0.996875 valid = 0.872868\n",
            "2022-01-09 01:09:13 - INFO:\ttrain #4440 lr = 6.41e-05 loss = 0.010129 train = 0.997070 valid = 0.872868\n",
            "2022-01-09 01:09:22 - INFO:\ttrain #4450 lr = 6.41e-05 loss = 0.010062 train = 0.998047 valid = 0.882210\n",
            "2022-01-09 01:09:31 - INFO:\ttrain #4460 lr = 6.40e-05 loss = 0.032337 train = 0.995313 valid = 0.872055\n",
            "2022-01-09 01:09:39 - INFO:\ttrain #4470 lr = 6.40e-05 loss = 0.015950 train = 0.997461 valid = 0.878148\n",
            "2022-01-09 01:09:48 - INFO:\ttrain #4480 lr = 6.39e-05 loss = 0.011543 train = 0.998242 valid = 0.878148\n",
            "2022-01-09 01:09:57 - INFO:\ttrain #4490 lr = 6.38e-05 loss = 0.020500 train = 0.996680 valid = 0.873680\n",
            "2022-01-09 01:10:05 - INFO:\ttrain #4500 lr = 6.38e-05 loss = 0.007610 train = 0.998437 valid = 0.880179\n",
            "2022-01-09 01:10:07 - INFO:\tSaved test = 0.859400\n",
            "2022-01-09 01:10:15 - INFO:\ttrain #4510 lr = 6.37e-05 loss = 0.021618 train = 0.996875 valid = 0.876929\n",
            "2022-01-09 01:10:24 - INFO:\ttrain #4520 lr = 6.36e-05 loss = 0.009288 train = 0.998047 valid = 0.867181\n",
            "2022-01-09 01:10:33 - INFO:\ttrain #4530 lr = 6.36e-05 loss = 0.019658 train = 0.996289 valid = 0.883022\n",
            "2022-01-09 01:10:41 - INFO:\ttrain #4540 lr = 6.35e-05 loss = 0.024401 train = 0.995703 valid = 0.870837\n",
            "2022-01-09 01:10:50 - INFO:\ttrain #4550 lr = 6.34e-05 loss = 0.014038 train = 0.997266 valid = 0.876117\n",
            "2022-01-09 01:10:59 - INFO:\ttrain #4560 lr = 6.34e-05 loss = 0.026644 train = 0.995313 valid = 0.870431\n",
            "2022-01-09 01:11:07 - INFO:\ttrain #4570 lr = 6.33e-05 loss = 0.023881 train = 0.996875 valid = 0.877742\n",
            "2022-01-09 01:11:16 - INFO:\ttrain #4580 lr = 6.33e-05 loss = 0.015733 train = 0.997070 valid = 0.878554\n",
            "2022-01-09 01:11:25 - INFO:\ttrain #4590 lr = 6.32e-05 loss = 0.044128 train = 0.994727 valid = 0.875711\n",
            "2022-01-09 01:11:34 - INFO:\ttrain #4600 lr = 6.31e-05 loss = 0.013036 train = 0.997070 valid = 0.866775\n",
            "2022-01-09 01:11:35 - INFO:\tSaved test = 0.856969\n",
            "2022-01-09 01:11:44 - INFO:\ttrain #4610 lr = 6.31e-05 loss = 0.050488 train = 0.994336 valid = 0.874492\n",
            "2022-01-09 01:11:52 - INFO:\ttrain #4620 lr = 6.30e-05 loss = 0.070658 train = 0.993164 valid = 0.873680\n",
            "2022-01-09 01:12:01 - INFO:\ttrain #4630 lr = 6.29e-05 loss = 0.023356 train = 0.996094 valid = 0.873274\n",
            "2022-01-09 01:12:10 - INFO:\ttrain #4640 lr = 6.29e-05 loss = 0.012906 train = 0.997852 valid = 0.869618\n",
            "2022-01-09 01:12:18 - INFO:\ttrain #4650 lr = 6.28e-05 loss = 0.016429 train = 0.996094 valid = 0.865150\n",
            "2022-01-09 01:12:27 - INFO:\ttrain #4660 lr = 6.27e-05 loss = 0.029348 train = 0.996094 valid = 0.861901\n",
            "2022-01-09 01:12:36 - INFO:\ttrain #4670 lr = 6.27e-05 loss = 0.019912 train = 0.997070 valid = 0.871243\n",
            "2022-01-09 01:12:44 - INFO:\ttrain #4680 lr = 6.26e-05 loss = 0.018585 train = 0.996680 valid = 0.879366\n",
            "2022-01-09 01:12:53 - INFO:\ttrain #4690 lr = 6.26e-05 loss = 0.022585 train = 0.996289 valid = 0.879366\n",
            "2022-01-09 01:13:02 - INFO:\ttrain #4700 lr = 6.25e-05 loss = 0.004549 train = 0.998242 valid = 0.864338\n",
            "2022-01-09 01:13:04 - INFO:\tSaved test = 0.849676\n",
            "2022-01-09 01:13:13 - INFO:\ttrain #4710 lr = 6.24e-05 loss = 0.022207 train = 0.996484 valid = 0.871649\n",
            "2022-01-09 01:13:22 - INFO:\ttrain #4720 lr = 6.24e-05 loss = 0.015429 train = 0.998047 valid = 0.876929\n",
            "2022-01-09 01:13:31 - INFO:\ttrain #4730 lr = 6.23e-05 loss = 0.009421 train = 0.998242 valid = 0.873680\n",
            "2022-01-09 01:13:40 - INFO:\ttrain #4740 lr = 6.22e-05 loss = 0.012381 train = 0.998047 valid = 0.876929\n",
            "2022-01-09 01:13:49 - INFO:\ttrain #4750 lr = 6.22e-05 loss = 0.016691 train = 0.996875 valid = 0.878148\n",
            "2022-01-09 01:13:58 - INFO:\ttrain #4760 lr = 6.21e-05 loss = 0.016398 train = 0.996680 valid = 0.872868\n",
            "2022-01-09 01:14:08 - INFO:\ttrain #4770 lr = 6.21e-05 loss = 0.014366 train = 0.996680 valid = 0.873274\n",
            "2022-01-09 01:14:17 - INFO:\ttrain #4780 lr = 6.20e-05 loss = 0.039235 train = 0.996484 valid = 0.865556\n",
            "2022-01-09 01:14:26 - INFO:\ttrain #4790 lr = 6.19e-05 loss = 0.025431 train = 0.997266 valid = 0.870837\n",
            "2022-01-09 01:14:35 - INFO:\ttrain #4800 lr = 6.19e-05 loss = 0.012483 train = 0.998047 valid = 0.870024\n",
            "2022-01-09 01:14:37 - INFO:\tSaved test = 0.861831\n",
            "2022-01-09 01:14:46 - INFO:\ttrain #4810 lr = 6.18e-05 loss = 0.007606 train = 0.998437 valid = 0.868806\n",
            "2022-01-09 01:14:55 - INFO:\ttrain #4820 lr = 6.18e-05 loss = 0.036583 train = 0.996094 valid = 0.880585\n",
            "2022-01-09 01:15:04 - INFO:\ttrain #4830 lr = 6.17e-05 loss = 0.016189 train = 0.997266 valid = 0.874898\n",
            "2022-01-09 01:15:14 - INFO:\ttrain #4840 lr = 6.16e-05 loss = 0.011935 train = 0.997852 valid = 0.880991\n",
            "2022-01-09 01:15:23 - INFO:\ttrain #4850 lr = 6.16e-05 loss = 0.017253 train = 0.996875 valid = 0.868400\n",
            "2022-01-09 01:15:32 - INFO:\ttrain #4860 lr = 6.15e-05 loss = 0.008608 train = 0.998437 valid = 0.871243\n",
            "2022-01-09 01:15:41 - INFO:\ttrain #4870 lr = 6.14e-05 loss = 0.012824 train = 0.997656 valid = 0.862713\n",
            "2022-01-09 01:15:50 - INFO:\ttrain #4880 lr = 6.14e-05 loss = 0.019642 train = 0.996875 valid = 0.864338\n",
            "2022-01-09 01:15:59 - INFO:\ttrain #4890 lr = 6.13e-05 loss = 0.012904 train = 0.998242 valid = 0.870431\n",
            "2022-01-09 01:16:08 - INFO:\ttrain #4900 lr = 6.13e-05 loss = 0.013930 train = 0.997070 valid = 0.873274\n",
            "2022-01-09 01:16:09 - INFO:\tSaved test = 0.850486\n",
            "2022-01-09 01:16:18 - INFO:\ttrain #4910 lr = 6.12e-05 loss = 0.011442 train = 0.997852 valid = 0.867181\n",
            "2022-01-09 01:16:27 - INFO:\ttrain #4920 lr = 6.11e-05 loss = 0.041552 train = 0.994922 valid = 0.865556\n",
            "2022-01-09 01:16:36 - INFO:\ttrain #4930 lr = 6.11e-05 loss = 0.038085 train = 0.995703 valid = 0.870024\n",
            "2022-01-09 01:16:45 - INFO:\ttrain #4940 lr = 6.10e-05 loss = 0.011031 train = 0.997852 valid = 0.872055\n",
            "2022-01-09 01:16:54 - INFO:\ttrain #4950 lr = 6.10e-05 loss = 0.036916 train = 0.996484 valid = 0.878554\n",
            "2022-01-09 01:17:03 - INFO:\ttrain #4960 lr = 6.09e-05 loss = 0.017537 train = 0.996875 valid = 0.874086\n",
            "2022-01-09 01:17:12 - INFO:\ttrain #4970 lr = 6.08e-05 loss = 0.043452 train = 0.995898 valid = 0.864338\n",
            "2022-01-09 01:17:21 - INFO:\ttrain #4980 lr = 6.08e-05 loss = 0.018276 train = 0.997461 valid = 0.868806\n",
            "2022-01-09 01:17:30 - INFO:\ttrain #4990 lr = 6.07e-05 loss = 0.005419 train = 0.999023 valid = 0.870837\n",
            "2022-01-09 01:17:39 - INFO:\ttrain #5000 lr = 6.07e-05 loss = 0.008531 train = 0.998242 valid = 0.876523\n",
            "2022-01-09 01:17:40 - INFO:\tSaved test = 0.850891\n",
            "2022-01-09 01:17:49 - INFO:\ttrain #5010 lr = 6.06e-05 loss = 0.015892 train = 0.997266 valid = 0.866369\n",
            "2022-01-09 01:17:59 - INFO:\ttrain #5020 lr = 6.05e-05 loss = 0.023905 train = 0.996680 valid = 0.865150\n",
            "2022-01-09 01:18:08 - INFO:\ttrain #5030 lr = 6.05e-05 loss = 0.051492 train = 0.993164 valid = 0.863932\n",
            "2022-01-09 01:18:17 - INFO:\ttrain #5040 lr = 6.04e-05 loss = 0.019427 train = 0.997656 valid = 0.861495\n",
            "2022-01-09 01:18:26 - INFO:\ttrain #5050 lr = 6.03e-05 loss = 0.028469 train = 0.995898 valid = 0.875305\n",
            "2022-01-09 01:18:35 - INFO:\ttrain #5060 lr = 6.03e-05 loss = 0.035641 train = 0.995898 valid = 0.872461\n",
            "2022-01-09 01:18:44 - INFO:\ttrain #5070 lr = 6.02e-05 loss = 0.030063 train = 0.995703 valid = 0.863119\n",
            "2022-01-09 01:18:53 - INFO:\ttrain #5080 lr = 6.02e-05 loss = 0.023189 train = 0.997070 valid = 0.861089\n",
            "2022-01-09 01:19:02 - INFO:\ttrain #5090 lr = 6.01e-05 loss = 0.040749 train = 0.994922 valid = 0.869618\n",
            "2022-01-09 01:19:11 - INFO:\ttrain #5100 lr = 6.00e-05 loss = 0.032024 train = 0.994727 valid = 0.875711\n",
            "2022-01-09 01:19:12 - INFO:\tSaved test = 0.854133\n",
            "2022-01-09 01:19:21 - INFO:\ttrain #5110 lr = 6.00e-05 loss = 0.005651 train = 0.999219 valid = 0.869618\n",
            "2022-01-09 01:19:30 - INFO:\ttrain #5120 lr = 5.99e-05 loss = 0.001470 train = 0.999609 valid = 0.865963\n",
            "2022-01-09 01:19:39 - INFO:\ttrain #5130 lr = 5.99e-05 loss = 0.000958 train = 0.999609 valid = 0.874086\n",
            "2022-01-09 01:19:49 - INFO:\ttrain #5140 lr = 5.98e-05 loss = 0.014466 train = 0.998437 valid = 0.867994\n",
            "2022-01-09 01:19:58 - INFO:\ttrain #5150 lr = 5.97e-05 loss = 0.010553 train = 0.998828 valid = 0.873274\n",
            "2022-01-09 01:20:07 - INFO:\ttrain #5160 lr = 5.97e-05 loss = 0.034533 train = 0.996680 valid = 0.865556\n",
            "2022-01-09 01:20:16 - INFO:\ttrain #5170 lr = 5.96e-05 loss = 0.020630 train = 0.997852 valid = 0.871649\n",
            "2022-01-09 01:20:24 - INFO:\ttrain #5180 lr = 5.96e-05 loss = 0.015750 train = 0.998242 valid = 0.867181\n",
            "2022-01-09 01:20:33 - INFO:\ttrain #5190 lr = 5.95e-05 loss = 0.002790 train = 0.999219 valid = 0.875711\n",
            "2022-01-09 01:20:42 - INFO:\ttrain #5200 lr = 5.95e-05 loss = 0.011279 train = 0.998828 valid = 0.869618\n",
            "2022-01-09 01:20:44 - INFO:\tSaved test = 0.854133\n",
            "2022-01-09 01:20:53 - INFO:\ttrain #5210 lr = 5.94e-05 loss = 0.029988 train = 0.998047 valid = 0.859058\n",
            "2022-01-09 01:21:02 - INFO:\ttrain #5220 lr = 5.93e-05 loss = 0.015740 train = 0.997070 valid = 0.873274\n",
            "2022-01-09 01:21:11 - INFO:\ttrain #5230 lr = 5.93e-05 loss = 0.027792 train = 0.996094 valid = 0.859464\n",
            "2022-01-09 01:21:20 - INFO:\ttrain #5240 lr = 5.92e-05 loss = 0.016968 train = 0.997852 valid = 0.858652\n",
            "2022-01-09 01:21:29 - INFO:\ttrain #5250 lr = 5.92e-05 loss = 0.018190 train = 0.996484 valid = 0.867994\n",
            "2022-01-09 01:21:38 - INFO:\ttrain #5260 lr = 5.91e-05 loss = 0.007295 train = 0.998242 valid = 0.874086\n",
            "2022-01-09 01:21:46 - INFO:\ttrain #5270 lr = 5.90e-05 loss = 0.013346 train = 0.997266 valid = 0.878960\n",
            "2022-01-09 01:21:55 - INFO:\ttrain #5280 lr = 5.90e-05 loss = 0.025013 train = 0.997656 valid = 0.870837\n",
            "2022-01-09 01:22:04 - INFO:\ttrain #5290 lr = 5.89e-05 loss = 0.015298 train = 0.998047 valid = 0.874086\n",
            "2022-01-09 01:22:14 - INFO:\ttrain #5300 lr = 5.89e-05 loss = 0.019251 train = 0.997656 valid = 0.872055\n",
            "2022-01-09 01:22:15 - INFO:\tSaved test = 0.858995\n",
            "2022-01-09 01:22:24 - INFO:\ttrain #5310 lr = 5.88e-05 loss = 0.019122 train = 0.997461 valid = 0.876929\n",
            "2022-01-09 01:22:33 - INFO:\ttrain #5320 lr = 5.87e-05 loss = 0.012609 train = 0.997461 valid = 0.877335\n",
            "2022-01-09 01:22:42 - INFO:\ttrain #5330 lr = 5.87e-05 loss = 0.007163 train = 0.998437 valid = 0.872055\n",
            "2022-01-09 01:22:51 - INFO:\ttrain #5340 lr = 5.86e-05 loss = 0.023859 train = 0.997266 valid = 0.863526\n",
            "2022-01-09 01:23:00 - INFO:\ttrain #5350 lr = 5.86e-05 loss = 0.013611 train = 0.997656 valid = 0.872055\n",
            "2022-01-09 01:23:09 - INFO:\ttrain #5360 lr = 5.85e-05 loss = 0.025244 train = 0.998242 valid = 0.875711\n",
            "2022-01-09 01:23:18 - INFO:\ttrain #5370 lr = 5.84e-05 loss = 0.008971 train = 0.998047 valid = 0.874492\n",
            "2022-01-09 01:23:26 - INFO:\ttrain #5380 lr = 5.84e-05 loss = 0.030954 train = 0.997266 valid = 0.865963\n",
            "2022-01-09 01:23:35 - INFO:\ttrain #5390 lr = 5.83e-05 loss = 0.003700 train = 0.999219 valid = 0.867181\n",
            "2022-01-09 01:23:44 - INFO:\ttrain #5400 lr = 5.83e-05 loss = 0.010860 train = 0.997852 valid = 0.873680\n",
            "2022-01-09 01:23:45 - INFO:\tSaved test = 0.861426\n",
            "2022-01-09 01:23:54 - INFO:\ttrain #5410 lr = 5.82e-05 loss = 0.005634 train = 0.998437 valid = 0.875711\n",
            "2022-01-09 01:24:03 - INFO:\ttrain #5420 lr = 5.82e-05 loss = 0.010815 train = 0.997656 valid = 0.870837\n",
            "2022-01-09 01:24:12 - INFO:\ttrain #5430 lr = 5.81e-05 loss = 0.033785 train = 0.996875 valid = 0.872868\n",
            "2022-01-09 01:24:21 - INFO:\ttrain #5440 lr = 5.80e-05 loss = 0.008363 train = 0.998633 valid = 0.875305\n",
            "2022-01-09 01:24:30 - INFO:\ttrain #5450 lr = 5.80e-05 loss = 0.010066 train = 0.998047 valid = 0.869618\n",
            "2022-01-09 01:24:39 - INFO:\ttrain #5460 lr = 5.79e-05 loss = 0.015581 train = 0.997852 valid = 0.870024\n",
            "2022-01-09 01:24:47 - INFO:\ttrain #5470 lr = 5.79e-05 loss = 0.021736 train = 0.996094 valid = 0.871243\n",
            "2022-01-09 01:24:56 - INFO:\ttrain #5480 lr = 5.78e-05 loss = 0.007564 train = 0.999023 valid = 0.874086\n",
            "2022-01-09 01:25:05 - INFO:\ttrain #5490 lr = 5.78e-05 loss = 0.003657 train = 0.999219 valid = 0.876929\n",
            "2022-01-09 01:25:13 - INFO:\ttrain #5500 lr = 5.77e-05 loss = 0.006976 train = 0.998437 valid = 0.881397\n",
            "2022-01-09 01:25:15 - INFO:\tSaved test = 0.859806\n",
            "2022-01-09 01:25:24 - INFO:\ttrain #5510 lr = 5.76e-05 loss = 0.000865 train = 0.999609 valid = 0.876523\n",
            "2022-01-09 01:25:33 - INFO:\ttrain #5520 lr = 5.76e-05 loss = 0.031924 train = 0.996094 valid = 0.870431\n",
            "2022-01-09 01:25:42 - INFO:\ttrain #5530 lr = 5.75e-05 loss = 0.048954 train = 0.996289 valid = 0.877335\n",
            "2022-01-09 01:25:51 - INFO:\ttrain #5540 lr = 5.75e-05 loss = 0.004938 train = 0.998828 valid = 0.874898\n",
            "2022-01-09 01:26:00 - INFO:\ttrain #5550 lr = 5.74e-05 loss = 0.010803 train = 0.998437 valid = 0.878148\n",
            "2022-01-09 01:26:09 - INFO:\ttrain #5560 lr = 5.73e-05 loss = 0.007416 train = 0.998047 valid = 0.867587\n",
            "2022-01-09 01:26:17 - INFO:\ttrain #5570 lr = 5.73e-05 loss = 0.015879 train = 0.998437 valid = 0.868806\n",
            "2022-01-09 01:26:26 - INFO:\ttrain #5580 lr = 5.72e-05 loss = 0.018884 train = 0.997656 valid = 0.878148\n",
            "2022-01-09 01:26:35 - INFO:\ttrain #5590 lr = 5.72e-05 loss = 0.015897 train = 0.998437 valid = 0.871649\n",
            "2022-01-09 01:26:44 - INFO:\ttrain #5600 lr = 5.71e-05 loss = 0.007334 train = 0.998437 valid = 0.873274\n",
            "2022-01-09 01:26:46 - INFO:\tSaved test = 0.858995\n",
            "2022-01-09 01:26:55 - INFO:\ttrain #5610 lr = 5.71e-05 loss = 0.010609 train = 0.999023 valid = 0.871649\n",
            "2022-01-09 01:27:04 - INFO:\ttrain #5620 lr = 5.70e-05 loss = 0.003276 train = 0.999219 valid = 0.879773\n",
            "2022-01-09 01:27:13 - INFO:\ttrain #5630 lr = 5.69e-05 loss = 0.024108 train = 0.997266 valid = 0.874492\n",
            "2022-01-09 01:27:22 - INFO:\ttrain #5640 lr = 5.69e-05 loss = 0.015365 train = 0.997656 valid = 0.865963\n",
            "2022-01-09 01:27:30 - INFO:\ttrain #5650 lr = 5.68e-05 loss = 0.007328 train = 0.998633 valid = 0.865963\n",
            "2022-01-09 01:27:39 - INFO:\ttrain #5660 lr = 5.68e-05 loss = 0.009739 train = 0.998437 valid = 0.877742\n",
            "2022-01-09 01:27:48 - INFO:\ttrain #5670 lr = 5.67e-05 loss = 0.017823 train = 0.998047 valid = 0.878960\n",
            "2022-01-09 01:27:57 - INFO:\ttrain #5680 lr = 5.67e-05 loss = 0.004039 train = 0.999219 valid = 0.872868\n",
            "2022-01-09 01:28:06 - INFO:\ttrain #5690 lr = 5.66e-05 loss = 0.012928 train = 0.998633 valid = 0.870837\n",
            "2022-01-09 01:28:15 - INFO:\ttrain #5700 lr = 5.66e-05 loss = 0.012185 train = 0.997656 valid = 0.864338\n",
            "2022-01-09 01:28:16 - INFO:\tSaved test = 0.861021\n",
            "2022-01-09 01:28:25 - INFO:\ttrain #5710 lr = 5.65e-05 loss = 0.020159 train = 0.997070 valid = 0.870837\n",
            "2022-01-09 01:28:34 - INFO:\ttrain #5720 lr = 5.64e-05 loss = 0.010399 train = 0.998047 valid = 0.874086\n",
            "2022-01-09 01:28:43 - INFO:\ttrain #5730 lr = 5.64e-05 loss = 0.046449 train = 0.996094 valid = 0.876929\n",
            "2022-01-09 01:28:52 - INFO:\ttrain #5740 lr = 5.63e-05 loss = 0.013807 train = 0.998047 valid = 0.873274\n",
            "2022-01-09 01:29:01 - INFO:\ttrain #5750 lr = 5.63e-05 loss = 0.029800 train = 0.996094 valid = 0.874086\n",
            "2022-01-09 01:29:10 - INFO:\ttrain #5760 lr = 5.62e-05 loss = 0.034141 train = 0.995898 valid = 0.874898\n",
            "2022-01-09 01:29:19 - INFO:\ttrain #5770 lr = 5.62e-05 loss = 0.012905 train = 0.997852 valid = 0.876117\n",
            "2022-01-09 01:29:27 - INFO:\ttrain #5780 lr = 5.61e-05 loss = 0.004996 train = 0.998828 valid = 0.878960\n",
            "2022-01-09 01:29:36 - INFO:\ttrain #5790 lr = 5.60e-05 loss = 0.018645 train = 0.998242 valid = 0.873274\n",
            "2022-01-09 01:29:45 - INFO:\ttrain #5800 lr = 5.60e-05 loss = 0.008738 train = 0.998828 valid = 0.875305\n",
            "2022-01-09 01:29:47 - INFO:\tSaved test = 0.863857\n",
            "2022-01-09 01:29:55 - INFO:\ttrain #5810 lr = 5.59e-05 loss = 0.050423 train = 0.996484 valid = 0.873680\n",
            "2022-01-09 01:30:04 - INFO:\ttrain #5820 lr = 5.59e-05 loss = 0.008809 train = 0.998633 valid = 0.881397\n",
            "2022-01-09 01:30:13 - INFO:\ttrain #5830 lr = 5.58e-05 loss = 0.031969 train = 0.996484 valid = 0.878148\n",
            "2022-01-09 01:30:22 - INFO:\ttrain #5840 lr = 5.58e-05 loss = 0.005807 train = 0.999023 valid = 0.887490 updated\n",
            "2022-01-09 01:30:31 - INFO:\ttrain #5850 lr = 5.57e-05 loss = 0.006690 train = 0.998828 valid = 0.876117\n",
            "2022-01-09 01:30:40 - INFO:\ttrain #5860 lr = 5.57e-05 loss = 0.017600 train = 0.998633 valid = 0.875305\n",
            "2022-01-09 01:30:49 - INFO:\ttrain #5870 lr = 5.56e-05 loss = 0.007948 train = 0.997852 valid = 0.872461\n",
            "2022-01-09 01:30:58 - INFO:\ttrain #5880 lr = 5.55e-05 loss = 0.038947 train = 0.995703 valid = 0.873274\n",
            "2022-01-09 01:31:07 - INFO:\ttrain #5890 lr = 5.55e-05 loss = 0.034295 train = 0.996484 valid = 0.865963\n",
            "2022-01-09 01:31:16 - INFO:\ttrain #5900 lr = 5.54e-05 loss = 0.010933 train = 0.997852 valid = 0.879366\n",
            "2022-01-09 01:31:17 - INFO:\tSaved test = 0.859806\n",
            "2022-01-09 01:31:26 - INFO:\ttrain #5910 lr = 5.54e-05 loss = 0.004760 train = 0.998633 valid = 0.867587\n",
            "2022-01-09 01:31:35 - INFO:\ttrain #5920 lr = 5.53e-05 loss = 0.030409 train = 0.996289 valid = 0.872868\n",
            "2022-01-09 01:31:44 - INFO:\ttrain #5930 lr = 5.53e-05 loss = 0.019226 train = 0.997852 valid = 0.881803\n",
            "2022-01-09 01:31:53 - INFO:\ttrain #5940 lr = 5.52e-05 loss = 0.018311 train = 0.998047 valid = 0.876929\n",
            "2022-01-09 01:32:02 - INFO:\ttrain #5950 lr = 5.52e-05 loss = 0.007468 train = 0.998047 valid = 0.874898\n",
            "2022-01-09 01:32:11 - INFO:\ttrain #5960 lr = 5.51e-05 loss = 0.005613 train = 0.998828 valid = 0.874898\n",
            "2022-01-09 01:32:20 - INFO:\ttrain #5970 lr = 5.50e-05 loss = 0.016917 train = 0.998242 valid = 0.874492\n",
            "2022-01-09 01:32:28 - INFO:\ttrain #5980 lr = 5.50e-05 loss = 0.003431 train = 0.999219 valid = 0.883022\n",
            "2022-01-09 01:32:37 - INFO:\ttrain #5990 lr = 5.49e-05 loss = 0.009204 train = 0.998828 valid = 0.866369\n",
            "2022-01-09 01:32:46 - INFO:\ttrain #6000 lr = 5.49e-05 loss = 0.006202 train = 0.998047 valid = 0.876117\n",
            "2022-01-09 01:32:48 - INFO:\tSaved test = 0.856564\n",
            "2022-01-09 01:32:57 - INFO:\ttrain #6010 lr = 5.48e-05 loss = 0.015420 train = 0.997461 valid = 0.878960\n",
            "2022-01-09 01:33:06 - INFO:\ttrain #6020 lr = 5.48e-05 loss = 0.005850 train = 0.999414 valid = 0.881803\n",
            "2022-01-09 01:33:14 - INFO:\ttrain #6030 lr = 5.47e-05 loss = 0.016069 train = 0.997656 valid = 0.877742\n",
            "2022-01-09 01:33:23 - INFO:\ttrain #6040 lr = 5.47e-05 loss = 0.001725 train = 0.999219 valid = 0.878960\n",
            "2022-01-09 01:33:32 - INFO:\ttrain #6050 lr = 5.46e-05 loss = 0.008176 train = 0.999219 valid = 0.876523\n",
            "2022-01-09 01:33:41 - INFO:\ttrain #6060 lr = 5.46e-05 loss = 0.012132 train = 0.998633 valid = 0.880179\n",
            "2022-01-09 01:33:50 - INFO:\ttrain #6070 lr = 5.45e-05 loss = 0.010909 train = 0.998437 valid = 0.883834\n",
            "2022-01-09 01:33:59 - INFO:\ttrain #6080 lr = 5.44e-05 loss = 0.003813 train = 0.999023 valid = 0.867587\n",
            "2022-01-09 01:34:08 - INFO:\ttrain #6090 lr = 5.44e-05 loss = 0.010698 train = 0.998828 valid = 0.881397\n",
            "2022-01-09 01:34:17 - INFO:\ttrain #6100 lr = 5.43e-05 loss = 0.016933 train = 0.998047 valid = 0.865150\n",
            "2022-01-09 01:34:18 - INFO:\tSaved test = 0.830632\n",
            "2022-01-09 01:34:27 - INFO:\ttrain #6110 lr = 5.43e-05 loss = 0.008852 train = 0.998437 valid = 0.875711\n",
            "2022-01-09 01:34:36 - INFO:\ttrain #6120 lr = 5.42e-05 loss = 0.010837 train = 0.999023 valid = 0.873680\n",
            "2022-01-09 01:34:45 - INFO:\ttrain #6130 lr = 5.42e-05 loss = 0.011001 train = 0.998633 valid = 0.878554\n",
            "2022-01-09 01:34:54 - INFO:\ttrain #6140 lr = 5.41e-05 loss = 0.015531 train = 0.998242 valid = 0.872461\n",
            "2022-01-09 01:35:03 - INFO:\ttrain #6150 lr = 5.41e-05 loss = 0.058315 train = 0.994727 valid = 0.872461\n",
            "2022-01-09 01:35:12 - INFO:\ttrain #6160 lr = 5.40e-05 loss = 0.011594 train = 0.998047 valid = 0.872055\n",
            "2022-01-09 01:35:21 - INFO:\ttrain #6170 lr = 5.40e-05 loss = 0.002533 train = 0.999023 valid = 0.866775\n",
            "2022-01-09 01:35:30 - INFO:\ttrain #6180 lr = 5.39e-05 loss = 0.018942 train = 0.997852 valid = 0.873680\n",
            "2022-01-09 01:35:39 - INFO:\ttrain #6190 lr = 5.38e-05 loss = 0.006758 train = 0.997852 valid = 0.879366\n",
            "2022-01-09 01:35:48 - INFO:\ttrain #6200 lr = 5.38e-05 loss = 0.019085 train = 0.997070 valid = 0.880991\n",
            "2022-01-09 01:35:49 - INFO:\tSaved test = 0.860211\n",
            "2022-01-09 01:35:58 - INFO:\ttrain #6210 lr = 5.37e-05 loss = 0.003838 train = 0.999219 valid = 0.880179\n",
            "2022-01-09 01:36:07 - INFO:\ttrain #6220 lr = 5.37e-05 loss = 0.013385 train = 0.998437 valid = 0.874898\n",
            "2022-01-09 01:36:16 - INFO:\ttrain #6230 lr = 5.36e-05 loss = 0.001911 train = 0.999414 valid = 0.876929\n",
            "2022-01-09 01:36:24 - INFO:\ttrain #6240 lr = 5.36e-05 loss = 0.015912 train = 0.998047 valid = 0.879366\n",
            "2022-01-09 01:36:33 - INFO:\ttrain #6250 lr = 5.35e-05 loss = 0.001992 train = 0.999219 valid = 0.874898\n",
            "2022-01-09 01:36:42 - INFO:\ttrain #6260 lr = 5.35e-05 loss = 0.004545 train = 0.998828 valid = 0.880179\n",
            "2022-01-09 01:36:51 - INFO:\ttrain #6270 lr = 5.34e-05 loss = 0.014951 train = 0.997852 valid = 0.876929\n",
            "2022-01-09 01:37:00 - INFO:\ttrain #6280 lr = 5.34e-05 loss = 0.024223 train = 0.997656 valid = 0.881397\n",
            "2022-01-09 01:37:09 - INFO:\ttrain #6290 lr = 5.33e-05 loss = 0.007194 train = 0.998828 valid = 0.878554\n",
            "2022-01-09 01:37:18 - INFO:\ttrain #6300 lr = 5.33e-05 loss = 0.006329 train = 0.998633 valid = 0.870837\n",
            "2022-01-09 01:37:19 - INFO:\tSaved test = 0.852512\n",
            "2022-01-09 01:37:28 - INFO:\ttrain #6310 lr = 5.32e-05 loss = 0.023777 train = 0.997266 valid = 0.876117\n",
            "2022-01-09 01:37:37 - INFO:\ttrain #6320 lr = 5.32e-05 loss = 0.049470 train = 0.995703 valid = 0.876929\n",
            "2022-01-09 01:37:46 - INFO:\ttrain #6330 lr = 5.31e-05 loss = 0.008577 train = 0.999219 valid = 0.875305\n",
            "2022-01-09 01:37:55 - INFO:\ttrain #6340 lr = 5.30e-05 loss = 0.002267 train = 0.999609 valid = 0.878554\n",
            "2022-01-09 01:38:04 - INFO:\ttrain #6350 lr = 5.30e-05 loss = 0.015791 train = 0.997852 valid = 0.873274\n",
            "2022-01-09 01:38:13 - INFO:\ttrain #6360 lr = 5.29e-05 loss = 0.007480 train = 0.998828 valid = 0.874492\n",
            "2022-01-09 01:38:22 - INFO:\ttrain #6370 lr = 5.29e-05 loss = 0.016652 train = 0.997852 valid = 0.877335\n",
            "2022-01-09 01:38:30 - INFO:\ttrain #6380 lr = 5.28e-05 loss = 0.022341 train = 0.997266 valid = 0.870837\n",
            "2022-01-09 01:38:39 - INFO:\ttrain #6390 lr = 5.28e-05 loss = 0.049370 train = 0.998242 valid = 0.876117\n",
            "2022-01-09 01:38:48 - INFO:\ttrain #6400 lr = 5.27e-05 loss = 0.001794 train = 0.999414 valid = 0.877335\n",
            "2022-01-09 01:38:50 - INFO:\tSaved test = 0.865478\n",
            "2022-01-09 01:38:59 - INFO:\ttrain #6410 lr = 5.27e-05 loss = 0.012099 train = 0.998242 valid = 0.875305\n",
            "2022-01-09 01:39:08 - INFO:\ttrain #6420 lr = 5.26e-05 loss = 0.007737 train = 0.999219 valid = 0.876929\n",
            "2022-01-09 01:39:17 - INFO:\ttrain #6430 lr = 5.26e-05 loss = 0.010153 train = 0.998828 valid = 0.871649\n",
            "2022-01-09 01:39:26 - INFO:\ttrain #6440 lr = 5.25e-05 loss = 0.007121 train = 0.998047 valid = 0.872055\n",
            "2022-01-09 01:39:34 - INFO:\ttrain #6450 lr = 5.25e-05 loss = 0.005225 train = 0.999219 valid = 0.874898\n",
            "2022-01-09 01:39:43 - INFO:\ttrain #6460 lr = 5.24e-05 loss = 0.014779 train = 0.998437 valid = 0.878554\n",
            "2022-01-09 01:39:52 - INFO:\ttrain #6470 lr = 5.24e-05 loss = 0.006349 train = 0.998828 valid = 0.874086\n",
            "2022-01-09 01:40:01 - INFO:\ttrain #6480 lr = 5.23e-05 loss = 0.002037 train = 0.999609 valid = 0.874492\n",
            "2022-01-09 01:40:10 - INFO:\ttrain #6490 lr = 5.23e-05 loss = 0.005946 train = 0.999414 valid = 0.873274\n",
            "2022-01-09 01:40:19 - INFO:\ttrain #6500 lr = 5.22e-05 loss = 0.001133 train = 0.999609 valid = 0.872055\n",
            "2022-01-09 01:40:21 - INFO:\tSaved test = 0.857374\n",
            "2022-01-09 01:40:30 - INFO:\ttrain #6510 lr = 5.22e-05 loss = 0.010457 train = 0.998633 valid = 0.879366\n",
            "2022-01-09 01:40:38 - INFO:\ttrain #6520 lr = 5.21e-05 loss = 0.002262 train = 0.999219 valid = 0.884647\n",
            "2022-01-09 01:40:47 - INFO:\ttrain #6530 lr = 5.20e-05 loss = 0.011992 train = 0.999023 valid = 0.878148\n",
            "2022-01-09 01:40:56 - INFO:\ttrain #6540 lr = 5.20e-05 loss = 0.009404 train = 0.999219 valid = 0.874492\n",
            "2022-01-09 01:41:05 - INFO:\ttrain #6550 lr = 5.19e-05 loss = 0.007969 train = 0.999219 valid = 0.881397\n",
            "2022-01-09 01:41:14 - INFO:\ttrain #6560 lr = 5.19e-05 loss = 0.014988 train = 0.998633 valid = 0.877335\n",
            "2022-01-09 01:41:23 - INFO:\ttrain #6570 lr = 5.18e-05 loss = 0.019308 train = 0.998047 valid = 0.875305\n",
            "2022-01-09 01:41:32 - INFO:\ttrain #6580 lr = 5.18e-05 loss = 0.017233 train = 0.998633 valid = 0.872868\n",
            "2022-01-09 01:41:41 - INFO:\ttrain #6590 lr = 5.17e-05 loss = 0.015607 train = 0.997852 valid = 0.871243\n",
            "2022-01-09 01:41:50 - INFO:\ttrain #6600 lr = 5.17e-05 loss = 0.016889 train = 0.997266 valid = 0.877335\n",
            "2022-01-09 01:41:51 - INFO:\tSaved test = 0.865478\n",
            "2022-01-09 01:42:00 - INFO:\ttrain #6610 lr = 5.16e-05 loss = 0.004627 train = 0.998633 valid = 0.869212\n",
            "2022-01-09 01:42:09 - INFO:\ttrain #6620 lr = 5.16e-05 loss = 0.001405 train = 0.999609 valid = 0.870837\n",
            "2022-01-09 01:42:18 - INFO:\ttrain #6630 lr = 5.15e-05 loss = 0.007005 train = 0.999219 valid = 0.879773\n",
            "2022-01-09 01:42:27 - INFO:\ttrain #6640 lr = 5.15e-05 loss = 0.009821 train = 0.998242 valid = 0.874898\n",
            "2022-01-09 01:42:36 - INFO:\ttrain #6650 lr = 5.14e-05 loss = 0.009650 train = 0.998633 valid = 0.875711\n",
            "2022-01-09 01:42:45 - INFO:\ttrain #6660 lr = 5.14e-05 loss = 0.057576 train = 0.996875 valid = 0.872868\n",
            "2022-01-09 01:42:54 - INFO:\ttrain #6670 lr = 5.13e-05 loss = 0.018758 train = 0.999023 valid = 0.874492\n",
            "2022-01-09 01:43:03 - INFO:\ttrain #6680 lr = 5.13e-05 loss = 0.018792 train = 0.997266 valid = 0.880991\n",
            "2022-01-09 01:43:12 - INFO:\ttrain #6690 lr = 5.12e-05 loss = 0.005160 train = 0.998828 valid = 0.872868\n",
            "2022-01-09 01:43:21 - INFO:\ttrain #6700 lr = 5.12e-05 loss = 0.014456 train = 0.998242 valid = 0.864744\n",
            "2022-01-09 01:43:22 - INFO:\tSaved test = 0.862237\n",
            "2022-01-09 01:43:31 - INFO:\ttrain #6710 lr = 5.11e-05 loss = 0.004977 train = 0.998242 valid = 0.878554\n",
            "2022-01-09 01:43:40 - INFO:\ttrain #6720 lr = 5.11e-05 loss = 0.016328 train = 0.998633 valid = 0.868400\n",
            "2022-01-09 01:43:49 - INFO:\ttrain #6730 lr = 5.10e-05 loss = 0.007709 train = 0.998828 valid = 0.871649\n",
            "2022-01-09 01:43:58 - INFO:\ttrain #6740 lr = 5.10e-05 loss = 0.006808 train = 0.999023 valid = 0.876929\n",
            "2022-01-09 01:44:07 - INFO:\ttrain #6750 lr = 5.09e-05 loss = 0.006206 train = 0.999023 valid = 0.874086\n",
            "2022-01-09 01:44:16 - INFO:\ttrain #6760 lr = 5.09e-05 loss = 0.009480 train = 0.998437 valid = 0.878554\n",
            "2022-01-09 01:44:25 - INFO:\ttrain #6770 lr = 5.08e-05 loss = 0.000651 train = 0.999805 valid = 0.872055\n",
            "2022-01-09 01:44:34 - INFO:\ttrain #6780 lr = 5.08e-05 loss = 0.004823 train = 0.998633 valid = 0.871649\n",
            "2022-01-09 01:44:43 - INFO:\ttrain #6790 lr = 5.07e-05 loss = 0.003332 train = 0.999414 valid = 0.877335\n",
            "2022-01-09 01:44:51 - INFO:\ttrain #6800 lr = 5.07e-05 loss = 0.000865 train = 0.999805 valid = 0.874492\n",
            "2022-01-09 01:44:53 - INFO:\tSaved test = 0.855754\n",
            "2022-01-09 01:45:02 - INFO:\ttrain #6810 lr = 5.06e-05 loss = 0.007977 train = 0.998828 valid = 0.881397\n",
            "2022-01-09 01:45:11 - INFO:\ttrain #6820 lr = 5.06e-05 loss = 0.057467 train = 0.996484 valid = 0.867587\n",
            "2022-01-09 01:45:20 - INFO:\ttrain #6830 lr = 5.05e-05 loss = 0.014828 train = 0.998633 valid = 0.872868\n",
            "2022-01-09 01:45:29 - INFO:\ttrain #6840 lr = 5.05e-05 loss = 0.033419 train = 0.997852 valid = 0.876117\n",
            "2022-01-09 01:45:38 - INFO:\ttrain #6850 lr = 5.04e-05 loss = 0.010425 train = 0.999219 valid = 0.871649\n",
            "2022-01-09 01:45:46 - INFO:\ttrain #6860 lr = 5.04e-05 loss = 0.030384 train = 0.997852 valid = 0.874492\n",
            "2022-01-09 01:45:55 - INFO:\ttrain #6870 lr = 5.03e-05 loss = 0.000560 train = 0.999805 valid = 0.875711\n",
            "2022-01-09 01:46:04 - INFO:\ttrain #6880 lr = 5.03e-05 loss = 0.010012 train = 0.998633 valid = 0.875305\n",
            "2022-01-09 01:46:13 - INFO:\ttrain #6890 lr = 5.02e-05 loss = 0.003604 train = 0.999609 valid = 0.877742\n",
            "2022-01-09 01:46:22 - INFO:\ttrain #6900 lr = 5.02e-05 loss = 0.000368 train = 0.999805 valid = 0.875711\n",
            "2022-01-09 01:46:24 - INFO:\tSaved test = 0.850486\n",
            "2022-01-09 01:46:33 - INFO:\ttrain #6910 lr = 5.01e-05 loss = 0.003092 train = 0.999219 valid = 0.880991\n",
            "2022-01-09 01:46:42 - INFO:\ttrain #6920 lr = 5.01e-05 loss = 0.001556 train = 0.999805 valid = 0.876117\n",
            "2022-01-09 01:46:50 - INFO:\ttrain #6930 lr = 5.00e-05 loss = 0.003740 train = 0.999414 valid = 0.870024\n",
            "2022-01-09 01:46:59 - INFO:\ttrain #6940 lr = 5.00e-05 loss = 0.014620 train = 0.998242 valid = 0.876117\n",
            "2022-01-09 01:47:08 - INFO:\ttrain #6950 lr = 4.99e-05 loss = 0.003014 train = 0.999805 valid = 0.887896 updated\n",
            "2022-01-09 01:47:17 - INFO:\ttrain #6960 lr = 4.99e-05 loss = 0.003111 train = 0.999609 valid = 0.885459\n",
            "2022-01-09 01:47:26 - INFO:\ttrain #6970 lr = 4.98e-05 loss = 0.005760 train = 0.999609 valid = 0.885459\n",
            "2022-01-09 01:47:35 - INFO:\ttrain #6980 lr = 4.98e-05 loss = 0.006263 train = 0.999023 valid = 0.876929\n",
            "2022-01-09 01:47:44 - INFO:\ttrain #6990 lr = 4.97e-05 loss = 0.007937 train = 0.998242 valid = 0.878554\n",
            "2022-01-09 01:47:52 - INFO:\ttrain #7000 lr = 4.97e-05 loss = 0.009326 train = 0.999023 valid = 0.880585\n",
            "2022-01-09 01:47:54 - INFO:\tSaved test = 0.864263\n",
            "2022-01-09 01:48:03 - INFO:\ttrain #7010 lr = 4.96e-05 loss = 0.011931 train = 0.998242 valid = 0.887490\n",
            "2022-01-09 01:48:12 - INFO:\ttrain #7020 lr = 4.96e-05 loss = 0.013957 train = 0.997656 valid = 0.874898\n",
            "2022-01-09 01:48:20 - INFO:\ttrain #7030 lr = 4.95e-05 loss = 0.016740 train = 0.997852 valid = 0.872461\n",
            "2022-01-09 01:48:29 - INFO:\ttrain #7040 lr = 4.95e-05 loss = 0.005629 train = 0.998828 valid = 0.874086\n",
            "2022-01-09 01:48:38 - INFO:\ttrain #7050 lr = 4.94e-05 loss = 0.001442 train = 0.999414 valid = 0.867587\n",
            "2022-01-09 01:48:47 - INFO:\ttrain #7060 lr = 4.94e-05 loss = 0.003364 train = 0.999023 valid = 0.873680\n",
            "2022-01-09 01:48:56 - INFO:\ttrain #7070 lr = 4.93e-05 loss = 0.001484 train = 0.999805 valid = 0.878148\n",
            "2022-01-09 01:49:05 - INFO:\ttrain #7080 lr = 4.93e-05 loss = 0.014930 train = 0.998437 valid = 0.873274\n",
            "2022-01-09 01:49:14 - INFO:\ttrain #7090 lr = 4.92e-05 loss = 0.017304 train = 0.998242 valid = 0.872461\n",
            "2022-01-09 01:49:23 - INFO:\ttrain #7100 lr = 4.92e-05 loss = 0.017177 train = 0.998437 valid = 0.873680\n",
            "2022-01-09 01:49:24 - INFO:\tSaved test = 0.862237\n",
            "2022-01-09 01:49:33 - INFO:\ttrain #7110 lr = 4.91e-05 loss = 0.011421 train = 0.998437 valid = 0.871649\n",
            "2022-01-09 01:49:42 - INFO:\ttrain #7120 lr = 4.91e-05 loss = 0.003342 train = 0.999219 valid = 0.876929\n",
            "2022-01-09 01:49:51 - INFO:\ttrain #7130 lr = 4.90e-05 loss = 0.001255 train = 0.999609 valid = 0.870431\n",
            "2022-01-09 01:50:00 - INFO:\ttrain #7140 lr = 4.90e-05 loss = 0.002065 train = 0.999023 valid = 0.878148\n",
            "2022-01-09 01:50:09 - INFO:\ttrain #7150 lr = 4.89e-05 loss = 0.002237 train = 0.999609 valid = 0.878960\n",
            "2022-01-09 01:50:18 - INFO:\ttrain #7160 lr = 4.89e-05 loss = 0.001945 train = 0.999609 valid = 0.876523\n",
            "2022-01-09 01:50:27 - INFO:\ttrain #7170 lr = 4.88e-05 loss = 0.026352 train = 0.998242 valid = 0.874492\n",
            "2022-01-09 01:50:36 - INFO:\ttrain #7180 lr = 4.88e-05 loss = 0.029311 train = 0.998047 valid = 0.872055\n",
            "2022-01-09 01:50:45 - INFO:\ttrain #7190 lr = 4.87e-05 loss = 0.013777 train = 0.999219 valid = 0.867994\n",
            "2022-01-09 01:50:54 - INFO:\ttrain #7200 lr = 4.87e-05 loss = 0.000744 train = 0.999805 valid = 0.867181\n",
            "2022-01-09 01:50:55 - INFO:\tSaved test = 0.853323\n",
            "2022-01-09 01:51:04 - INFO:\ttrain #7210 lr = 4.86e-05 loss = 0.019525 train = 0.998242 valid = 0.872461\n",
            "2022-01-09 01:51:13 - INFO:\ttrain #7220 lr = 4.86e-05 loss = 0.012328 train = 0.998633 valid = 0.874086\n",
            "2022-01-09 01:51:22 - INFO:\ttrain #7230 lr = 4.85e-05 loss = 0.001001 train = 0.999609 valid = 0.871649\n",
            "2022-01-09 01:51:31 - INFO:\ttrain #7240 lr = 4.85e-05 loss = 0.006554 train = 0.999609 valid = 0.865556\n",
            "2022-01-09 01:51:40 - INFO:\ttrain #7250 lr = 4.84e-05 loss = 0.005486 train = 0.999609 valid = 0.870024\n",
            "2022-01-09 01:51:49 - INFO:\ttrain #7260 lr = 4.84e-05 loss = 0.001129 train = 0.999414 valid = 0.876523\n",
            "2022-01-09 01:51:58 - INFO:\ttrain #7270 lr = 4.83e-05 loss = 0.018320 train = 0.998242 valid = 0.869618\n",
            "2022-01-09 01:52:07 - INFO:\ttrain #7280 lr = 4.83e-05 loss = 0.015646 train = 0.998047 valid = 0.875305\n",
            "2022-01-09 01:52:16 - INFO:\ttrain #7290 lr = 4.82e-05 loss = 0.012098 train = 0.998633 valid = 0.878554\n",
            "2022-01-09 01:52:25 - INFO:\ttrain #7300 lr = 4.82e-05 loss = 0.004665 train = 0.999219 valid = 0.876929\n",
            "2022-01-09 01:52:26 - INFO:\tSaved test = 0.863452\n",
            "2022-01-09 01:52:35 - INFO:\ttrain #7310 lr = 4.81e-05 loss = 0.001006 train = 0.999805 valid = 0.878960\n",
            "2022-01-09 01:52:44 - INFO:\ttrain #7320 lr = 4.81e-05 loss = 0.005295 train = 0.999219 valid = 0.871649\n",
            "2022-01-09 01:52:53 - INFO:\ttrain #7330 lr = 4.80e-05 loss = 0.003440 train = 0.999609 valid = 0.869618\n",
            "2022-01-09 01:53:02 - INFO:\ttrain #7340 lr = 4.80e-05 loss = 0.000255 train = 1.000000 valid = 0.872055\n",
            "2022-01-09 01:53:11 - INFO:\ttrain #7350 lr = 4.79e-05 loss = 0.005643 train = 0.999023 valid = 0.874898\n",
            "2022-01-09 01:53:20 - INFO:\ttrain #7360 lr = 4.79e-05 loss = 0.001345 train = 0.999805 valid = 0.882210\n",
            "2022-01-09 01:53:28 - INFO:\ttrain #7370 lr = 4.79e-05 loss = 0.012015 train = 0.998633 valid = 0.871243\n",
            "2022-01-09 01:53:37 - INFO:\ttrain #7380 lr = 4.78e-05 loss = 0.013763 train = 0.998828 valid = 0.861901\n",
            "2022-01-09 01:53:46 - INFO:\ttrain #7390 lr = 4.78e-05 loss = 0.003990 train = 0.999219 valid = 0.871649\n",
            "2022-01-09 01:53:55 - INFO:\ttrain #7400 lr = 4.77e-05 loss = 0.028840 train = 0.997070 valid = 0.874898\n",
            "2022-01-09 01:53:56 - INFO:\tSaved test = 0.852512\n",
            "2022-01-09 01:54:05 - INFO:\ttrain #7410 lr = 4.77e-05 loss = 0.070478 train = 0.996289 valid = 0.882616\n",
            "2022-01-09 01:54:14 - INFO:\ttrain #7420 lr = 4.76e-05 loss = 0.025071 train = 0.999023 valid = 0.878148\n",
            "2022-01-09 01:54:23 - INFO:\ttrain #7430 lr = 4.76e-05 loss = 0.013668 train = 0.998828 valid = 0.888708 updated\n",
            "2022-01-09 01:54:32 - INFO:\ttrain #7440 lr = 4.75e-05 loss = 0.004633 train = 0.999414 valid = 0.874492\n",
            "2022-01-09 01:54:41 - INFO:\ttrain #7450 lr = 4.75e-05 loss = 0.001173 train = 0.999609 valid = 0.883022\n",
            "2022-01-09 01:54:50 - INFO:\ttrain #7460 lr = 4.74e-05 loss = 0.004682 train = 0.999023 valid = 0.874086\n",
            "2022-01-09 01:54:59 - INFO:\ttrain #7470 lr = 4.74e-05 loss = 0.010626 train = 0.999023 valid = 0.871649\n",
            "2022-01-09 01:55:08 - INFO:\ttrain #7480 lr = 4.73e-05 loss = 0.007088 train = 0.998828 valid = 0.879773\n",
            "2022-01-09 01:55:17 - INFO:\ttrain #7490 lr = 4.73e-05 loss = 0.060827 train = 0.996484 valid = 0.876523\n",
            "2022-01-09 01:55:26 - INFO:\ttrain #7500 lr = 4.72e-05 loss = 0.022451 train = 0.998242 valid = 0.879366\n",
            "2022-01-09 01:55:27 - INFO:\tSaved test = 0.867504\n",
            "2022-01-09 01:55:36 - INFO:\ttrain #7510 lr = 4.72e-05 loss = 0.004828 train = 0.999023 valid = 0.881397\n",
            "2022-01-09 01:55:45 - INFO:\ttrain #7520 lr = 4.71e-05 loss = 0.009246 train = 0.998828 valid = 0.876929\n",
            "2022-01-09 01:55:54 - INFO:\ttrain #7530 lr = 4.71e-05 loss = 0.004320 train = 0.999023 valid = 0.872868\n",
            "2022-01-09 01:56:03 - INFO:\ttrain #7540 lr = 4.70e-05 loss = 0.003874 train = 0.999805 valid = 0.877335\n",
            "2022-01-09 01:56:12 - INFO:\ttrain #7550 lr = 4.70e-05 loss = 0.001740 train = 0.999805 valid = 0.874898\n",
            "2022-01-09 01:56:20 - INFO:\ttrain #7560 lr = 4.70e-05 loss = 0.005072 train = 0.999414 valid = 0.880179\n",
            "2022-01-09 01:56:29 - INFO:\ttrain #7570 lr = 4.69e-05 loss = 0.003525 train = 0.999609 valid = 0.875711\n",
            "2022-01-09 01:56:38 - INFO:\ttrain #7580 lr = 4.69e-05 loss = 0.025902 train = 0.997266 valid = 0.878554\n",
            "2022-01-09 01:56:47 - INFO:\ttrain #7590 lr = 4.68e-05 loss = 0.001106 train = 0.999609 valid = 0.879773\n",
            "2022-01-09 01:56:56 - INFO:\ttrain #7600 lr = 4.68e-05 loss = 0.001312 train = 0.999219 valid = 0.884240\n",
            "2022-01-09 01:56:58 - INFO:\tSaved test = 0.865073\n",
            "2022-01-09 01:57:06 - INFO:\ttrain #7610 lr = 4.67e-05 loss = 0.080190 train = 0.997070 valid = 0.859464\n",
            "2022-01-09 01:57:15 - INFO:\ttrain #7620 lr = 4.67e-05 loss = 0.017792 train = 0.998633 valid = 0.865963\n",
            "2022-01-09 01:57:24 - INFO:\ttrain #7630 lr = 4.66e-05 loss = 0.002906 train = 0.999219 valid = 0.866775\n",
            "2022-01-09 01:57:33 - INFO:\ttrain #7640 lr = 4.66e-05 loss = 0.005978 train = 0.998633 valid = 0.878148\n",
            "2022-01-09 01:57:42 - INFO:\ttrain #7650 lr = 4.65e-05 loss = 0.004846 train = 0.999609 valid = 0.873274\n",
            "2022-01-09 01:57:51 - INFO:\ttrain #7660 lr = 4.65e-05 loss = 0.023311 train = 0.998437 valid = 0.878148\n",
            "2022-01-09 01:58:00 - INFO:\ttrain #7670 lr = 4.64e-05 loss = 0.003299 train = 0.999609 valid = 0.878554\n",
            "2022-01-09 01:58:09 - INFO:\ttrain #7680 lr = 4.64e-05 loss = 0.000872 train = 0.999609 valid = 0.880991\n",
            "2022-01-09 01:58:18 - INFO:\ttrain #7690 lr = 4.63e-05 loss = 0.004380 train = 0.999609 valid = 0.881397\n",
            "2022-01-09 01:58:27 - INFO:\ttrain #7700 lr = 4.63e-05 loss = 0.001341 train = 0.999414 valid = 0.883022\n",
            "2022-01-09 01:58:28 - INFO:\tSaved test = 0.862642\n",
            "2022-01-09 01:58:37 - INFO:\ttrain #7710 lr = 4.63e-05 loss = 0.003410 train = 0.999414 valid = 0.884647\n",
            "2022-01-09 01:58:46 - INFO:\ttrain #7720 lr = 4.62e-05 loss = 0.007674 train = 0.999219 valid = 0.886271\n",
            "2022-01-09 01:58:55 - INFO:\ttrain #7730 lr = 4.62e-05 loss = 0.006424 train = 0.999609 valid = 0.884240\n",
            "2022-01-09 01:59:04 - INFO:\ttrain #7740 lr = 4.61e-05 loss = 0.000593 train = 0.999805 valid = 0.878554\n",
            "2022-01-09 01:59:13 - INFO:\ttrain #7750 lr = 4.61e-05 loss = 0.008144 train = 0.999023 valid = 0.882616\n",
            "2022-01-09 01:59:22 - INFO:\ttrain #7760 lr = 4.60e-05 loss = 0.000398 train = 1.000000 valid = 0.880585\n",
            "2022-01-09 01:59:31 - INFO:\ttrain #7770 lr = 4.60e-05 loss = 0.000127 train = 1.000000 valid = 0.878554\n",
            "2022-01-09 01:59:40 - INFO:\ttrain #7780 lr = 4.59e-05 loss = 0.000027 train = 1.000000 valid = 0.881803\n",
            "2022-01-09 01:59:49 - INFO:\ttrain #7790 lr = 4.59e-05 loss = 0.000040 train = 1.000000 valid = 0.879773\n",
            "2022-01-09 01:59:58 - INFO:\ttrain #7800 lr = 4.58e-05 loss = 0.000102 train = 1.000000 valid = 0.886677\n",
            "2022-01-09 01:59:59 - INFO:\tSaved test = 0.869935\n",
            "2022-01-09 02:00:08 - INFO:\ttrain #7810 lr = 4.58e-05 loss = 0.000283 train = 1.000000 valid = 0.873680\n",
            "2022-01-09 02:00:17 - INFO:\ttrain #7820 lr = 4.57e-05 loss = 0.019643 train = 0.998633 valid = 0.877335\n",
            "2022-01-09 02:00:26 - INFO:\ttrain #7830 lr = 4.57e-05 loss = 0.011535 train = 0.998633 valid = 0.880179\n",
            "2022-01-09 02:00:35 - INFO:\ttrain #7840 lr = 4.57e-05 loss = 0.001605 train = 0.999805 valid = 0.883022\n",
            "2022-01-09 02:00:44 - INFO:\ttrain #7850 lr = 4.56e-05 loss = 0.003613 train = 0.999414 valid = 0.877742\n",
            "2022-01-09 02:00:53 - INFO:\ttrain #7860 lr = 4.56e-05 loss = 0.010556 train = 0.999414 valid = 0.885459\n",
            "2022-01-09 02:01:02 - INFO:\ttrain #7870 lr = 4.55e-05 loss = 0.003360 train = 0.999609 valid = 0.877742\n",
            "2022-01-09 02:01:11 - INFO:\ttrain #7880 lr = 4.55e-05 loss = 0.009155 train = 0.998633 valid = 0.879773\n",
            "2022-01-09 02:01:19 - INFO:\ttrain #7890 lr = 4.54e-05 loss = 0.002385 train = 0.999805 valid = 0.876117\n",
            "2022-01-09 02:01:28 - INFO:\ttrain #7900 lr = 4.54e-05 loss = 0.017261 train = 0.997461 valid = 0.881397\n",
            "2022-01-09 02:01:30 - INFO:\tSaved test = 0.858185\n",
            "2022-01-09 02:01:39 - INFO:\ttrain #7910 lr = 4.53e-05 loss = 0.005715 train = 0.999609 valid = 0.878960\n",
            "2022-01-09 02:01:48 - INFO:\ttrain #7920 lr = 4.53e-05 loss = 0.003656 train = 0.999023 valid = 0.876523\n",
            "2022-01-09 02:01:56 - INFO:\ttrain #7930 lr = 4.52e-05 loss = 0.003529 train = 0.999805 valid = 0.881803\n",
            "2022-01-09 02:02:05 - INFO:\ttrain #7940 lr = 4.52e-05 loss = 0.004650 train = 0.999219 valid = 0.880991\n",
            "2022-01-09 02:02:14 - INFO:\ttrain #7950 lr = 4.52e-05 loss = 0.003181 train = 0.999219 valid = 0.880179\n",
            "2022-01-09 02:02:23 - INFO:\ttrain #7960 lr = 4.51e-05 loss = 0.013868 train = 0.998633 valid = 0.878148\n",
            "2022-01-09 02:02:32 - INFO:\ttrain #7970 lr = 4.51e-05 loss = 0.003541 train = 0.999609 valid = 0.873680\n",
            "2022-01-09 02:02:41 - INFO:\ttrain #7980 lr = 4.50e-05 loss = 0.004707 train = 0.999414 valid = 0.879366\n",
            "2022-01-09 02:02:50 - INFO:\ttrain #7990 lr = 4.50e-05 loss = 0.004879 train = 0.999609 valid = 0.875305\n",
            "2022-01-09 02:02:59 - INFO:\ttrain #8000 lr = 4.49e-05 loss = 0.008095 train = 0.998633 valid = 0.876523\n",
            "2022-01-09 02:03:00 - INFO:\tSaved test = 0.861831\n",
            "2022-01-09 02:03:09 - INFO:\ttrain #8010 lr = 4.49e-05 loss = 0.007147 train = 0.999023 valid = 0.886271\n",
            "2022-01-09 02:03:18 - INFO:\ttrain #8020 lr = 4.48e-05 loss = 0.003909 train = 0.999805 valid = 0.881803\n",
            "2022-01-09 02:03:27 - INFO:\ttrain #8030 lr = 4.48e-05 loss = 0.017539 train = 0.997461 valid = 0.880179\n",
            "2022-01-09 02:03:36 - INFO:\ttrain #8040 lr = 4.48e-05 loss = 0.011008 train = 0.998633 valid = 0.886677\n",
            "2022-01-09 02:03:45 - INFO:\ttrain #8050 lr = 4.47e-05 loss = 0.001416 train = 0.999609 valid = 0.880585\n",
            "2022-01-09 02:03:54 - INFO:\ttrain #8060 lr = 4.47e-05 loss = 0.007051 train = 0.999219 valid = 0.880991\n",
            "2022-01-09 02:04:03 - INFO:\ttrain #8070 lr = 4.46e-05 loss = 0.004923 train = 0.999609 valid = 0.879773\n",
            "2022-01-09 02:04:12 - INFO:\ttrain #8080 lr = 4.46e-05 loss = 0.014420 train = 0.999023 valid = 0.880991\n",
            "2022-01-09 02:04:21 - INFO:\ttrain #8090 lr = 4.45e-05 loss = 0.007695 train = 0.998828 valid = 0.886271\n",
            "2022-01-09 02:04:30 - INFO:\ttrain #8100 lr = 4.45e-05 loss = 0.025734 train = 0.997852 valid = 0.877335\n",
            "2022-01-09 02:04:31 - INFO:\tSaved test = 0.869125\n",
            "2022-01-09 02:04:40 - INFO:\ttrain #8110 lr = 4.44e-05 loss = 0.047712 train = 0.997852 valid = 0.879773\n",
            "2022-01-09 02:04:49 - INFO:\ttrain #8120 lr = 4.44e-05 loss = 0.004663 train = 0.999023 valid = 0.879366\n",
            "2022-01-09 02:04:58 - INFO:\ttrain #8130 lr = 4.44e-05 loss = 0.008597 train = 0.999023 valid = 0.885865\n",
            "2022-01-09 02:05:07 - INFO:\ttrain #8140 lr = 4.43e-05 loss = 0.002136 train = 0.999219 valid = 0.885459\n",
            "2022-01-09 02:05:16 - INFO:\ttrain #8150 lr = 4.43e-05 loss = 0.004253 train = 0.999023 valid = 0.880179\n",
            "2022-01-09 02:05:25 - INFO:\ttrain #8160 lr = 4.42e-05 loss = 0.006118 train = 0.999609 valid = 0.876929\n",
            "2022-01-09 02:05:34 - INFO:\ttrain #8170 lr = 4.42e-05 loss = 0.000873 train = 0.999805 valid = 0.878148\n",
            "2022-01-09 02:05:43 - INFO:\ttrain #8180 lr = 4.41e-05 loss = 0.000027 train = 1.000000 valid = 0.881803\n",
            "2022-01-09 02:05:52 - INFO:\ttrain #8190 lr = 4.41e-05 loss = 0.000078 train = 1.000000 valid = 0.878554\n",
            "2022-01-09 02:06:00 - INFO:\ttrain #8200 lr = 4.40e-05 loss = 0.022347 train = 0.998633 valid = 0.876523\n",
            "2022-01-09 02:06:02 - INFO:\tSaved test = 0.863452\n",
            "2022-01-09 02:06:11 - INFO:\ttrain #8210 lr = 4.40e-05 loss = 0.001328 train = 0.999414 valid = 0.877335\n",
            "2022-01-09 02:06:20 - INFO:\ttrain #8220 lr = 4.40e-05 loss = 0.000028 train = 1.000000 valid = 0.877335\n",
            "2022-01-09 02:06:29 - INFO:\ttrain #8230 lr = 4.39e-05 loss = 0.004290 train = 0.999609 valid = 0.877335\n",
            "2022-01-09 02:06:38 - INFO:\ttrain #8240 lr = 4.39e-05 loss = 0.002327 train = 0.999805 valid = 0.874898\n",
            "2022-01-09 02:06:47 - INFO:\ttrain #8250 lr = 4.38e-05 loss = 0.004067 train = 0.999023 valid = 0.880179\n",
            "2022-01-09 02:06:55 - INFO:\ttrain #8260 lr = 4.38e-05 loss = 0.000250 train = 0.999805 valid = 0.880991\n",
            "2022-01-09 02:07:04 - INFO:\ttrain #8270 lr = 4.37e-05 loss = 0.000024 train = 1.000000 valid = 0.887084\n",
            "2022-01-09 02:07:13 - INFO:\ttrain #8280 lr = 4.37e-05 loss = 0.000408 train = 0.999805 valid = 0.884240\n",
            "2022-01-09 02:07:22 - INFO:\ttrain #8290 lr = 4.36e-05 loss = 0.006759 train = 0.999609 valid = 0.875711\n",
            "2022-01-09 02:07:31 - INFO:\ttrain #8300 lr = 4.36e-05 loss = 0.004129 train = 0.999609 valid = 0.876117\n",
            "2022-01-09 02:07:32 - INFO:\tSaved test = 0.863452\n",
            "2022-01-09 02:07:41 - INFO:\ttrain #8310 lr = 4.36e-05 loss = 0.000793 train = 0.999805 valid = 0.884647\n",
            "2022-01-09 02:07:50 - INFO:\ttrain #8320 lr = 4.35e-05 loss = 0.004604 train = 0.999609 valid = 0.876117\n",
            "2022-01-09 02:07:59 - INFO:\ttrain #8330 lr = 4.35e-05 loss = 0.011877 train = 0.997266 valid = 0.872868\n",
            "2022-01-09 02:08:08 - INFO:\ttrain #8340 lr = 4.34e-05 loss = 0.000944 train = 0.999805 valid = 0.881803\n",
            "2022-01-09 02:08:17 - INFO:\ttrain #8350 lr = 4.34e-05 loss = 0.002671 train = 0.999219 valid = 0.874086\n",
            "2022-01-09 02:08:26 - INFO:\ttrain #8360 lr = 4.33e-05 loss = 0.008616 train = 0.999023 valid = 0.868400\n",
            "2022-01-09 02:08:35 - INFO:\ttrain #8370 lr = 4.33e-05 loss = 0.011556 train = 0.999219 valid = 0.874492\n",
            "2022-01-09 02:08:44 - INFO:\ttrain #8380 lr = 4.33e-05 loss = 0.008717 train = 0.998828 valid = 0.876523\n",
            "2022-01-09 02:08:53 - INFO:\ttrain #8390 lr = 4.32e-05 loss = 0.021285 train = 0.998437 valid = 0.882210\n",
            "2022-01-09 02:09:02 - INFO:\ttrain #8400 lr = 4.32e-05 loss = 0.017170 train = 0.998242 valid = 0.878148\n",
            "2022-01-09 02:09:03 - INFO:\tSaved test = 0.856159\n",
            "2022-01-09 02:09:12 - INFO:\ttrain #8410 lr = 4.31e-05 loss = 0.028319 train = 0.997656 valid = 0.869212\n",
            "2022-01-09 02:09:21 - INFO:\ttrain #8420 lr = 4.31e-05 loss = 0.030706 train = 0.997852 valid = 0.878960\n",
            "2022-01-09 02:09:30 - INFO:\ttrain #8430 lr = 4.30e-05 loss = 0.013033 train = 0.998828 valid = 0.883428\n",
            "2022-01-09 02:09:39 - INFO:\ttrain #8440 lr = 4.30e-05 loss = 0.021095 train = 0.998437 valid = 0.874492\n",
            "2022-01-09 02:09:48 - INFO:\ttrain #8450 lr = 4.30e-05 loss = 0.010769 train = 0.999023 valid = 0.873680\n",
            "2022-01-09 02:09:57 - INFO:\ttrain #8460 lr = 4.29e-05 loss = 0.002363 train = 0.999414 valid = 0.874898\n",
            "2022-01-09 02:10:06 - INFO:\ttrain #8470 lr = 4.29e-05 loss = 0.000221 train = 0.999805 valid = 0.873680\n",
            "2022-01-09 02:10:15 - INFO:\ttrain #8480 lr = 4.28e-05 loss = 0.004712 train = 0.999023 valid = 0.879773\n",
            "2022-01-09 02:10:24 - INFO:\ttrain #8490 lr = 4.28e-05 loss = 0.003861 train = 0.999609 valid = 0.880585\n",
            "2022-01-09 02:10:33 - INFO:\ttrain #8500 lr = 4.27e-05 loss = 0.002118 train = 0.999414 valid = 0.877742\n",
            "2022-01-09 02:10:34 - INFO:\tSaved test = 0.863452\n",
            "2022-01-09 02:10:43 - INFO:\ttrain #8510 lr = 4.27e-05 loss = 0.000112 train = 1.000000 valid = 0.878554\n",
            "2022-01-09 02:10:52 - INFO:\ttrain #8520 lr = 4.27e-05 loss = 0.001674 train = 0.999805 valid = 0.875305\n",
            "2022-01-09 02:11:01 - INFO:\ttrain #8530 lr = 4.26e-05 loss = 0.000268 train = 0.999805 valid = 0.879366\n",
            "2022-01-09 02:11:11 - INFO:\ttrain #8540 lr = 4.26e-05 loss = 0.000934 train = 0.999805 valid = 0.868400\n",
            "2022-01-09 02:11:19 - INFO:\ttrain #8550 lr = 4.25e-05 loss = 0.000240 train = 1.000000 valid = 0.873680\n",
            "2022-01-09 02:11:28 - INFO:\ttrain #8560 lr = 4.25e-05 loss = 0.005736 train = 0.999609 valid = 0.873680\n",
            "2022-01-09 02:11:37 - INFO:\ttrain #8570 lr = 4.24e-05 loss = 0.023079 train = 0.998242 valid = 0.877742\n",
            "2022-01-09 02:11:46 - INFO:\ttrain #8580 lr = 4.24e-05 loss = 0.024134 train = 0.998047 valid = 0.875305\n",
            "2022-01-09 02:11:55 - INFO:\ttrain #8590 lr = 4.24e-05 loss = 0.000365 train = 1.000000 valid = 0.872055\n",
            "2022-01-09 02:12:04 - INFO:\ttrain #8600 lr = 4.23e-05 loss = 0.002060 train = 0.999805 valid = 0.874492\n",
            "2022-01-09 02:12:06 - INFO:\tSaved test = 0.863452\n",
            "2022-01-09 02:12:15 - INFO:\ttrain #8610 lr = 4.23e-05 loss = 0.002337 train = 0.999414 valid = 0.870837\n",
            "2022-01-09 02:12:23 - INFO:\ttrain #8620 lr = 4.22e-05 loss = 0.004844 train = 0.999414 valid = 0.870431\n",
            "2022-01-09 02:12:32 - INFO:\ttrain #8630 lr = 4.22e-05 loss = 0.002691 train = 0.999414 valid = 0.878554\n",
            "2022-01-09 02:12:41 - INFO:\ttrain #8640 lr = 4.21e-05 loss = 0.001824 train = 0.999609 valid = 0.879366\n",
            "2022-01-09 02:12:50 - INFO:\ttrain #8650 lr = 4.21e-05 loss = 0.046670 train = 0.997852 valid = 0.875711\n",
            "2022-01-09 02:12:59 - INFO:\ttrain #8660 lr = 4.21e-05 loss = 0.022683 train = 0.999219 valid = 0.878554\n",
            "2022-01-09 02:13:08 - INFO:\ttrain #8670 lr = 4.20e-05 loss = 0.023968 train = 0.998047 valid = 0.871649\n",
            "2022-01-09 02:13:17 - INFO:\ttrain #8680 lr = 4.20e-05 loss = 0.022098 train = 0.997656 valid = 0.868806\n",
            "2022-01-09 02:13:26 - INFO:\ttrain #8690 lr = 4.19e-05 loss = 0.007062 train = 0.999414 valid = 0.873680\n",
            "2022-01-09 02:13:35 - INFO:\ttrain #8700 lr = 4.19e-05 loss = 0.005158 train = 0.999023 valid = 0.877742\n",
            "2022-01-09 02:13:36 - INFO:\tSaved test = 0.861021\n",
            "2022-01-09 02:13:45 - INFO:\ttrain #8710 lr = 4.19e-05 loss = 0.000761 train = 0.999805 valid = 0.871649\n",
            "2022-01-09 02:13:54 - INFO:\ttrain #8720 lr = 4.18e-05 loss = 0.042868 train = 0.996875 valid = 0.874086\n",
            "2022-01-09 02:14:03 - INFO:\ttrain #8730 lr = 4.18e-05 loss = 0.005548 train = 0.999609 valid = 0.880991\n",
            "2022-01-09 02:14:12 - INFO:\ttrain #8740 lr = 4.17e-05 loss = 0.000099 train = 1.000000 valid = 0.870024\n",
            "2022-01-09 02:14:21 - INFO:\ttrain #8750 lr = 4.17e-05 loss = 0.010857 train = 0.999023 valid = 0.874086\n",
            "2022-01-09 02:14:30 - INFO:\ttrain #8760 lr = 4.16e-05 loss = 0.017969 train = 0.998437 valid = 0.876929\n",
            "2022-01-09 02:14:39 - INFO:\ttrain #8770 lr = 4.16e-05 loss = 0.013610 train = 0.999414 valid = 0.876523\n",
            "2022-01-09 02:14:48 - INFO:\ttrain #8780 lr = 4.16e-05 loss = 0.001571 train = 0.999805 valid = 0.880585\n",
            "2022-01-09 02:14:57 - INFO:\ttrain #8790 lr = 4.15e-05 loss = 0.000145 train = 1.000000 valid = 0.880179\n",
            "2022-01-09 02:15:06 - INFO:\ttrain #8800 lr = 4.15e-05 loss = 0.003021 train = 0.999609 valid = 0.877335\n",
            "2022-01-09 02:15:07 - INFO:\tSaved test = 0.862642\n",
            "2022-01-09 02:15:16 - INFO:\ttrain #8810 lr = 4.14e-05 loss = 0.002093 train = 0.999609 valid = 0.880991\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-22-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-21-87a43fac0421>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(more_epoch, valid_result_threshold)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0miperm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mget_trans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_trans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                     \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miperm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcrit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\colab\\PointCloud\\encoder.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, ans, inputs, extra, perm)\u001b[0m\n\u001b[0;32m    353\u001b[0m                 \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_layers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_type\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\colab\\PointCloud\\encoder.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, ans, sample, vec, dmap, drev)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_type\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m             \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpts_align\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m             \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\colab\\PointCloud\\encoder.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, points)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEgeHANNsM7r"
      },
      "source": [
        "# **Test**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataset import make_batch_train, make_batch_eval\n",
        "\n",
        "global batch_size\n",
        "num_workers = 0\n",
        "batch_size = 64\n",
        "\n",
        "for name, dataset in zip(['valid', 'test'], [train_dataset, valid_dataset, test_dataset]):\n",
        "    dataset.mem = torch.load(f'{OUTPUT}/{name}_data{prefix}.pth')\n",
        "\n",
        "mbtrain = make_batch_train\n",
        "# mbtrain = make_batch_train_augment\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, collate_fn=mbtrain, pin_memory=True, drop_last=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, collate_fn=make_batch_eval, pin_memory=True, drop_last=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, collate_fn=make_batch_eval, pin_memory=True, drop_last=False)"
      ],
      "metadata": {
        "id": "B0jmq0zxbmsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uTtXJtExKBf"
      },
      "source": [
        "ckpt = torch.load(f\"{OUTPUT}/trained_best{prefix}.pth\")\n",
        "# ckpt = torch.load(f\"{OUTPUT}/trained_14000.pth\")\n",
        "model.load_state_dict(ckpt['encoder'])\n",
        "linear.load_state_dict(ckpt['linear'])\n",
        "batch_size = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5fkZc6a2CUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7094be5a-0f05-4179-9933-69ea130da2f4"
      },
      "source": [
        "evaluate(model, linear, valid_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-07 11:32:58 - INFO:\tloader # = 39\n",
            "2022-01-07 11:32:58 - DEBUG:\ttest #0 correct = 0.875000\n",
            "2022-01-07 11:32:58 - DEBUG:\ttest #1 correct = 0.875000\n",
            "2022-01-07 11:32:58 - DEBUG:\ttest #2 correct = 0.875000\n",
            "2022-01-07 11:32:58 - DEBUG:\ttest #3 correct = 0.882812\n",
            "2022-01-07 11:32:58 - DEBUG:\ttest #4 correct = 0.881250\n",
            "2022-01-07 11:32:58 - DEBUG:\ttest #5 correct = 0.877604\n",
            "2022-01-07 11:32:58 - DEBUG:\ttest #6 correct = 0.877232\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #7 correct = 0.869141\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #8 correct = 0.864583\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #9 correct = 0.867188\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #10 correct = 0.872159\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #11 correct = 0.876302\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #12 correct = 0.879808\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #13 correct = 0.878348\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #14 correct = 0.877083\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #15 correct = 0.878906\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #16 correct = 0.881434\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #17 correct = 0.882812\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #18 correct = 0.879934\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #19 correct = 0.879687\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #20 correct = 0.876488\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #21 correct = 0.878551\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #22 correct = 0.879755\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #23 correct = 0.879557\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #24 correct = 0.878125\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #25 correct = 0.879207\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #26 correct = 0.880787\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #27 correct = 0.880022\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #28 correct = 0.881466\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #29 correct = 0.882812\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #30 correct = 0.882056\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #31 correct = 0.881836\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #32 correct = 0.883996\n",
            "2022-01-07 11:32:59 - DEBUG:\ttest #33 correct = 0.885570\n",
            "2022-01-07 11:33:00 - DEBUG:\ttest #34 correct = 0.887054\n",
            "2022-01-07 11:33:00 - DEBUG:\ttest #35 correct = 0.886285\n",
            "2022-01-07 11:33:00 - DEBUG:\ttest #36 correct = 0.887247\n",
            "2022-01-07 11:33:00 - DEBUG:\ttest #37 correct = 0.886924\n",
            "2022-01-07 11:33:00 - DEBUG:\ttest #38 correct = 0.886271\n",
            "2022-01-07 11:33:00 - INFO:\tDone: score = 0.88627132\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8862713241267263"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7Gsdnr16JCm",
        "outputId": "dd17cd07-379c-433a-d8f8-04d80f437fd2"
      },
      "source": [
        "evaluate(model, linear, test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-07 11:33:02 - INFO:\tloader # = 39\n",
            "2022-01-07 11:33:02 - DEBUG:\ttest #0 correct = 0.781250\n",
            "2022-01-07 11:33:02 - DEBUG:\ttest #1 correct = 0.789062\n",
            "2022-01-07 11:33:02 - DEBUG:\ttest #2 correct = 0.807292\n",
            "2022-01-07 11:33:02 - DEBUG:\ttest #3 correct = 0.839844\n",
            "2022-01-07 11:33:02 - DEBUG:\ttest #4 correct = 0.840625\n",
            "2022-01-07 11:33:02 - DEBUG:\ttest #5 correct = 0.841146\n",
            "2022-01-07 11:33:02 - DEBUG:\ttest #6 correct = 0.845982\n",
            "2022-01-07 11:33:02 - DEBUG:\ttest #7 correct = 0.857422\n",
            "2022-01-07 11:33:02 - DEBUG:\ttest #8 correct = 0.857639\n",
            "2022-01-07 11:33:02 - DEBUG:\ttest #9 correct = 0.859375\n",
            "2022-01-07 11:33:02 - DEBUG:\ttest #10 correct = 0.866477\n",
            "2022-01-07 11:33:02 - DEBUG:\ttest #11 correct = 0.869792\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #12 correct = 0.872596\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #13 correct = 0.869420\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #14 correct = 0.868750\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #15 correct = 0.866211\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #16 correct = 0.861213\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #17 correct = 0.858507\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #18 correct = 0.857730\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #19 correct = 0.860156\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #20 correct = 0.862351\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #21 correct = 0.861506\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #22 correct = 0.860734\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #23 correct = 0.858724\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #24 correct = 0.853750\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #25 correct = 0.854567\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #26 correct = 0.850116\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #27 correct = 0.847098\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #28 correct = 0.848060\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #29 correct = 0.848958\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #30 correct = 0.849798\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #31 correct = 0.845703\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #32 correct = 0.845644\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #33 correct = 0.846967\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #34 correct = 0.845089\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #35 correct = 0.844618\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #36 correct = 0.845861\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #37 correct = 0.847039\n",
            "2022-01-07 11:33:03 - DEBUG:\ttest #38 correct = 0.847650\n",
            "2022-01-07 11:33:03 - INFO:\tDone: score = 0.84764992\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8476499189627229"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2ZPmyge6h4q",
        "outputId": "15616a18-2a1b-47ed-f49c-1bdbfcad11d4"
      },
      "source": [
        "evaluate(model, linear, train_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-11-29 22:03:37 - INFO:\tloader # = 1076\n",
            "2021-11-29 22:03:37 - DEBUG:\ttest #0 correct = 1.000000\n",
            "2021-11-29 22:03:37 - DEBUG:\ttest #1 correct = 1.000000\n",
            "2021-11-29 22:03:37 - DEBUG:\ttest #2 correct = 1.000000\n",
            "2021-11-29 22:03:37 - DEBUG:\ttest #3 correct = 1.000000\n",
            "2021-11-29 22:03:37 - DEBUG:\ttest #4 correct = 1.000000\n",
            "2021-11-29 22:03:37 - DEBUG:\ttest #5 correct = 0.997396\n",
            "2021-11-29 22:03:37 - DEBUG:\ttest #6 correct = 0.997768\n",
            "2021-11-29 22:03:38 - DEBUG:\ttest #7 correct = 0.998047\n",
            "2021-11-29 22:03:38 - DEBUG:\ttest #8 correct = 0.998264\n",
            "2021-11-29 22:03:38 - DEBUG:\ttest #9 correct = 0.998437\n",
            "2021-11-29 22:03:38 - DEBUG:\ttest #10 correct = 0.998580\n",
            "2021-11-29 22:03:38 - DEBUG:\ttest #11 correct = 0.998698\n",
            "2021-11-29 22:03:38 - DEBUG:\ttest #12 correct = 0.998798\n",
            "2021-11-29 22:03:38 - DEBUG:\ttest #13 correct = 0.998884\n",
            "2021-11-29 22:03:38 - DEBUG:\ttest #14 correct = 0.998958\n",
            "2021-11-29 22:03:38 - DEBUG:\ttest #15 correct = 0.999023\n",
            "2021-11-29 22:03:38 - DEBUG:\ttest #16 correct = 0.999081\n",
            "2021-11-29 22:03:39 - DEBUG:\ttest #17 correct = 0.999132\n",
            "2021-11-29 22:03:39 - DEBUG:\ttest #18 correct = 0.999178\n",
            "2021-11-29 22:03:39 - DEBUG:\ttest #19 correct = 0.999219\n",
            "2021-11-29 22:03:39 - DEBUG:\ttest #20 correct = 0.999256\n",
            "2021-11-29 22:03:39 - DEBUG:\ttest #21 correct = 0.999290\n",
            "2021-11-29 22:03:39 - DEBUG:\ttest #22 correct = 0.999321\n",
            "2021-11-29 22:03:39 - DEBUG:\ttest #23 correct = 0.999349\n",
            "2021-11-29 22:03:39 - DEBUG:\ttest #24 correct = 0.998750\n",
            "2021-11-29 22:03:39 - DEBUG:\ttest #25 correct = 0.998798\n",
            "2021-11-29 22:03:40 - DEBUG:\ttest #26 correct = 0.998843\n",
            "2021-11-29 22:03:40 - DEBUG:\ttest #27 correct = 0.998884\n",
            "2021-11-29 22:03:40 - DEBUG:\ttest #28 correct = 0.998922\n",
            "2021-11-29 22:03:40 - DEBUG:\ttest #29 correct = 0.998958\n",
            "2021-11-29 22:03:40 - DEBUG:\ttest #30 correct = 0.998992\n",
            "2021-11-29 22:03:40 - DEBUG:\ttest #31 correct = 0.999023\n",
            "2021-11-29 22:03:40 - DEBUG:\ttest #32 correct = 0.999053\n",
            "2021-11-29 22:03:40 - DEBUG:\ttest #33 correct = 0.999081\n",
            "2021-11-29 22:03:40 - DEBUG:\ttest #34 correct = 0.999107\n",
            "2021-11-29 22:03:41 - DEBUG:\ttest #35 correct = 0.999132\n",
            "2021-11-29 22:03:41 - DEBUG:\ttest #36 correct = 0.999155\n",
            "2021-11-29 22:03:41 - DEBUG:\ttest #37 correct = 0.999178\n",
            "2021-11-29 22:03:41 - DEBUG:\ttest #38 correct = 0.999199\n",
            "2021-11-29 22:03:41 - DEBUG:\ttest #39 correct = 0.999219\n",
            "2021-11-29 22:03:41 - DEBUG:\ttest #40 correct = 0.999238\n",
            "2021-11-29 22:03:41 - DEBUG:\ttest #41 correct = 0.999256\n",
            "2021-11-29 22:03:41 - DEBUG:\ttest #42 correct = 0.999273\n",
            "2021-11-29 22:03:41 - DEBUG:\ttest #43 correct = 0.999290\n",
            "2021-11-29 22:03:42 - DEBUG:\ttest #44 correct = 0.999306\n",
            "2021-11-29 22:03:42 - DEBUG:\ttest #45 correct = 0.999321\n",
            "2021-11-29 22:03:42 - DEBUG:\ttest #46 correct = 0.999335\n",
            "2021-11-29 22:03:42 - DEBUG:\ttest #47 correct = 0.999349\n",
            "2021-11-29 22:03:42 - DEBUG:\ttest #48 correct = 0.999362\n",
            "2021-11-29 22:03:42 - DEBUG:\ttest #49 correct = 0.999375\n",
            "2021-11-29 22:03:42 - DEBUG:\ttest #50 correct = 0.999387\n",
            "2021-11-29 22:03:42 - DEBUG:\ttest #51 correct = 0.999399\n",
            "2021-11-29 22:03:42 - DEBUG:\ttest #52 correct = 0.999410\n",
            "2021-11-29 22:03:43 - DEBUG:\ttest #53 correct = 0.999421\n",
            "2021-11-29 22:03:43 - DEBUG:\ttest #54 correct = 0.999432\n",
            "2021-11-29 22:03:43 - DEBUG:\ttest #55 correct = 0.999442\n",
            "2021-11-29 22:03:43 - DEBUG:\ttest #56 correct = 0.999452\n",
            "2021-11-29 22:03:43 - DEBUG:\ttest #57 correct = 0.999461\n",
            "2021-11-29 22:03:43 - DEBUG:\ttest #58 correct = 0.999470\n",
            "2021-11-29 22:03:43 - DEBUG:\ttest #59 correct = 0.999219\n",
            "2021-11-29 22:03:43 - DEBUG:\ttest #60 correct = 0.999232\n",
            "2021-11-29 22:03:43 - DEBUG:\ttest #61 correct = 0.999244\n",
            "2021-11-29 22:03:44 - DEBUG:\ttest #62 correct = 0.999256\n",
            "2021-11-29 22:03:44 - DEBUG:\ttest #63 correct = 0.999268\n",
            "2021-11-29 22:03:44 - DEBUG:\ttest #64 correct = 0.999279\n",
            "2021-11-29 22:03:44 - DEBUG:\ttest #65 correct = 0.999290\n",
            "2021-11-29 22:03:44 - DEBUG:\ttest #66 correct = 0.999300\n",
            "2021-11-29 22:03:44 - DEBUG:\ttest #67 correct = 0.999311\n",
            "2021-11-29 22:03:44 - DEBUG:\ttest #68 correct = 0.999321\n",
            "2021-11-29 22:03:44 - DEBUG:\ttest #69 correct = 0.999330\n",
            "2021-11-29 22:03:44 - DEBUG:\ttest #70 correct = 0.999340\n",
            "2021-11-29 22:03:45 - DEBUG:\ttest #71 correct = 0.999349\n",
            "2021-11-29 22:03:45 - DEBUG:\ttest #72 correct = 0.999358\n",
            "2021-11-29 22:03:45 - DEBUG:\ttest #73 correct = 0.999367\n",
            "2021-11-29 22:03:45 - DEBUG:\ttest #74 correct = 0.999375\n",
            "2021-11-29 22:03:45 - DEBUG:\ttest #75 correct = 0.999383\n",
            "2021-11-29 22:03:45 - DEBUG:\ttest #76 correct = 0.999391\n",
            "2021-11-29 22:03:45 - DEBUG:\ttest #77 correct = 0.999399\n",
            "2021-11-29 22:03:45 - DEBUG:\ttest #78 correct = 0.999407\n",
            "2021-11-29 22:03:45 - DEBUG:\ttest #79 correct = 0.999219\n",
            "2021-11-29 22:03:46 - DEBUG:\ttest #80 correct = 0.999035\n",
            "2021-11-29 22:03:46 - DEBUG:\ttest #81 correct = 0.999047\n",
            "2021-11-29 22:03:46 - DEBUG:\ttest #82 correct = 0.999059\n",
            "2021-11-29 22:03:46 - DEBUG:\ttest #83 correct = 0.999070\n",
            "2021-11-29 22:03:46 - DEBUG:\ttest #84 correct = 0.999081\n",
            "2021-11-29 22:03:46 - DEBUG:\ttest #85 correct = 0.999092\n",
            "2021-11-29 22:03:46 - DEBUG:\ttest #86 correct = 0.999102\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-24-5b1a2df14c11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-17-d85afdf54d5c>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(model, linear, loader, noprint, perms)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mactivate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mperm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mperms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\colab\\PointCloud\\dataset.py\u001b[0m in \u001b[0;36mmake_batch_train\u001b[1;34m(batches)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmake_batch_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmake_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmake_batch_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\colab\\PointCloud\\dataset.py\u001b[0m in \u001b[0;36mmake_batch\u001b[1;34m(batches, eval)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mjitter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[0mjitter\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mjitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m             \u001b[0mpts\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mjitter\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1e-3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[0mpoints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U4NvVgYupdf"
      },
      "source": [
        "# **Scratch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-XSgniTvM8f"
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if 'srate' in name:\n",
        "        print(name, param.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0IeD-3ZgY4n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOygixubgY13"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E6mDOgfgZuw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_iQLwahgZrn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ5vq0ZPgZkV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gMJnjFlgYyv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScbXNhfOAkZl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}